{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Trained Pytorch model and results\n",
    "\n",
    "## Import libraries and plot training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from anytree import Node\n",
    "from anytree.importer import JsonImporter\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from models.hierarchical_cnn import HierarchicalCNN\n",
    "from utils.custom_dataset import CustomDataset\n",
    "\n",
    "# Read the training log file\n",
    "training_log = pd.read_csv('/mnt/RAID/projects/FjordVision/logs-coco/model_alpha_05.csv')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(training_log['Epoch'], training_log['Training Loss'], label='Training Loss')\n",
    "plt.plot(training_log['Epoch'], training_log['Validation Loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df = pd.read_parquet('/mnt/RAID/projects/FjordVision/data/coco-segmented-objects-dataset.parquet')\n",
    "\n",
    "# Assuming df is your DataFrame with all data\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Model and Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate Taxonomy\n",
    "importer = JsonImporter()\n",
    "with open('/mnt/RAID/projects/FjordVision/data/coco.json', 'r') as f:\n",
    "    root = importer.read(f)\n",
    "\n",
    "classes_file = '/mnt/RAID/datasets/coco/classes.txt'\n",
    "\n",
    "object_names = []\n",
    "with open(classes_file, 'r') as file:\n",
    "    object_names = [line.strip() for line in file]\n",
    "\n",
    "subcategory_names, category_names, binary_names = [], [], []\n",
    "for node in root.descendants:\n",
    "    if node.rank == 'subcategory':\n",
    "        subcategory_names.append(node.name)\n",
    "    elif node.rank == 'category':\n",
    "        category_names.append(node.name)\n",
    "    elif node.rank == 'binary':\n",
    "        binary_names.append(node.name)\n",
    "\n",
    "class_name_lists = [binary_names, category_names, subcategory_names, object_names]\n",
    "                    \n",
    "# Create a defaultdict to store the counts for each rank\n",
    "rank_counts = defaultdict(int)\n",
    "\n",
    "# Iterate over the nodes of the tree\n",
    "for node in root.descendants:\n",
    "    rank = node.rank\n",
    "    rank_counts[rank] += 1\n",
    "\n",
    "# Example instantiation of the model\n",
    "num_classes_hierarchy = list(rank_counts.values())  # Example: [num_species, num_genus, num_class, num_binary]\n",
    "num_additional_features = 3  # Assuming 3 additional features: conf, iou, pred_species\n",
    "\n",
    "model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "model.load_state_dict(torch.load('/mnt/RAID/projects/FjordVision/models/weights/coco-best_model_alpha_05.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree.importer import JsonImporter\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "# Define the function in your notebook\n",
    "def get_hierarchical_labels(species_index, species_names, genus_names, class_names, binary_names, root):\n",
    "    if species_index == -1:\n",
    "        return -1, -1, -1  # Handle cases where species_index is invalid\n",
    "\n",
    "    species_name = species_names[species_index]\n",
    "    node = next((n for n in root.descendants if n.name == species_name), None)\n",
    "\n",
    "    if node is None:\n",
    "        return -1, -1, -1  # Species not found in the tree\n",
    "\n",
    "    # Initialize indices\n",
    "    genus_index, class_index, binary_index = -1, -1, -1\n",
    "    \n",
    "    # Traverse up the tree to find the indices\n",
    "    current_node = node\n",
    "    while current_node.parent is not None:\n",
    "        current_node = current_node.parent\n",
    "        if current_node.rank == 'subcategory':\n",
    "            genus_index = genus_names.index(current_node.name) if current_node.name in genus_names else -1\n",
    "        elif current_node.rank == 'category':\n",
    "            class_index = class_names.index(current_node.name) if current_node.name in class_names else -1\n",
    "        elif current_node.rank == 'binary':\n",
    "            binary_index = binary_names.index(current_node.name) if current_node.name in binary_names else -1\n",
    "\n",
    "    return genus_index, class_index, binary_index\n",
    "\n",
    "\n",
    "# Iterate through all object names and check which ones return -1 for any rank\n",
    "for object_name in object_names:\n",
    "    species_index = object_names.index(object_name) if object_name in object_names else -1\n",
    "    genus_index, class_index, binary_index = get_hierarchical_labels(species_index, object_names, subcategory_names, category_names, binary_names, root)\n",
    "    \n",
    "    # Check if any of the indices are -1\n",
    "    if genus_index == -1 or class_index == -1 or binary_index == -1:\n",
    "        print(f\"Object Name: {object_name} - Genus Index: {genus_index}, Class Index: {class_index}, Binary Index: {binary_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df, object_names, subcategory_names, category_names, binary_names, root)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df['predicted_species'] == test_df['species']).sum() / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store true labels and predictions for each level\n",
    "true_labels = {level: [] for level in ['binary', 'category', 'subcategory', 'object']}\n",
    "predictions = {level: [] for level in ['binary', 'category', 'subcategory', 'object']}\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "        images, conf, iou, pred_species = images.to(device), conf.to(device), iou.to(device), pred_species.to(device)\n",
    "        \n",
    "        outputs = model(images, conf, iou, pred_species)\n",
    "        \n",
    "        # Convert model outputs to predictions\n",
    "        for i, output in enumerate(outputs):  # For each hierarchical level\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            level = ['binary', 'category', 'subcategory', 'object'][i]\n",
    "            predictions[level].extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Store true labels\n",
    "        true_labels['binary'].extend(binary_index.cpu().numpy())\n",
    "        true_labels['category'].extend(class_index.cpu().numpy())\n",
    "        true_labels['subcategory'].extend(genus_index.cpu().numpy())\n",
    "        true_labels['object'].extend(species_index.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = {}\n",
    "for level in ['binary', 'category', 'subcategory', 'object']:\n",
    "    f1_scores[level] = f1_score(true_labels[level], predictions[level], average='macro')\n",
    "    print(f\"F1 Score for {level}: {f1_scores[level]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "# Assume necessary imports and model definition are done here\n",
    "\n",
    "def transform_activations(activations):\n",
    "    \"\"\"\n",
    "    Transforms activations from (C x B x H x W) to (B x C x H x W).\n",
    "    Specifically handles the case where C should be treated as B for visualization.\n",
    "    \"\"\"\n",
    "    B, C, H, W = activations.shape[1], 1, activations.shape[2], activations.shape[3]\n",
    "    return activations.permute(1, 0, 2, 3).view(B, C, H, W)\n",
    "\n",
    "def resample_activations_to_grid(activations, nrow=4):\n",
    "    \"\"\"\n",
    "    Ensures there are nrow*nrow activation maps by either repeating or subsetting.\n",
    "    Adjusted for a 4x4 grid.\n",
    "    \"\"\"\n",
    "    total_needed = nrow * nrow  # Adjusted for a 4x4 grid\n",
    "    current_count = activations.shape[0]\n",
    "\n",
    "    if current_count < total_needed:\n",
    "        repeats = total_needed // current_count + 1\n",
    "        activations = activations.repeat(repeats, 1, 1, 1)[:total_needed]\n",
    "    elif current_count > total_needed:\n",
    "        indices = torch.linspace(0, current_count - 1, total_needed).long()\n",
    "        activations = activations[indices]\n",
    "\n",
    "    return activations\n",
    "\n",
    "def visualize_hierarchical_predictions_and_activations(image, activations, true_labels, predictions, class_name_lists, file_name):\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 4))  # Adjusted subplot size for better visualization\n",
    "    levels = ['original', 'binary', 'class', 'genus', 'species']\n",
    "\n",
    "    # Original image visualization\n",
    "    img_np = np.transpose(image.cpu().numpy(), (1, 2, 0))\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    axs[0].imshow(img_np)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Visualize activations for each level\n",
    "    for i, level in enumerate(levels):\n",
    "        if i == 0: continue\n",
    "        current_activation = activations[i - 1]\n",
    "        current_activation = transform_activations(current_activation)\n",
    "        current_activation = resample_activations_to_grid(current_activation, nrow=4)  # Ensure 4x4 grid\n",
    "        activation_grid = make_grid(current_activation, nrow=4, normalize=True, padding=2)\n",
    "\n",
    "        # Directly convert the grid tensor to a NumPy array and apply cmap\n",
    "        grid_np = np.transpose(activation_grid.cpu().numpy(), (1, 2, 0))\n",
    "        axs[i].imshow(grid_np[:, :, 0], cmap='viridis')  # Ensures viridis is applied for single-channel images\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name)  # Save the figure\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Define alpha values\n",
    "alpha_values = [0.5]\n",
    "\n",
    "# Create the main directory for activations if it doesn't exist\n",
    "os.makedirs('activations', exist_ok=True)\n",
    "\n",
    "# Loop through each alpha value\n",
    "for alpha in alpha_values:\n",
    "    # Adjust the alpha value for file naming convention\n",
    "    alpha_str = str(alpha).replace('.', '')\n",
    "    alpha_dir = f'activations/alpha_{alpha_str}'\n",
    "    os.makedirs(alpha_dir, exist_ok=True)\n",
    "    \n",
    "    # Loop through each species\n",
    "    for idx, species in enumerate(object_names):\n",
    "        # Modify the model loading path to include the current alpha value\n",
    "        model_path = f'/mnt/RAID/projects/FjordVision/models/weights/coco-best_model_alpha_{alpha_str}.pth'\n",
    "        \n",
    "        # Load and prepare the model for each species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        model.register_hooks()\n",
    "\n",
    "        # Get one random sample from the DataLoader\n",
    "        for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "            if species_index[0].item() == idx:\n",
    "                selected_image = images[0].unsqueeze(0).to(device)\n",
    "                selected_conf = conf[0].unsqueeze(0).to(device)\n",
    "                selected_iou = iou[0].unsqueeze(0).to(device)\n",
    "                selected_pred_species = pred_species[0].unsqueeze(0).to(device)\n",
    "                _ = model(selected_image, selected_conf, selected_iou, selected_pred_species)\n",
    "                break\n",
    "\n",
    "        # Create a directory for the species within the alpha directory if it doesn't exist\n",
    "        species_dir = os.path.join(alpha_dir, species.replace(\" \", \"_\"))\n",
    "        os.makedirs(species_dir, exist_ok=True)\n",
    "\n",
    "        # Generate and save the activation visualizations in the species directory\n",
    "        file_name = os.path.join(species_dir, f'{species.replace(\" \", \"_\")}.png')\n",
    "        visualize_hierarchical_predictions_and_activations(\n",
    "            selected_image.squeeze(0), \n",
    "            model.activations, \n",
    "            {'binary': binary_index[0].item(), 'category': class_index[0].item(), 'subcategory': genus_index[0].item(), 'object': species_index[0].item()}, \n",
    "            predictions, \n",
    "            class_name_lists,\n",
    "            file_name  # Pass the file name where the image should be saved\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Segmentation of Selected Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise most likely classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the parameters for the image optimization process\n",
    "upscaling_steps = 15\n",
    "upscaling_factor = 1.2\n",
    "lr = 0.01\n",
    "\n",
    "# Load the model\n",
    "alphas = ['05']\n",
    "levels = ['binary', 'category', 'subcategory', 'object']\n",
    "class_levels = [binary_names, category_names, subcategory_names, object_names]\n",
    "\n",
    "# Create the main directory for class activations\n",
    "os.makedirs('class-activations', exist_ok=True)\n",
    "\n",
    "for alpha in alphas:\n",
    "    model_path = f'/mnt/RAID/projects/FjordVision/models/weights/coco-best_model_alpha_{alpha}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for level_index, level in enumerate(levels):\n",
    "        level_path = os.path.join('class-activations', level)\n",
    "        os.makedirs(level_path, exist_ok=True)\n",
    "\n",
    "        for class_name in class_levels[level_index]:\n",
    "            class_path = os.path.join(level_path, class_name.replace(\" \", \"_\"))\n",
    "            os.makedirs(class_path, exist_ok=True)\n",
    "\n",
    "            # Initialize the image tensor once before the loop\n",
    "            image = torch.randn(1, 3, 50, 50, device=device, requires_grad=True)\n",
    "\n",
    "            for step in range(upscaling_steps):\n",
    "                optimizer = optim.Adam([image], lr=lr)\n",
    "\n",
    "                for iteration in range(30):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(image, torch.tensor([0.0], device=device), torch.tensor([0.0], device=device), torch.tensor([0.0], device=device))\n",
    "                    target_class_index = class_levels[level_index].index(class_name)\n",
    "                    target_output = outputs[level_index]\n",
    "\n",
    "                    loss = -target_output[0, target_class_index]\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Delete intermediate tensors\n",
    "                    del outputs, target_output, loss\n",
    "\n",
    "                # Upscale the image tensor\n",
    "                if step < upscaling_steps - 1:\n",
    "                    size = int(50 * (upscaling_factor ** (step + 1)))\n",
    "                    image = image.detach().cpu().numpy()\n",
    "                    image = np.transpose(image, (0, 2, 3, 1))\n",
    "                    image = cv2.resize(image[0], (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "                    image = np.transpose(image, (2, 0, 1))\n",
    "                    image = torch.from_numpy(image).unsqueeze(0).to(device)\n",
    "                    image.requires_grad_(True)\n",
    "\n",
    "            # Process and save the final image\n",
    "            image_np = image.detach().cpu().squeeze().numpy()\n",
    "            image_np = np.transpose(image_np, (1, 2, 0))\n",
    "            image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n",
    "            image_filename = os.path.join(class_path, f'{class_name.replace(\" \", \"_\")}_alpha_{alpha}.png')\n",
    "            plt.imsave(image_filename, image_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjordvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
