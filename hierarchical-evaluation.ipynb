{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(\"/mnt/RAID/projects/FjordVision\")\n",
    "from models.probability_tree import ProbabilityTree\n",
    "import torch\n",
    "from anytree.importer import JsonImporter\n",
    "from preprocessing.preprocessing import load_ground_truth_mask_xyn, convert_polygon_to_mask, calculate_binary_mask_iou\n",
    "from utils.metrics import calculate_hierarchical_precision_recall, calculate_weighted_f1_score\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Function to divide the data into chunks of size n\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# Define the file path\n",
    "weights_path = '/mnt/RAID/projects/FjordVision/runs/segment/Yolov8n-seg-train/weights/best.pt'\n",
    "\n",
    "# Load the YOLO model weights\n",
    "model = YOLO(weights_path)\n",
    "\n",
    "importer = JsonImporter()\n",
    "with open('data/ontology.json', 'r') as f:\n",
    "    root = importer.read(f)\n",
    "\n",
    "classes_file = '/mnt/RAID/datasets/label-studio/fjord/classes.txt'\n",
    "\n",
    "species_names = []\n",
    "with open(classes_file, 'r') as file:\n",
    "    species_names = [line.strip() for line in file]\n",
    "\n",
    "genus_names, class_names, binary_names = [], [], []\n",
    "for node in root.descendants:\n",
    "    if node.rank == 'genus':\n",
    "        genus_names.append(node.name)\n",
    "    elif node.rank == 'class':\n",
    "        class_names.append(node.name)\n",
    "    elif node.rank == 'binary':\n",
    "        binary_names.append(node.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Probability Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "ontology_path = 'data/ontology.json'  # Update this path as necessary\n",
    "prob_tree = ProbabilityTree(ontology_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the image folder path\n",
    "image_folder_path = '/mnt/RAID/datasets/The Fjord Dataset/fjord/images/test/'\n",
    "frames = os.listdir(image_folder_path)\n",
    "image_files_full_path = [image_folder_path + f for f in frames]\n",
    "\n",
    "# Define the label folder path\n",
    "label_folder_path = '/mnt/RAID/datasets/The Fjord Dataset/fjord/labels/test/'\n",
    "\n",
    "classes = '/mnt/RAID/datasets/The Fjord Dataset/fjord/classes.txt'\n",
    "\n",
    "class_index = []\n",
    "with open(classes, 'r') as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "        class_name = line.strip()\n",
    "        class_index.append(class_name)\n",
    "\n",
    "Y = []\n",
    "Yhat = []\n",
    "confidences = []\n",
    "batch_size = 50\n",
    "\n",
    "# Loop through batches of images\n",
    "for image_batch in chunks(image_files_full_path, batch_size):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_batch, stream=True)\n",
    "\n",
    "    # Loop through the files in the image folder\n",
    "    for file_name, prediction in zip(image_batch, predictions):\n",
    "        # Check if the file is an image file\n",
    "        if file_name.endswith('.jpg') or file_name.endswith('.png'):\n",
    "            # Construct the corresponding label file name\n",
    "            shape = prediction.orig_img.shape[:2]\n",
    "            base_file_name = file_name.split('/')[-1].replace('.jpg', '.txt')\n",
    "            label_file_path = label_folder_path + base_file_name\n",
    "        \n",
    "            # check if predictions are empty\n",
    "            if len(prediction.boxes.cls) == 0:\n",
    "                continue\n",
    "\n",
    "            GT = load_ground_truth_mask_xyn(label_file_path)\n",
    "            visited = len(GT)*[None]\n",
    "\n",
    "            for cls, mask, conf in zip(prediction.boxes.cls, prediction.masks.xyn, prediction.boxes.conf):\n",
    "                confidences.append(conf.item())\n",
    "                m = convert_polygon_to_mask(mask, shape)\n",
    "                best_iou = 0\n",
    "\n",
    "                # calculate iou and find the best mask\n",
    "                for idx, (gcls, gmsk) in enumerate(GT):\n",
    "                    g = convert_polygon_to_mask(gmsk, shape)\n",
    "                    iou = calculate_binary_mask_iou(m, g)\n",
    "\n",
    "                    if iou > best_iou and iou > 0.5:\n",
    "                        best_iou = iou\n",
    "                        best_g = g\n",
    "                        best_gcls = gcls\n",
    "                        visited[idx] = True\n",
    "                        best_idx = idx\n",
    "\n",
    "                if best_idx is not None and best_iou > 0.5:\n",
    "                    visited[best_idx] = True\n",
    "\n",
    "                if best_g is None:\n",
    "                    Y.append(None)\n",
    "                    Yhat.append(int(cls.item()))\n",
    "                else:\n",
    "                    Y.append(best_gcls)\n",
    "                    Yhat.append(int(cls.item()))\n",
    "\n",
    "            for vis in visited:\n",
    "                if vis is None:\n",
    "                    Y.append(GT[idx][0])\n",
    "                    Yhat.append(None)\n",
    "\n",
    "    # After processing each batch, clear unusPolitisk likheited memory from CUDA\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted precision, recall, and F1\n",
    "precision, recall = calculate_hierarchical_precision_recall(Y, Yhat, root, species_names)\n",
    "weighted_f1_score = calculate_weighted_f1_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9588657803141181"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972809667673716"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9270517169110761"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Predictions with uniform probability tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree.search import find\n",
    "from anytree.walker import Walker\n",
    "\n",
    "def hierarchical_similarity(node1, node2):\n",
    "    walker = Walker()\n",
    "    # Assuming node1 and node2 are already the correct nodes from the tree\n",
    "    upwards, _, down = walker.walk(node1, node2)\n",
    "    distance = len(upwards) + len(down)\n",
    "\n",
    "    return 1 / (1 + distance)\n",
    "\n",
    "def calculate_hierarchical_precision_recall(Y, Yhat, tree, confidences, threshold=0.8):\n",
    "    weighted_true_positives = 0\n",
    "    weighted_false_positives = 0\n",
    "    weighted_false_negatives = 0\n",
    "    taxonomies = [species_names, genus_names, class_names, binary_names]\n",
    "    \n",
    "    for true_label, predicted_label, conf in zip(Y, Yhat, confidences):\n",
    "        if predicted_label is None:  # Handle negative prediction as complete miss\n",
    "            weighted_false_negatives += 1\n",
    "            continue\n",
    "        if true_label is None:  # Handle missing ground truth as complete miss\n",
    "            weighted_false_positives += 1\n",
    "            continue\n",
    "\n",
    "        current_taxonomy = 0\n",
    "        node = find(tree.root, lambda node: node.name == taxonomies[current_taxonomy][predicted_label])\n",
    "        while conf < threshold and current_taxonomy < len(taxonomies) - 1:\n",
    "            # Move up the taxonomy if the confidence is below the threshold\n",
    "            if node.parent is not None:\n",
    "                node = node.parent\n",
    "                current_taxonomy += 1\n",
    "                # Attempt to find the new predicted_label index in the parent taxonomy\n",
    "                try:\n",
    "                    predicted_label = taxonomies[current_taxonomy].index(node.name)\n",
    "                except ValueError:\n",
    "                    # If the node's name is not in the taxonomy, break from the loop\n",
    "                    break\n",
    "                conf += tree.sum_siblings_probabilities(node.name)\n",
    "            else:\n",
    "                break  # If there's no parent, we're at the root and cannot go up further\n",
    "\n",
    "        # At this point, node represents the current predicted label node\n",
    "        node1 = node\n",
    "        node2 = find(tree.root, lambda node: node.name == taxonomies[0][true_label])\n",
    "        similarity_weight = hierarchical_similarity(node1, node2)\n",
    "\n",
    "        if true_label == predicted_label:\n",
    "            weighted_true_positives += similarity_weight\n",
    "        else:\n",
    "            weighted_false_positives += (1 - similarity_weight)  # Penalize based on dissimilarity\n",
    "\n",
    "    precision = weighted_true_positives / (weighted_true_positives + weighted_false_positives) if (weighted_true_positives + weighted_false_positives) > 0 else 0\n",
    "    recall = weighted_true_positives / (weighted_true_positives + weighted_false_negatives) if (weighted_true_positives + weighted_false_negatives) > 0 else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "def calculate_weighted_f1_score(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate weighted precision, recall, and F1\n",
    "precision, recall = calculate_hierarchical_precision_recall(Y, Yhat, prob_tree, confidences, threshold=0.2)\n",
    "weighted_f1_score = calculate_weighted_f1_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590961757352848"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8988274706867672"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279843027366996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Using Probability Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1321,\n",
       " 1: 1399,\n",
       " 2: 2324,\n",
       " 3: 1210,\n",
       " 4: 3098,\n",
       " 5: 1376,\n",
       " 6: 1519,\n",
       " 7: 1081,\n",
       " 8: 1292,\n",
       " 9: 2113,\n",
       " 10: 1202,\n",
       " 11: 3314,\n",
       " 12: 4837}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_folder_path = '/mnt/RAID/datasets/The Fjord Dataset/fjord/labels/train/'\n",
    "frames = os.listdir(label_folder_path)\n",
    "label_files_full_path = [label_folder_path + f for f in frames]\n",
    "\n",
    "class_indexes = []\n",
    "\n",
    "for label_file in label_files_full_path:\n",
    "    with open(label_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                class_index = int(line.split()[0])\n",
    "                class_indexes.append(class_index)\n",
    "\n",
    "class_index_counts = {}\n",
    "for class_index in class_indexes:\n",
    "    if class_index in class_index_counts:\n",
    "        class_index_counts[class_index] += 1\n",
    "    else:\n",
    "        class_index_counts[class_index] = 1\n",
    "\n",
    "sorted_class_index_counts = dict(sorted(class_index_counts.items()))\n",
    "sorted_class_index_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjordvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
