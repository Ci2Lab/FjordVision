Experiment started at Mon Jun 24 14:48:57 CEST 2024
Running attention_removed experiments:
Running attention_removed classification training with alpha = 0 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.4092, Validation Loss: 4.7441, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 4.1313, Validation Loss: 2.9070, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 3.2914, Validation Loss: 2.1586, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.7106, Validation Loss: 1.7642, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.3057, Validation Loss: 1.4975, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.1744, Validation Loss: 1.4370, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.8250, Validation Loss: 1.1264, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.6995, Validation Loss: 1.0266, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.3956, Validation Loss: 0.8634, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.4460, Validation Loss: 0.8037, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.2758, Validation Loss: 0.7588, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.2401, Validation Loss: 0.6379, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.1954, Validation Loss: 0.6000, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.0236, Validation Loss: 0.5268, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 0.9225, Validation Loss: 0.4531, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 0.9376, Validation Loss: 0.5037, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 0.9033, Validation Loss: 0.3567, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.7787, Validation Loss: 0.4234, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.7985, Validation Loss: 0.3287, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.7740, Validation Loss: 0.6378, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.7856, Validation Loss: 0.3395, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.6705, Validation Loss: 0.3529, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.7366, Validation Loss: 0.5170, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.6838, Validation Loss: 0.4421, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.6053, Validation Loss: 0.3063, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.6855, Validation Loss: 0.2845, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.5560, Validation Loss: 0.2908, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.6930, Validation Loss: 0.2801, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.6208, Validation Loss: 0.2600, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.5603, Validation Loss: 0.2343, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.5383, Validation Loss: 0.3023, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.5408, Validation Loss: 0.2825, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.5128, Validation Loss: 0.2176, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.4277, Validation Loss: 0.2707, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.5504, Validation Loss: 0.2584, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.5163, Validation Loss: 0.2644, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.4606, Validation Loss: 0.2453, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.5194, Validation Loss: 0.2609, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.4389, Validation Loss: 0.2407, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.3930, Validation Loss: 0.2573, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.5471, Validation Loss: 0.3377, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.3407, Validation Loss: 0.2048, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.4376, Validation Loss: 0.2964, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.4249, Validation Loss: 0.3441, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.3472, Validation Loss: 0.2316, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.3704, Validation Loss: 0.2807, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.4111, Validation Loss: 0.1858, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.3556, Validation Loss: 0.3137, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.3259, Validation Loss: 0.2022, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.4061, Validation Loss: 0.2881, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.3644, Validation Loss: 0.2924, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.3657, Validation Loss: 0.2124, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.3430, Validation Loss: 0.2789, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.2901, Validation Loss: 0.2001, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.4030, Validation Loss: 0.2246, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.3331, Validation Loss: 0.2338, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.3510, Validation Loss: 0.2669, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.3080, Validation Loss: 0.1954, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.2664, Validation Loss: 0.1767, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.2184, Validation Loss: 0.1515, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.2250, Validation Loss: 0.1631, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.1780, Validation Loss: 0.1518, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.1839, Validation Loss: 0.1659, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.1694, Validation Loss: 0.1759, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.2226, Validation Loss: 0.1641, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.2233, Validation Loss: 0.1508, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.1811, Validation Loss: 0.1459, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.1808, Validation Loss: 0.1488, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.1677, Validation Loss: 0.1525, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.1561, Validation Loss: 0.1559, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.1733, Validation Loss: 0.1540, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.1662, Validation Loss: 0.1570, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.1449, Validation Loss: 0.1634, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.1769, Validation Loss: 0.1615, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.1465, Validation Loss: 0.1514, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.1505, Validation Loss: 0.1538, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.1436, Validation Loss: 0.1457, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.1479, Validation Loss: 0.1473, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.1295, Validation Loss: 0.1438, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.1747, Validation Loss: 0.1449, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.1095, Validation Loss: 0.1452, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.1555, Validation Loss: 0.1557, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.1508, Validation Loss: 0.1693, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.1194, Validation Loss: 0.1756, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.1420, Validation Loss: 0.1957, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.1353, Validation Loss: 0.1683, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.1467, Validation Loss: 0.1543, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.1268, Validation Loss: 0.1535, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.1270, Validation Loss: 0.1536, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.1383, Validation Loss: 0.1484, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.1324, Validation Loss: 0.1533, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 92, Training Loss: 0.1030, Validation Loss: 0.1401, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 93, Training Loss: 0.1419, Validation Loss: 0.1432, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 94, Training Loss: 0.0996, Validation Loss: 0.1417, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 95, Training Loss: 0.1198, Validation Loss: 0.1477, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 96, Training Loss: 0.1326, Validation Loss: 0.1473, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 97, Training Loss: 0.1289, Validation Loss: 0.1531, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 98, Training Loss: 0.1190, Validation Loss: 0.1478, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 99, Training Loss: 0.0945, Validation Loss: 0.1362, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 100, Training Loss: 0.1190, Validation Loss: 0.1421, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Running attention_removed classification training with alpha = 0.2 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.1990, Validation Loss: 3.8101, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.4688, Validation Loss: 2.5826, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.6456, Validation Loss: 1.9475, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.2237, Validation Loss: 1.5267, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.9806, Validation Loss: 1.3022, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.7998, Validation Loss: 1.1739, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.5607, Validation Loss: 0.9093, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.3606, Validation Loss: 0.8296, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.2694, Validation Loss: 0.6692, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.3096, Validation Loss: 0.7215, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.0561, Validation Loss: 0.7207, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.1812, Validation Loss: 0.5131, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 0.9269, Validation Loss: 0.5550, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 0.9210, Validation Loss: 0.4470, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.8361, Validation Loss: 0.4194, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.7687, Validation Loss: 0.3673, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.7874, Validation Loss: 0.3012, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.7381, Validation Loss: 0.3126, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.6339, Validation Loss: 0.2801, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.7128, Validation Loss: 0.3021, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.6422, Validation Loss: 0.2776, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.6814, Validation Loss: 0.2615, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.5869, Validation Loss: 0.2817, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.6367, Validation Loss: 0.2822, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.4264, Validation Loss: 0.2794, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.5355, Validation Loss: 0.2629, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.5239, Validation Loss: 0.2308, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.4758, Validation Loss: 0.2904, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.5671, Validation Loss: 0.2893, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.4744, Validation Loss: 0.2742, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.4494, Validation Loss: 0.2420, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.4669, Validation Loss: 0.2386, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.4048, Validation Loss: 0.2447, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.3709, Validation Loss: 0.1827, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.4153, Validation Loss: 0.1593, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.4294, Validation Loss: 0.2765, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.4452, Validation Loss: 0.1985, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.4211, Validation Loss: 0.1697, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.3664, Validation Loss: 0.2083, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.4256, Validation Loss: 0.2210, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.4076, Validation Loss: 0.1771, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.3655, Validation Loss: 0.2406, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.3627, Validation Loss: 0.1908, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.4124, Validation Loss: 0.2847, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.2948, Validation Loss: 0.1733, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.3460, Validation Loss: 0.1767, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.3241, Validation Loss: 0.1370, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.2383, Validation Loss: 0.1212, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.2653, Validation Loss: 0.1185, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.2423, Validation Loss: 0.1186, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.1879, Validation Loss: 0.1127, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.2034, Validation Loss: 0.1088, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.2157, Validation Loss: 0.1120, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.1813, Validation Loss: 0.1006, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.1589, Validation Loss: 0.1022, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.1788, Validation Loss: 0.1026, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.1980, Validation Loss: 0.1102, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.1795, Validation Loss: 0.1066, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.1956, Validation Loss: 0.1044, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.1950, Validation Loss: 0.1048, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.1742, Validation Loss: 0.0990, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.1517, Validation Loss: 0.0978, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.1378, Validation Loss: 0.1012, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.1651, Validation Loss: 0.1019, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.1543, Validation Loss: 0.0987, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.1579, Validation Loss: 0.1049, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.1395, Validation Loss: 0.1014, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.1326, Validation Loss: 0.1015, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.1393, Validation Loss: 0.0967, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.1189, Validation Loss: 0.0975, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.1407, Validation Loss: 0.1030, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.1680, Validation Loss: 0.1018, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.1411, Validation Loss: 0.1049, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.1522, Validation Loss: 0.1059, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.1214, Validation Loss: 0.1017, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.1191, Validation Loss: 0.1048, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.1385, Validation Loss: 0.1083, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.1169, Validation Loss: 0.0986, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.1445, Validation Loss: 0.0992, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.1098, Validation Loss: 0.1020, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.1202, Validation Loss: 0.1034, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.1324, Validation Loss: 0.1049, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.1436, Validation Loss: 0.0998, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.1228, Validation Loss: 0.1034, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.1294, Validation Loss: 0.1013, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.1186, Validation Loss: 0.0983, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.1203, Validation Loss: 0.0980, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.1356, Validation Loss: 0.0996, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.1247, Validation Loss: 0.1002, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Early stopping triggered.
Running attention_removed classification training with alpha = 0.5 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1503, Validation Loss: 3.1473, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.8094, Validation Loss: 1.9421, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 2.2396, Validation Loss: 1.6483, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.8808, Validation Loss: 1.3402, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.5472, Validation Loss: 0.9922, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.3850, Validation Loss: 0.8710, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.2550, Validation Loss: 0.8346, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.1157, Validation Loss: 0.6763, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.0402, Validation Loss: 0.6436, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 0.9268, Validation Loss: 0.5205, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.8989, Validation Loss: 0.4937, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.8420, Validation Loss: 0.4894, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.9510, Validation Loss: 0.4146, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.8052, Validation Loss: 0.4565, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.7285, Validation Loss: 0.3755, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.6590, Validation Loss: 0.3151, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.7506, Validation Loss: 0.2995, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.5753, Validation Loss: 0.3696, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.5575, Validation Loss: 0.3168, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.5570, Validation Loss: 0.2346, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.5143, Validation Loss: 0.2263, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.5065, Validation Loss: 0.1931, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.4623, Validation Loss: 0.2257, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.4017, Validation Loss: 0.2416, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.3946, Validation Loss: 0.1979, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.4224, Validation Loss: 0.1609, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.4279, Validation Loss: 0.2031, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.4027, Validation Loss: 0.1832, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.3375, Validation Loss: 0.2289, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.4079, Validation Loss: 0.2271, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.3936, Validation Loss: 0.2410, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.3947, Validation Loss: 0.2211, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.3837, Validation Loss: 0.1616, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.3086, Validation Loss: 0.1587, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.3490, Validation Loss: 0.1977, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.4610, Validation Loss: 0.1747, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.3437, Validation Loss: 0.1615, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.2609, Validation Loss: 0.1910, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.2924, Validation Loss: 0.1396, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.2770, Validation Loss: 0.1480, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.3435, Validation Loss: 0.1518, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.3083, Validation Loss: 0.1332, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.2504, Validation Loss: 0.1411, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.2307, Validation Loss: 0.1242, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.2659, Validation Loss: 0.1176, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.2205, Validation Loss: 0.1316, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.2401, Validation Loss: 0.1277, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.2607, Validation Loss: 0.1228, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.2318, Validation Loss: 0.1637, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.2189, Validation Loss: 0.1190, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.2075, Validation Loss: 0.1306, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.2420, Validation Loss: 0.1328, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.2359, Validation Loss: 0.1881, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.2914, Validation Loss: 0.1736, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.2921, Validation Loss: 0.1315, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.2501, Validation Loss: 0.1145, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.2208, Validation Loss: 0.1218, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.2368, Validation Loss: 0.1211, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.2592, Validation Loss: 0.1285, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.2095, Validation Loss: 0.1455, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.1993, Validation Loss: 0.1294, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.2561, Validation Loss: 0.1184, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.1966, Validation Loss: 0.1352, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.1949, Validation Loss: 0.1243, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.2033, Validation Loss: 0.1187, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.1836, Validation Loss: 0.1412, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.2345, Validation Loss: 0.1613, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.1778, Validation Loss: 0.1355, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.1308, Validation Loss: 0.1038, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.1443, Validation Loss: 0.0965, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.1386, Validation Loss: 0.0927, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.0983, Validation Loss: 0.0862, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.0981, Validation Loss: 0.0894, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.1268, Validation Loss: 0.0898, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.1004, Validation Loss: 0.0844, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.0881, Validation Loss: 0.0874, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.0740, Validation Loss: 0.0820, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.0791, Validation Loss: 0.0807, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.0938, Validation Loss: 0.0791, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.0865, Validation Loss: 0.0763, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.0661, Validation Loss: 0.0767, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.0636, Validation Loss: 0.0828, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.0954, Validation Loss: 0.0826, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.0812, Validation Loss: 0.0816, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0678, Validation Loss: 0.0780, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.0795, Validation Loss: 0.0760, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.0694, Validation Loss: 0.0814, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0685, Validation Loss: 0.0835, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.0787, Validation Loss: 0.0821, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.0629, Validation Loss: 0.0811, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.0759, Validation Loss: 0.0807, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.0755, Validation Loss: 0.0844, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.0987, Validation Loss: 0.0827, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 94, Training Loss: 0.0648, Validation Loss: 0.0785, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 95, Training Loss: 0.0579, Validation Loss: 0.0822, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 96, Training Loss: 0.0633, Validation Loss: 0.0792, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 97, Training Loss: 0.0645, Validation Loss: 0.0796, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 98, Training Loss: 0.0666, Validation Loss: 0.0863, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 99, Training Loss: 0.0673, Validation Loss: 0.0839, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 100, Training Loss: 0.0463, Validation Loss: 0.0787, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Running attention_removed classification training with alpha = 0.8 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.4467, Validation Loss: 2.5410, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 2.3696, Validation Loss: 1.6454, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.8681, Validation Loss: 1.3553, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.6264, Validation Loss: 1.1674, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.3832, Validation Loss: 0.9629, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.2406, Validation Loss: 0.8241, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.1049, Validation Loss: 0.6614, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.0089, Validation Loss: 0.6167, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.9716, Validation Loss: 0.6491, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.8971, Validation Loss: 0.5543, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.7784, Validation Loss: 0.4367, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.6838, Validation Loss: 0.3735, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.6865, Validation Loss: 0.3598, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.6345, Validation Loss: 0.2984, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.5840, Validation Loss: 0.3032, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.4922, Validation Loss: 0.2590, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.5366, Validation Loss: 0.3305, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.4668, Validation Loss: 0.2775, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.4205, Validation Loss: 0.2128, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.4179, Validation Loss: 0.2026, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.4136, Validation Loss: 0.2713, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.4827, Validation Loss: 0.2068, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.4619, Validation Loss: 0.1797, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.3718, Validation Loss: 0.1792, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.3788, Validation Loss: 0.1767, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.3584, Validation Loss: 0.2308, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.3514, Validation Loss: 0.1700, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.3105, Validation Loss: 0.1770, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.3530, Validation Loss: 0.2181, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.3756, Validation Loss: 0.2243, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.3427, Validation Loss: 0.2213, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.3057, Validation Loss: 0.1259, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.2853, Validation Loss: 0.1468, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.3043, Validation Loss: 0.1232, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.2572, Validation Loss: 0.1057, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.2285, Validation Loss: 0.1809, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.2359, Validation Loss: 0.1312, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.2840, Validation Loss: 0.1918, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.2861, Validation Loss: 0.1388, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.3191, Validation Loss: 0.1457, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.2297, Validation Loss: 0.1627, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.2539, Validation Loss: 0.1117, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.2236, Validation Loss: 0.1216, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.2385, Validation Loss: 0.1317, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.2382, Validation Loss: 0.1642, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.2649, Validation Loss: 0.1268, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.1988, Validation Loss: 0.1130, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.1468, Validation Loss: 0.0937, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.1599, Validation Loss: 0.0925, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.1353, Validation Loss: 0.0910, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.1407, Validation Loss: 0.0826, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.1327, Validation Loss: 0.0823, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.1309, Validation Loss: 0.0847, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.1171, Validation Loss: 0.0877, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.1393, Validation Loss: 0.0859, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.1249, Validation Loss: 0.0789, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.1136, Validation Loss: 0.0806, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.1206, Validation Loss: 0.0760, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.0970, Validation Loss: 0.0742, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.1028, Validation Loss: 0.0800, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.1144, Validation Loss: 0.0824, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.1232, Validation Loss: 0.0934, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.1101, Validation Loss: 0.0796, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.0918, Validation Loss: 0.0787, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.0894, Validation Loss: 0.0735, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.1224, Validation Loss: 0.0757, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.1110, Validation Loss: 0.0841, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.1026, Validation Loss: 0.0853, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.0916, Validation Loss: 0.0747, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.0755, Validation Loss: 0.0730, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.1165, Validation Loss: 0.0716, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.0883, Validation Loss: 0.0740, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.0886, Validation Loss: 0.0755, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.0775, Validation Loss: 0.0718, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.0869, Validation Loss: 0.0811, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.0819, Validation Loss: 0.0747, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.1057, Validation Loss: 0.0734, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.0748, Validation Loss: 0.0754, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.0897, Validation Loss: 0.0793, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.0671, Validation Loss: 0.0817, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.0781, Validation Loss: 0.0721, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.0775, Validation Loss: 0.0708, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.0684, Validation Loss: 0.0715, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.0789, Validation Loss: 0.0740, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.0813, Validation Loss: 0.0797, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.0719, Validation Loss: 0.0806, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.0721, Validation Loss: 0.0808, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.0766, Validation Loss: 0.0703, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.0775, Validation Loss: 0.0731, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.0650, Validation Loss: 0.0778, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.0723, Validation Loss: 0.0770, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.0630, Validation Loss: 0.0730, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.0755, Validation Loss: 0.0739, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.0706, Validation Loss: 0.0689, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.0717, Validation Loss: 0.0698, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.0795, Validation Loss: 0.0775, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.0727, Validation Loss: 0.0762, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 98, Training Loss: 0.0650, Validation Loss: 0.0755, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 99, Training Loss: 0.0845, Validation Loss: 0.0779, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 100, Training Loss: 0.0533, Validation Loss: 0.0750, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Running attention_removed classification training with alpha = 1 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.2089, Validation Loss: 2.3572, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 2.1928, Validation Loss: 1.5700, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.7668, Validation Loss: 1.3302, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.5351, Validation Loss: 1.1607, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.3722, Validation Loss: 0.9837, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.2011, Validation Loss: 0.8119, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 1.0708, Validation Loss: 0.6766, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.9902, Validation Loss: 0.7742, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.9745, Validation Loss: 0.6069, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.8599, Validation Loss: 0.4673, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.7943, Validation Loss: 0.6213, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.7936, Validation Loss: 0.4149, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.6918, Validation Loss: 0.3578, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.5879, Validation Loss: 0.3663, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.6251, Validation Loss: 0.2961, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.5340, Validation Loss: 0.2691, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.5682, Validation Loss: 0.2877, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.5613, Validation Loss: 0.2659, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.4916, Validation Loss: 0.2241, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.4720, Validation Loss: 0.2107, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.3947, Validation Loss: 0.2096, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.4262, Validation Loss: 0.2056, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.4840, Validation Loss: 0.2669, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.4719, Validation Loss: 0.1831, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.3806, Validation Loss: 0.2281, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.4297, Validation Loss: 0.1614, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.3984, Validation Loss: 0.1671, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.3699, Validation Loss: 0.2062, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.3440, Validation Loss: 0.1914, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.3261, Validation Loss: 0.1536, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.3292, Validation Loss: 0.1652, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.2816, Validation Loss: 0.1232, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.3117, Validation Loss: 0.1474, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.3329, Validation Loss: 0.3039, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.3689, Validation Loss: 0.1177, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.2975, Validation Loss: 0.1144, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.2964, Validation Loss: 0.1533, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.2619, Validation Loss: 0.0999, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.2623, Validation Loss: 0.0934, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.2544, Validation Loss: 0.1328, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.2475, Validation Loss: 0.1096, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.2400, Validation Loss: 0.1561, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.2209, Validation Loss: 0.1054, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.1930, Validation Loss: 0.1037, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.2392, Validation Loss: 0.1729, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.2696, Validation Loss: 0.0861, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.2360, Validation Loss: 0.1193, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.2220, Validation Loss: 0.1622, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.2051, Validation Loss: 0.1270, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.1842, Validation Loss: 0.0777, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.1784, Validation Loss: 0.1172, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.1625, Validation Loss: 0.0719, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.1598, Validation Loss: 0.1039, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.1788, Validation Loss: 0.1042, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.2166, Validation Loss: 0.1433, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.1732, Validation Loss: 0.0808, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.1662, Validation Loss: 0.0990, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.1957, Validation Loss: 0.1225, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.2053, Validation Loss: 0.0973, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.1918, Validation Loss: 0.0920, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.1826, Validation Loss: 0.0898, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.1792, Validation Loss: 0.0819, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.2331, Validation Loss: 0.1001, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.1574, Validation Loss: 0.0926, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.1254, Validation Loss: 0.0717, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.1007, Validation Loss: 0.0592, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.0937, Validation Loss: 0.0600, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.1058, Validation Loss: 0.0603, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.0907, Validation Loss: 0.0628, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.0926, Validation Loss: 0.0655, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.1009, Validation Loss: 0.0594, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.0743, Validation Loss: 0.0577, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.0909, Validation Loss: 0.0569, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.0972, Validation Loss: 0.0588, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.0808, Validation Loss: 0.0568, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.0804, Validation Loss: 0.0575, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.0752, Validation Loss: 0.0601, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.0802, Validation Loss: 0.0580, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.0735, Validation Loss: 0.0591, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.1005, Validation Loss: 0.0605, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.0767, Validation Loss: 0.0609, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.0646, Validation Loss: 0.0552, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.0940, Validation Loss: 0.0563, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.0575, Validation Loss: 0.0576, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0618, Validation Loss: 0.0594, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.0677, Validation Loss: 0.0607, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.0617, Validation Loss: 0.0614, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.0686, Validation Loss: 0.0635, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.0607, Validation Loss: 0.0640, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.0784, Validation Loss: 0.0612, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.0573, Validation Loss: 0.0613, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.0556, Validation Loss: 0.0626, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.0816, Validation Loss: 0.0597, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.0529, Validation Loss: 0.0592, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.0495, Validation Loss: 0.0604, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.0618, Validation Loss: 0.0571, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.0549, Validation Loss: 0.0597, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.0683, Validation Loss: 0.0610, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.0571, Validation Loss: 0.0627, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.0622, Validation Loss: 0.0594, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running remove_features experiments:
Running remove_features classification training with alpha = 0 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 7.3379, Validation Loss: 7.4915, Alpha: 0.0000
Epoch: 2, Training Loss: 5.7607, Validation Loss: 4.7060, Alpha: 0.0000
Epoch: 3, Training Loss: 4.9278, Validation Loss: 4.5689, Alpha: 0.0000
Epoch: 4, Training Loss: 4.2217, Validation Loss: 3.7384, Alpha: 0.0000
Epoch: 5, Training Loss: 3.7926, Validation Loss: 3.2091, Alpha: 0.0000
Epoch: 6, Training Loss: 3.4969, Validation Loss: 3.6491, Alpha: 0.0000
Epoch: 7, Training Loss: 3.1216, Validation Loss: 2.6292, Alpha: 0.0000
Epoch: 8, Training Loss: 2.8876, Validation Loss: 2.4482, Alpha: 0.0000
Epoch: 9, Training Loss: 2.6822, Validation Loss: 2.4835, Alpha: 0.0000
Epoch: 10, Training Loss: 2.6792, Validation Loss: 2.2612, Alpha: 0.0000
Epoch: 11, Training Loss: 2.4367, Validation Loss: 2.3099, Alpha: 0.0000
Epoch: 12, Training Loss: 2.3363, Validation Loss: 2.2682, Alpha: 0.0000
Epoch: 13, Training Loss: 2.1385, Validation Loss: 1.8995, Alpha: 0.0000
Epoch: 14, Training Loss: 2.1460, Validation Loss: 2.2146, Alpha: 0.0000
Epoch: 15, Training Loss: 1.9654, Validation Loss: 1.7966, Alpha: 0.0000
Epoch: 16, Training Loss: 1.8502, Validation Loss: 2.7833, Alpha: 0.0000
Epoch: 17, Training Loss: 1.8291, Validation Loss: 1.6045, Alpha: 0.0000
Epoch: 18, Training Loss: 1.8188, Validation Loss: 1.5860, Alpha: 0.0000
Epoch: 19, Training Loss: 1.6849, Validation Loss: 1.6865, Alpha: 0.0000
Epoch: 20, Training Loss: 1.6573, Validation Loss: 2.9810, Alpha: 0.0000
Epoch: 21, Training Loss: 1.5562, Validation Loss: 1.5451, Alpha: 0.0000
Epoch: 22, Training Loss: 1.4631, Validation Loss: 1.6878, Alpha: 0.0000
Epoch: 23, Training Loss: 1.4045, Validation Loss: 1.3863, Alpha: 0.0000
Epoch: 24, Training Loss: 1.4405, Validation Loss: 1.1764, Alpha: 0.0000
Epoch: 25, Training Loss: 1.3560, Validation Loss: 1.1671, Alpha: 0.0000
Epoch: 26, Training Loss: 1.3633, Validation Loss: 1.1474, Alpha: 0.0000
Epoch: 27, Training Loss: 1.2317, Validation Loss: 1.4840, Alpha: 0.0000
Epoch: 28, Training Loss: 1.0840, Validation Loss: 1.1991, Alpha: 0.0000
Epoch: 29, Training Loss: 1.0422, Validation Loss: 1.3403, Alpha: 0.0000
Epoch: 30, Training Loss: 1.0631, Validation Loss: 1.8770, Alpha: 0.0000
Epoch: 31, Training Loss: 1.0625, Validation Loss: 1.2874, Alpha: 0.0000
Epoch: 32, Training Loss: 1.0491, Validation Loss: 1.3319, Alpha: 0.0000
Epoch: 33, Training Loss: 0.9391, Validation Loss: 1.7802, Alpha: 0.0000
Epoch: 34, Training Loss: 0.9740, Validation Loss: 1.0451, Alpha: 0.0000
Epoch: 35, Training Loss: 0.9296, Validation Loss: 2.1267, Alpha: 0.0000
Epoch: 36, Training Loss: 0.8488, Validation Loss: 1.6095, Alpha: 0.0000
Epoch: 37, Training Loss: 0.9289, Validation Loss: 1.1395, Alpha: 0.0000
Epoch: 38, Training Loss: 0.9142, Validation Loss: 1.3488, Alpha: 0.0000
Epoch: 39, Training Loss: 0.8995, Validation Loss: 1.0155, Alpha: 0.0000
Epoch: 40, Training Loss: 0.8542, Validation Loss: 0.9402, Alpha: 0.0000
Epoch: 41, Training Loss: 0.8955, Validation Loss: 1.0770, Alpha: 0.0000
Epoch: 42, Training Loss: 0.8406, Validation Loss: 1.6810, Alpha: 0.0000
Epoch: 43, Training Loss: 0.7012, Validation Loss: 1.2519, Alpha: 0.0000
Epoch: 44, Training Loss: 0.6865, Validation Loss: 1.1937, Alpha: 0.0000
Epoch: 45, Training Loss: 0.6748, Validation Loss: 1.1074, Alpha: 0.0000
Epoch: 46, Training Loss: 0.5763, Validation Loss: 0.8842, Alpha: 0.0000
Epoch: 47, Training Loss: 0.6290, Validation Loss: 0.9499, Alpha: 0.0000
Epoch: 48, Training Loss: 0.7302, Validation Loss: 1.3225, Alpha: 0.0000
Epoch: 49, Training Loss: 0.6053, Validation Loss: 1.0506, Alpha: 0.0000
Epoch: 50, Training Loss: 0.6236, Validation Loss: 0.8278, Alpha: 0.0000
Epoch: 51, Training Loss: 0.4995, Validation Loss: 1.6311, Alpha: 0.0000
Epoch: 52, Training Loss: 0.5443, Validation Loss: 1.0504, Alpha: 0.0000
Epoch: 53, Training Loss: 0.5889, Validation Loss: 0.9143, Alpha: 0.0000
Epoch: 54, Training Loss: 0.4822, Validation Loss: 1.3176, Alpha: 0.0000
Epoch: 55, Training Loss: 0.5788, Validation Loss: 0.8715, Alpha: 0.0000
Epoch: 56, Training Loss: 0.5273, Validation Loss: 0.8578, Alpha: 0.0000
Epoch: 57, Training Loss: 0.5231, Validation Loss: 2.5704, Alpha: 0.0000
Epoch: 58, Training Loss: 0.4626, Validation Loss: 1.1247, Alpha: 0.0000
Epoch: 59, Training Loss: 0.5104, Validation Loss: 0.8609, Alpha: 0.0000
Epoch: 60, Training Loss: 0.5165, Validation Loss: 0.8925, Alpha: 0.0000
Epoch: 61, Training Loss: 0.4723, Validation Loss: 0.9290, Alpha: 0.0000
Epoch: 62, Training Loss: 0.3746, Validation Loss: 0.6717, Alpha: 0.0000
Epoch: 63, Training Loss: 0.2636, Validation Loss: 0.6176, Alpha: 0.0000
Epoch: 64, Training Loss: 0.2331, Validation Loss: 0.6097, Alpha: 0.0000
Epoch: 65, Training Loss: 0.2281, Validation Loss: 0.5994, Alpha: 0.0000
Epoch: 66, Training Loss: 0.1990, Validation Loss: 0.6067, Alpha: 0.0000
Epoch: 67, Training Loss: 0.1820, Validation Loss: 0.5805, Alpha: 0.0000
Epoch: 68, Training Loss: 0.1797, Validation Loss: 0.5852, Alpha: 0.0000
Epoch: 69, Training Loss: 0.1818, Validation Loss: 0.6226, Alpha: 0.0000
Epoch: 70, Training Loss: 0.1582, Validation Loss: 0.5876, Alpha: 0.0000
Epoch: 71, Training Loss: 0.1646, Validation Loss: 0.5819, Alpha: 0.0000
Epoch: 72, Training Loss: 0.1684, Validation Loss: 0.6201, Alpha: 0.0000
Epoch: 73, Training Loss: 0.1404, Validation Loss: 0.6258, Alpha: 0.0000
Epoch: 74, Training Loss: 0.1371, Validation Loss: 0.6088, Alpha: 0.0000
Epoch: 75, Training Loss: 0.1350, Validation Loss: 0.5857, Alpha: 0.0000
Epoch: 76, Training Loss: 0.1275, Validation Loss: 0.5989, Alpha: 0.0000
Epoch: 77, Training Loss: 0.1507, Validation Loss: 0.6024, Alpha: 0.0000
Epoch: 78, Training Loss: 0.1291, Validation Loss: 0.5910, Alpha: 0.0000
Epoch: 79, Training Loss: 0.1355, Validation Loss: 0.6105, Alpha: 0.0000
Epoch: 80, Training Loss: 0.1272, Validation Loss: 0.5933, Alpha: 0.0000
Epoch: 81, Training Loss: 0.1283, Validation Loss: 0.5809, Alpha: 0.0000
Epoch: 82, Training Loss: 0.1421, Validation Loss: 0.5902, Alpha: 0.0000
Epoch: 83, Training Loss: 0.1079, Validation Loss: 0.5883, Alpha: 0.0000
Epoch: 84, Training Loss: 0.1270, Validation Loss: 0.5767, Alpha: 0.0000
Epoch: 85, Training Loss: 0.1069, Validation Loss: 0.5836, Alpha: 0.0000
Epoch: 86, Training Loss: 0.1287, Validation Loss: 0.5791, Alpha: 0.0000
Epoch: 87, Training Loss: 0.1356, Validation Loss: 0.5718, Alpha: 0.0000
Epoch: 88, Training Loss: 0.1261, Validation Loss: 0.5748, Alpha: 0.0000
Epoch: 89, Training Loss: 0.1030, Validation Loss: 0.5738, Alpha: 0.0000
Epoch: 90, Training Loss: 0.1036, Validation Loss: 0.5748, Alpha: 0.0000
Epoch: 91, Training Loss: 0.1123, Validation Loss: 0.5692, Alpha: 0.0000
Epoch: 92, Training Loss: 0.1135, Validation Loss: 0.5843, Alpha: 0.0000
Epoch: 93, Training Loss: 0.1545, Validation Loss: 0.5826, Alpha: 0.0000
Epoch: 94, Training Loss: 0.1154, Validation Loss: 0.5739, Alpha: 0.0000
Epoch: 95, Training Loss: 0.1154, Validation Loss: 0.5697, Alpha: 0.0000
Epoch: 96, Training Loss: 0.0996, Validation Loss: 0.5718, Alpha: 0.0000
Epoch: 97, Training Loss: 0.0970, Validation Loss: 0.5712, Alpha: 0.0000
Epoch: 98, Training Loss: 0.1125, Validation Loss: 0.5734, Alpha: 0.0000
Epoch: 99, Training Loss: 0.1162, Validation Loss: 0.5700, Alpha: 0.0000
Epoch: 100, Training Loss: 0.1339, Validation Loss: 0.5811, Alpha: 0.0000
Running remove_features classification training with alpha = 0.2 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.0857, Validation Loss: 6.1662, Alpha: 0.2000
Epoch: 2, Training Loss: 4.8999, Validation Loss: 4.1927, Alpha: 0.2000
Epoch: 3, Training Loss: 4.2252, Validation Loss: 3.7828, Alpha: 0.2000
Epoch: 4, Training Loss: 3.7870, Validation Loss: 3.4057, Alpha: 0.2000
Epoch: 5, Training Loss: 3.4537, Validation Loss: 2.8914, Alpha: 0.2000
Epoch: 6, Training Loss: 3.1733, Validation Loss: 2.6701, Alpha: 0.2000
Epoch: 7, Training Loss: 3.0051, Validation Loss: 2.4670, Alpha: 0.2000
Epoch: 8, Training Loss: 2.7660, Validation Loss: 2.4114, Alpha: 0.2000
Epoch: 9, Training Loss: 2.6116, Validation Loss: 2.1699, Alpha: 0.2000
Epoch: 10, Training Loss: 2.4613, Validation Loss: 2.0678, Alpha: 0.2000
Epoch: 11, Training Loss: 2.3364, Validation Loss: 1.9590, Alpha: 0.2000
Epoch: 12, Training Loss: 2.2446, Validation Loss: 1.9399, Alpha: 0.2000
Epoch: 13, Training Loss: 2.1698, Validation Loss: 1.8967, Alpha: 0.2000
Epoch: 14, Training Loss: 2.0789, Validation Loss: 1.9399, Alpha: 0.2000
Epoch: 15, Training Loss: 1.9601, Validation Loss: 1.6178, Alpha: 0.2000
Epoch: 16, Training Loss: 1.8273, Validation Loss: 1.6328, Alpha: 0.2000
Epoch: 17, Training Loss: 1.7737, Validation Loss: 1.8157, Alpha: 0.2000
Epoch: 18, Training Loss: 1.7460, Validation Loss: 1.5880, Alpha: 0.2000
Epoch: 19, Training Loss: 1.6502, Validation Loss: 1.4856, Alpha: 0.2000
Epoch: 20, Training Loss: 1.5130, Validation Loss: 1.3183, Alpha: 0.2000
Epoch: 21, Training Loss: 1.4170, Validation Loss: 1.2909, Alpha: 0.2000
Epoch: 22, Training Loss: 1.4307, Validation Loss: 1.4341, Alpha: 0.2000
Epoch: 23, Training Loss: 1.3552, Validation Loss: 1.1706, Alpha: 0.2000
Epoch: 24, Training Loss: 1.3424, Validation Loss: 1.2667, Alpha: 0.2000
Epoch: 25, Training Loss: 1.3146, Validation Loss: 1.2959, Alpha: 0.2000
Epoch: 26, Training Loss: 1.2976, Validation Loss: 1.1084, Alpha: 0.2000
Epoch: 27, Training Loss: 1.1679, Validation Loss: 1.4016, Alpha: 0.2000
Epoch: 28, Training Loss: 1.1044, Validation Loss: 1.0025, Alpha: 0.2000
Epoch: 29, Training Loss: 1.1338, Validation Loss: 1.0830, Alpha: 0.2000
Epoch: 30, Training Loss: 1.1003, Validation Loss: 0.9553, Alpha: 0.2000
Epoch: 31, Training Loss: 0.9495, Validation Loss: 1.0502, Alpha: 0.2000
Epoch: 32, Training Loss: 1.0168, Validation Loss: 1.0200, Alpha: 0.2000
Epoch: 33, Training Loss: 0.9684, Validation Loss: 0.9960, Alpha: 0.2000
Epoch: 34, Training Loss: 0.8780, Validation Loss: 1.2123, Alpha: 0.2000
Epoch: 35, Training Loss: 0.9954, Validation Loss: 1.7327, Alpha: 0.2000
Epoch: 36, Training Loss: 0.9479, Validation Loss: 0.9298, Alpha: 0.2000
Epoch: 37, Training Loss: 0.9136, Validation Loss: 0.9700, Alpha: 0.2000
Epoch: 38, Training Loss: 0.8529, Validation Loss: 0.9606, Alpha: 0.2000
Epoch: 39, Training Loss: 0.8220, Validation Loss: 0.9569, Alpha: 0.2000
Epoch: 40, Training Loss: 0.9000, Validation Loss: 1.0488, Alpha: 0.2000
Epoch: 41, Training Loss: 0.8533, Validation Loss: 1.0283, Alpha: 0.2000
Epoch: 42, Training Loss: 0.8166, Validation Loss: 0.9235, Alpha: 0.2000
Epoch: 43, Training Loss: 0.7742, Validation Loss: 0.8842, Alpha: 0.2000
Epoch: 44, Training Loss: 0.7087, Validation Loss: 0.8328, Alpha: 0.2000
Epoch: 45, Training Loss: 0.6765, Validation Loss: 1.0192, Alpha: 0.2000
Epoch: 46, Training Loss: 0.7402, Validation Loss: 1.1246, Alpha: 0.2000
Epoch: 47, Training Loss: 0.6188, Validation Loss: 0.7436, Alpha: 0.2000
Epoch: 48, Training Loss: 0.5911, Validation Loss: 0.7203, Alpha: 0.2000
Epoch: 49, Training Loss: 0.5776, Validation Loss: 0.8230, Alpha: 0.2000
Epoch: 50, Training Loss: 0.5290, Validation Loss: 0.8623, Alpha: 0.2000
Epoch: 51, Training Loss: 0.5146, Validation Loss: 0.6966, Alpha: 0.2000
Epoch: 52, Training Loss: 0.5593, Validation Loss: 0.7594, Alpha: 0.2000
Epoch: 53, Training Loss: 0.5457, Validation Loss: 0.8047, Alpha: 0.2000
Epoch: 54, Training Loss: 0.5293, Validation Loss: 0.8223, Alpha: 0.2000
Epoch: 55, Training Loss: 0.4997, Validation Loss: 0.9096, Alpha: 0.2000
Epoch: 56, Training Loss: 0.4820, Validation Loss: 0.7612, Alpha: 0.2000
Epoch: 57, Training Loss: 0.4437, Validation Loss: 0.8628, Alpha: 0.2000
Epoch: 58, Training Loss: 0.6236, Validation Loss: 0.7926, Alpha: 0.2000
Epoch: 59, Training Loss: 0.4932, Validation Loss: 0.7802, Alpha: 0.2000
Epoch: 60, Training Loss: 0.4545, Validation Loss: 0.9031, Alpha: 0.2000
Epoch: 61, Training Loss: 0.4538, Validation Loss: 0.7218, Alpha: 0.2000
Epoch: 62, Training Loss: 0.4268, Validation Loss: 0.7303, Alpha: 0.2000
Epoch: 63, Training Loss: 0.3288, Validation Loss: 0.5594, Alpha: 0.2000
Epoch: 64, Training Loss: 0.2746, Validation Loss: 0.5399, Alpha: 0.2000
Epoch: 65, Training Loss: 0.2367, Validation Loss: 0.5178, Alpha: 0.2000
Epoch: 66, Training Loss: 0.1899, Validation Loss: 0.5031, Alpha: 0.2000
Epoch: 67, Training Loss: 0.2552, Validation Loss: 0.5145, Alpha: 0.2000
Epoch: 68, Training Loss: 0.2041, Validation Loss: 0.5154, Alpha: 0.2000
Epoch: 69, Training Loss: 0.1921, Validation Loss: 0.4897, Alpha: 0.2000
Epoch: 70, Training Loss: 0.1752, Validation Loss: 0.5029, Alpha: 0.2000
Epoch: 71, Training Loss: 0.1644, Validation Loss: 0.5198, Alpha: 0.2000
Epoch: 72, Training Loss: 0.1557, Validation Loss: 0.5167, Alpha: 0.2000
Epoch: 73, Training Loss: 0.1595, Validation Loss: 0.4932, Alpha: 0.2000
Epoch: 74, Training Loss: 0.1758, Validation Loss: 0.5083, Alpha: 0.2000
Epoch: 75, Training Loss: 0.1281, Validation Loss: 0.4794, Alpha: 0.2000
Epoch: 76, Training Loss: 0.1400, Validation Loss: 0.5357, Alpha: 0.2000
Epoch: 77, Training Loss: 0.1503, Validation Loss: 0.4899, Alpha: 0.2000
Epoch: 78, Training Loss: 0.1403, Validation Loss: 0.4750, Alpha: 0.2000
Epoch: 79, Training Loss: 0.1183, Validation Loss: 0.4760, Alpha: 0.2000
Epoch: 80, Training Loss: 0.1442, Validation Loss: 0.4919, Alpha: 0.2000
Epoch: 81, Training Loss: 0.1446, Validation Loss: 0.4981, Alpha: 0.2000
Epoch: 82, Training Loss: 0.1271, Validation Loss: 0.4995, Alpha: 0.2000
Epoch: 83, Training Loss: 0.1278, Validation Loss: 0.5001, Alpha: 0.2000
Epoch: 84, Training Loss: 0.1280, Validation Loss: 0.4955, Alpha: 0.2000
Epoch: 85, Training Loss: 0.1089, Validation Loss: 0.5003, Alpha: 0.2000
Epoch: 86, Training Loss: 0.1169, Validation Loss: 0.5319, Alpha: 0.2000
Epoch: 87, Training Loss: 0.1181, Validation Loss: 0.5201, Alpha: 0.2000
Epoch: 88, Training Loss: 0.1393, Validation Loss: 0.5141, Alpha: 0.2000
Epoch: 89, Training Loss: 0.1111, Validation Loss: 0.5252, Alpha: 0.2000
Epoch: 90, Training Loss: 0.1103, Validation Loss: 0.5196, Alpha: 0.2000
Epoch: 91, Training Loss: 0.1030, Validation Loss: 0.5092, Alpha: 0.2000
Epoch: 92, Training Loss: 0.0930, Validation Loss: 0.4995, Alpha: 0.2000
Epoch: 93, Training Loss: 0.0910, Validation Loss: 0.4870, Alpha: 0.2000
Epoch: 94, Training Loss: 0.1083, Validation Loss: 0.4867, Alpha: 0.2000
Epoch: 95, Training Loss: 0.1217, Validation Loss: 0.4797, Alpha: 0.2000
Epoch: 96, Training Loss: 0.0965, Validation Loss: 0.4821, Alpha: 0.2000
Epoch: 97, Training Loss: 0.0945, Validation Loss: 0.4832, Alpha: 0.2000
Epoch: 98, Training Loss: 0.1017, Validation Loss: 0.4813, Alpha: 0.2000
Early stopping triggered.
Running remove_features classification training with alpha = 0.5 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.8351, Validation Loss: 4.9095, Alpha: 0.5000
Epoch: 2, Training Loss: 4.1107, Validation Loss: 3.5211, Alpha: 0.5000
Epoch: 3, Training Loss: 3.5378, Validation Loss: 2.9937, Alpha: 0.5000
Epoch: 4, Training Loss: 3.2159, Validation Loss: 2.7777, Alpha: 0.5000
Epoch: 5, Training Loss: 2.9185, Validation Loss: 2.4827, Alpha: 0.5000
Epoch: 6, Training Loss: 2.7255, Validation Loss: 2.4697, Alpha: 0.5000
Epoch: 7, Training Loss: 2.5315, Validation Loss: 2.2398, Alpha: 0.5000
Epoch: 8, Training Loss: 2.3924, Validation Loss: 1.9913, Alpha: 0.5000
Epoch: 9, Training Loss: 2.2231, Validation Loss: 2.0758, Alpha: 0.5000
Epoch: 10, Training Loss: 2.0150, Validation Loss: 1.6294, Alpha: 0.5000
Epoch: 11, Training Loss: 1.8891, Validation Loss: 1.8295, Alpha: 0.5000
Epoch: 12, Training Loss: 1.7904, Validation Loss: 1.6701, Alpha: 0.5000
Epoch: 13, Training Loss: 1.6742, Validation Loss: 1.3641, Alpha: 0.5000
Epoch: 14, Training Loss: 1.5956, Validation Loss: 1.4879, Alpha: 0.5000
Epoch: 15, Training Loss: 1.5496, Validation Loss: 1.3133, Alpha: 0.5000
Epoch: 16, Training Loss: 1.4615, Validation Loss: 1.3336, Alpha: 0.5000
Epoch: 17, Training Loss: 1.3223, Validation Loss: 1.2380, Alpha: 0.5000
Epoch: 18, Training Loss: 1.3352, Validation Loss: 1.1145, Alpha: 0.5000
Epoch: 19, Training Loss: 1.2242, Validation Loss: 1.0154, Alpha: 0.5000
Epoch: 20, Training Loss: 1.2418, Validation Loss: 1.2923, Alpha: 0.5000
Epoch: 21, Training Loss: 1.1020, Validation Loss: 0.8791, Alpha: 0.5000
Epoch: 22, Training Loss: 1.1040, Validation Loss: 0.8763, Alpha: 0.5000
Epoch: 23, Training Loss: 1.0092, Validation Loss: 1.0046, Alpha: 0.5000
Epoch: 24, Training Loss: 1.0417, Validation Loss: 1.2303, Alpha: 0.5000
Epoch: 25, Training Loss: 0.9607, Validation Loss: 0.8542, Alpha: 0.5000
Epoch: 26, Training Loss: 0.8979, Validation Loss: 0.7334, Alpha: 0.5000
Epoch: 27, Training Loss: 0.8994, Validation Loss: 0.7413, Alpha: 0.5000
Epoch: 28, Training Loss: 0.8354, Validation Loss: 0.8123, Alpha: 0.5000
Epoch: 29, Training Loss: 0.8802, Validation Loss: 0.7256, Alpha: 0.5000
Epoch: 30, Training Loss: 0.7418, Validation Loss: 0.8302, Alpha: 0.5000
Epoch: 31, Training Loss: 0.7114, Validation Loss: 0.6253, Alpha: 0.5000
Epoch: 32, Training Loss: 0.7231, Validation Loss: 0.6748, Alpha: 0.5000
Epoch: 33, Training Loss: 0.7366, Validation Loss: 0.6756, Alpha: 0.5000
Epoch: 34, Training Loss: 0.6832, Validation Loss: 0.6481, Alpha: 0.5000
Epoch: 35, Training Loss: 0.5702, Validation Loss: 0.5926, Alpha: 0.5000
Epoch: 36, Training Loss: 0.5852, Validation Loss: 0.5556, Alpha: 0.5000
Epoch: 37, Training Loss: 0.5792, Validation Loss: 0.8482, Alpha: 0.5000
Epoch: 38, Training Loss: 0.5668, Validation Loss: 0.7249, Alpha: 0.5000
Epoch: 39, Training Loss: 0.5568, Validation Loss: 0.6043, Alpha: 0.5000
Epoch: 40, Training Loss: 0.5320, Validation Loss: 0.6863, Alpha: 0.5000
Epoch: 41, Training Loss: 0.5535, Validation Loss: 0.6997, Alpha: 0.5000
Epoch: 42, Training Loss: 0.4814, Validation Loss: 0.5557, Alpha: 0.5000
Epoch: 43, Training Loss: 0.5110, Validation Loss: 0.7251, Alpha: 0.5000
Epoch: 44, Training Loss: 0.4708, Validation Loss: 0.5842, Alpha: 0.5000
Epoch: 45, Training Loss: 0.4892, Validation Loss: 0.5887, Alpha: 0.5000
Epoch: 46, Training Loss: 0.5367, Validation Loss: 0.7356, Alpha: 0.5000
Epoch: 47, Training Loss: 0.4466, Validation Loss: 0.5848, Alpha: 0.5000
Epoch: 48, Training Loss: 0.4161, Validation Loss: 0.4400, Alpha: 0.5000
Epoch: 49, Training Loss: 0.3064, Validation Loss: 0.3848, Alpha: 0.5000
Epoch: 50, Training Loss: 0.2817, Validation Loss: 0.3655, Alpha: 0.5000
Epoch: 51, Training Loss: 0.2765, Validation Loss: 0.3769, Alpha: 0.5000
Epoch: 52, Training Loss: 0.2378, Validation Loss: 0.3701, Alpha: 0.5000
Epoch: 53, Training Loss: 0.2440, Validation Loss: 0.3490, Alpha: 0.5000
Epoch: 54, Training Loss: 0.2338, Validation Loss: 0.3640, Alpha: 0.5000
Epoch: 55, Training Loss: 0.2304, Validation Loss: 0.3525, Alpha: 0.5000
Epoch: 56, Training Loss: 0.2013, Validation Loss: 0.3349, Alpha: 0.5000
Epoch: 57, Training Loss: 0.2019, Validation Loss: 0.3565, Alpha: 0.5000
Epoch: 58, Training Loss: 0.2130, Validation Loss: 0.3411, Alpha: 0.5000
Epoch: 59, Training Loss: 0.1876, Validation Loss: 0.3525, Alpha: 0.5000
Epoch: 60, Training Loss: 0.1684, Validation Loss: 0.3287, Alpha: 0.5000
Epoch: 61, Training Loss: 0.1644, Validation Loss: 0.3244, Alpha: 0.5000
Epoch: 62, Training Loss: 0.1718, Validation Loss: 0.3467, Alpha: 0.5000
Epoch: 63, Training Loss: 0.1437, Validation Loss: 0.3394, Alpha: 0.5000
Epoch: 64, Training Loss: 0.1492, Validation Loss: 0.3314, Alpha: 0.5000
Epoch: 65, Training Loss: 0.1598, Validation Loss: 0.3211, Alpha: 0.5000
Epoch: 66, Training Loss: 0.1316, Validation Loss: 0.3243, Alpha: 0.5000
Epoch: 67, Training Loss: 0.1469, Validation Loss: 0.3488, Alpha: 0.5000
Epoch: 68, Training Loss: 0.1507, Validation Loss: 0.3387, Alpha: 0.5000
Epoch: 69, Training Loss: 0.1535, Validation Loss: 0.3398, Alpha: 0.5000
Epoch: 70, Training Loss: 0.1502, Validation Loss: 0.3503, Alpha: 0.5000
Epoch: 71, Training Loss: 0.1240, Validation Loss: 0.3367, Alpha: 0.5000
Epoch: 72, Training Loss: 0.1154, Validation Loss: 0.3384, Alpha: 0.5000
Epoch: 73, Training Loss: 0.1223, Validation Loss: 0.3318, Alpha: 0.5000
Epoch: 74, Training Loss: 0.1216, Validation Loss: 0.3247, Alpha: 0.5000
Epoch: 75, Training Loss: 0.1373, Validation Loss: 0.3286, Alpha: 0.5000
Epoch: 76, Training Loss: 0.1117, Validation Loss: 0.3421, Alpha: 0.5000
Epoch: 77, Training Loss: 0.1191, Validation Loss: 0.3237, Alpha: 0.5000
Epoch: 78, Training Loss: 0.1090, Validation Loss: 0.3235, Alpha: 0.5000
Epoch: 79, Training Loss: 0.1256, Validation Loss: 0.3235, Alpha: 0.5000
Epoch: 80, Training Loss: 0.1104, Validation Loss: 0.3199, Alpha: 0.5000
Epoch: 81, Training Loss: 0.1045, Validation Loss: 0.3193, Alpha: 0.5000
Epoch: 82, Training Loss: 0.1034, Validation Loss: 0.3158, Alpha: 0.5000
Epoch: 83, Training Loss: 0.1130, Validation Loss: 0.3258, Alpha: 0.5000
Epoch: 84, Training Loss: 0.1052, Validation Loss: 0.3139, Alpha: 0.5000
Epoch: 85, Training Loss: 0.1034, Validation Loss: 0.3120, Alpha: 0.5000
Epoch: 86, Training Loss: 0.0999, Validation Loss: 0.3122, Alpha: 0.5000
Epoch: 87, Training Loss: 0.1043, Validation Loss: 0.3136, Alpha: 0.5000
Epoch: 88, Training Loss: 0.1163, Validation Loss: 0.3207, Alpha: 0.5000
Epoch: 89, Training Loss: 0.1335, Validation Loss: 0.3204, Alpha: 0.5000
Epoch: 90, Training Loss: 0.1316, Validation Loss: 0.3145, Alpha: 0.5000
Epoch: 91, Training Loss: 0.0958, Validation Loss: 0.3099, Alpha: 0.5000
Epoch: 92, Training Loss: 0.1140, Validation Loss: 0.3191, Alpha: 0.5000
Epoch: 93, Training Loss: 0.1165, Validation Loss: 0.3211, Alpha: 0.5000
Epoch: 94, Training Loss: 0.1031, Validation Loss: 0.3236, Alpha: 0.5000
Epoch: 95, Training Loss: 0.1088, Validation Loss: 0.3215, Alpha: 0.5000
Epoch: 96, Training Loss: 0.0987, Validation Loss: 0.3146, Alpha: 0.5000
Epoch: 97, Training Loss: 0.0907, Validation Loss: 0.3189, Alpha: 0.5000
Epoch: 98, Training Loss: 0.1084, Validation Loss: 0.3146, Alpha: 0.5000
Epoch: 99, Training Loss: 0.0983, Validation Loss: 0.3160, Alpha: 0.5000
Epoch: 100, Training Loss: 0.1063, Validation Loss: 0.3154, Alpha: 0.5000
Running remove_features classification training with alpha = 0.8 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.0069, Validation Loss: 4.0371, Alpha: 0.8000
Epoch: 2, Training Loss: 3.4145, Validation Loss: 2.8192, Alpha: 0.8000
Epoch: 3, Training Loss: 2.8549, Validation Loss: 3.4328, Alpha: 0.8000
Epoch: 4, Training Loss: 2.5648, Validation Loss: 2.1422, Alpha: 0.8000
Epoch: 5, Training Loss: 2.3871, Validation Loss: 2.2456, Alpha: 0.8000
Epoch: 6, Training Loss: 2.1347, Validation Loss: 1.9998, Alpha: 0.8000
Epoch: 7, Training Loss: 1.9820, Validation Loss: 1.6929, Alpha: 0.8000
Epoch: 8, Training Loss: 1.8228, Validation Loss: 1.6574, Alpha: 0.8000
Epoch: 9, Training Loss: 1.7224, Validation Loss: 1.5070, Alpha: 0.8000
Epoch: 10, Training Loss: 1.5758, Validation Loss: 1.4830, Alpha: 0.8000
Epoch: 11, Training Loss: 1.5062, Validation Loss: 1.3774, Alpha: 0.8000
Epoch: 12, Training Loss: 1.4457, Validation Loss: 1.2492, Alpha: 0.8000
Epoch: 13, Training Loss: 1.3750, Validation Loss: 1.1648, Alpha: 0.8000
Epoch: 14, Training Loss: 1.2982, Validation Loss: 1.2050, Alpha: 0.8000
Epoch: 15, Training Loss: 1.3109, Validation Loss: 1.1146, Alpha: 0.8000
Epoch: 16, Training Loss: 1.2440, Validation Loss: 1.0807, Alpha: 0.8000
Epoch: 17, Training Loss: 1.1357, Validation Loss: 0.9887, Alpha: 0.8000
Epoch: 18, Training Loss: 1.0699, Validation Loss: 1.1126, Alpha: 0.8000
Epoch: 19, Training Loss: 1.0541, Validation Loss: 0.8336, Alpha: 0.8000
Epoch: 20, Training Loss: 1.0139, Validation Loss: 0.8883, Alpha: 0.8000
Epoch: 21, Training Loss: 1.0180, Validation Loss: 0.8393, Alpha: 0.8000
Epoch: 22, Training Loss: 0.9137, Validation Loss: 1.1985, Alpha: 0.8000
Epoch: 23, Training Loss: 0.8444, Validation Loss: 0.7643, Alpha: 0.8000
Epoch: 24, Training Loss: 0.9100, Validation Loss: 1.1254, Alpha: 0.8000
Epoch: 25, Training Loss: 0.8300, Validation Loss: 0.8841, Alpha: 0.8000
Epoch: 26, Training Loss: 0.8504, Validation Loss: 0.7432, Alpha: 0.8000
Epoch: 27, Training Loss: 0.7429, Validation Loss: 0.6262, Alpha: 0.8000
Epoch: 28, Training Loss: 0.7693, Validation Loss: 0.7010, Alpha: 0.8000
Epoch: 29, Training Loss: 0.7997, Validation Loss: 0.9565, Alpha: 0.8000
Epoch: 30, Training Loss: 0.7411, Validation Loss: 1.3164, Alpha: 0.8000
Epoch: 31, Training Loss: 0.6781, Validation Loss: 0.6321, Alpha: 0.8000
Epoch: 32, Training Loss: 0.6878, Validation Loss: 0.7539, Alpha: 0.8000
Epoch: 33, Training Loss: 0.6957, Validation Loss: 0.9919, Alpha: 0.8000
Epoch: 34, Training Loss: 0.6821, Validation Loss: 0.7750, Alpha: 0.8000
Epoch: 35, Training Loss: 0.6441, Validation Loss: 0.6760, Alpha: 0.8000
Epoch: 36, Training Loss: 0.6695, Validation Loss: 0.8623, Alpha: 0.8000
Epoch: 37, Training Loss: 0.6556, Validation Loss: 0.7048, Alpha: 0.8000
Epoch: 38, Training Loss: 0.6012, Validation Loss: 0.8731, Alpha: 0.8000
Epoch: 39, Training Loss: 0.5261, Validation Loss: 0.4277, Alpha: 0.8000
Epoch: 40, Training Loss: 0.4219, Validation Loss: 0.4025, Alpha: 0.8000
Epoch: 41, Training Loss: 0.4188, Validation Loss: 0.3999, Alpha: 0.8000
Epoch: 42, Training Loss: 0.3897, Validation Loss: 0.3909, Alpha: 0.8000
Epoch: 43, Training Loss: 0.3683, Validation Loss: 0.3869, Alpha: 0.8000
Epoch: 44, Training Loss: 0.3821, Validation Loss: 0.3864, Alpha: 0.8000
Epoch: 45, Training Loss: 0.3599, Validation Loss: 0.3847, Alpha: 0.8000
Epoch: 46, Training Loss: 0.3295, Validation Loss: 0.3660, Alpha: 0.8000
Epoch: 47, Training Loss: 0.3177, Validation Loss: 0.3603, Alpha: 0.8000
Epoch: 48, Training Loss: 0.3055, Validation Loss: 0.3554, Alpha: 0.8000
Epoch: 49, Training Loss: 0.3175, Validation Loss: 0.3623, Alpha: 0.8000
Epoch: 50, Training Loss: 0.2721, Validation Loss: 0.3685, Alpha: 0.8000
Epoch: 51, Training Loss: 0.2764, Validation Loss: 0.3558, Alpha: 0.8000
Epoch: 52, Training Loss: 0.3066, Validation Loss: 0.3388, Alpha: 0.8000
Epoch: 53, Training Loss: 0.3062, Validation Loss: 0.3721, Alpha: 0.8000
Epoch: 54, Training Loss: 0.2809, Validation Loss: 0.3463, Alpha: 0.8000
Epoch: 55, Training Loss: 0.2780, Validation Loss: 0.3692, Alpha: 0.8000
Epoch: 56, Training Loss: 0.2702, Validation Loss: 0.3648, Alpha: 0.8000
Epoch: 57, Training Loss: 0.2547, Validation Loss: 0.3479, Alpha: 0.8000
Epoch: 58, Training Loss: 0.2430, Validation Loss: 0.3355, Alpha: 0.8000
Epoch: 59, Training Loss: 0.2689, Validation Loss: 0.3374, Alpha: 0.8000
Epoch: 60, Training Loss: 0.2347, Validation Loss: 0.3323, Alpha: 0.8000
Epoch: 61, Training Loss: 0.2496, Validation Loss: 0.3376, Alpha: 0.8000
Epoch: 62, Training Loss: 0.2209, Validation Loss: 0.3378, Alpha: 0.8000
Epoch: 63, Training Loss: 0.2114, Validation Loss: 0.3137, Alpha: 0.8000
Epoch: 64, Training Loss: 0.2300, Validation Loss: 0.3309, Alpha: 0.8000
Epoch: 65, Training Loss: 0.2235, Validation Loss: 0.3169, Alpha: 0.8000
Epoch: 66, Training Loss: 0.1946, Validation Loss: 0.3204, Alpha: 0.8000
Epoch: 67, Training Loss: 0.2135, Validation Loss: 0.3118, Alpha: 0.8000
Epoch: 68, Training Loss: 0.1996, Validation Loss: 0.3251, Alpha: 0.8000
Epoch: 69, Training Loss: 0.2027, Validation Loss: 0.3563, Alpha: 0.8000
Epoch: 70, Training Loss: 0.2070, Validation Loss: 0.3652, Alpha: 0.8000
Epoch: 71, Training Loss: 0.1832, Validation Loss: 0.3370, Alpha: 0.8000
Epoch: 72, Training Loss: 0.2057, Validation Loss: 0.3257, Alpha: 0.8000
Epoch: 73, Training Loss: 0.2078, Validation Loss: 0.3227, Alpha: 0.8000
Epoch: 74, Training Loss: 0.1830, Validation Loss: 0.3189, Alpha: 0.8000
Epoch: 75, Training Loss: 0.1682, Validation Loss: 0.3227, Alpha: 0.8000
Epoch: 76, Training Loss: 0.1712, Validation Loss: 0.3129, Alpha: 0.8000
Epoch: 77, Training Loss: 0.1682, Validation Loss: 0.3006, Alpha: 0.8000
Epoch: 78, Training Loss: 0.1878, Validation Loss: 0.3217, Alpha: 0.8000
Epoch: 79, Training Loss: 0.1535, Validation Loss: 0.3152, Alpha: 0.8000
Epoch: 80, Training Loss: 0.1699, Validation Loss: 0.3102, Alpha: 0.8000
Epoch: 81, Training Loss: 0.1544, Validation Loss: 0.3209, Alpha: 0.8000
Epoch: 82, Training Loss: 0.1455, Validation Loss: 0.3472, Alpha: 0.8000
Epoch: 83, Training Loss: 0.1550, Validation Loss: 0.3280, Alpha: 0.8000
Epoch: 84, Training Loss: 0.1451, Validation Loss: 0.3175, Alpha: 0.8000
Epoch: 85, Training Loss: 0.1618, Validation Loss: 0.3342, Alpha: 0.8000
Epoch: 86, Training Loss: 0.1287, Validation Loss: 0.3273, Alpha: 0.8000
Epoch: 87, Training Loss: 0.1371, Validation Loss: 0.3355, Alpha: 0.8000
Epoch: 88, Training Loss: 0.1436, Validation Loss: 0.3309, Alpha: 0.8000
Epoch: 89, Training Loss: 0.1295, Validation Loss: 0.3106, Alpha: 0.8000
Epoch: 90, Training Loss: 0.1216, Validation Loss: 0.3136, Alpha: 0.8000
Epoch: 91, Training Loss: 0.1178, Validation Loss: 0.3087, Alpha: 0.8000
Epoch: 92, Training Loss: 0.1369, Validation Loss: 0.3106, Alpha: 0.8000
Epoch: 93, Training Loss: 0.1280, Validation Loss: 0.3101, Alpha: 0.8000
Epoch: 94, Training Loss: 0.1195, Validation Loss: 0.3121, Alpha: 0.8000
Epoch: 95, Training Loss: 0.1200, Validation Loss: 0.3095, Alpha: 0.8000
Epoch: 96, Training Loss: 0.1058, Validation Loss: 0.3071, Alpha: 0.8000
Epoch: 97, Training Loss: 0.1049, Validation Loss: 0.3087, Alpha: 0.8000
Early stopping triggered.
Running remove_features classification training with alpha = 1 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.6706, Validation Loss: 3.4818, Alpha: 1.0000
Epoch: 2, Training Loss: 2.9870, Validation Loss: 2.6094, Alpha: 1.0000
Epoch: 3, Training Loss: 2.6436, Validation Loss: 2.4069, Alpha: 1.0000
Epoch: 4, Training Loss: 2.4042, Validation Loss: 2.2506, Alpha: 1.0000
Epoch: 5, Training Loss: 2.2365, Validation Loss: 1.9344, Alpha: 1.0000
Epoch: 6, Training Loss: 2.0039, Validation Loss: 1.8695, Alpha: 1.0000
Epoch: 7, Training Loss: 1.8867, Validation Loss: 1.6413, Alpha: 1.0000
Epoch: 8, Training Loss: 1.7406, Validation Loss: 1.9400, Alpha: 1.0000
Epoch: 9, Training Loss: 1.6369, Validation Loss: 1.4066, Alpha: 1.0000
Epoch: 10, Training Loss: 1.5719, Validation Loss: 1.3643, Alpha: 1.0000
Epoch: 11, Training Loss: 1.5318, Validation Loss: 1.2433, Alpha: 1.0000
Epoch: 12, Training Loss: 1.4130, Validation Loss: 1.1876, Alpha: 1.0000
Epoch: 13, Training Loss: 1.3124, Validation Loss: 1.1771, Alpha: 1.0000
Epoch: 14, Training Loss: 1.3405, Validation Loss: 1.1960, Alpha: 1.0000
Epoch: 15, Training Loss: 1.2151, Validation Loss: 1.0602, Alpha: 1.0000
Epoch: 16, Training Loss: 1.1468, Validation Loss: 0.9392, Alpha: 1.0000
Epoch: 17, Training Loss: 1.1059, Validation Loss: 0.8580, Alpha: 1.0000
Epoch: 18, Training Loss: 1.0699, Validation Loss: 1.0885, Alpha: 1.0000
Epoch: 19, Training Loss: 1.0089, Validation Loss: 0.9801, Alpha: 1.0000
Epoch: 20, Training Loss: 0.9852, Validation Loss: 0.8439, Alpha: 1.0000
Epoch: 21, Training Loss: 0.9142, Validation Loss: 0.8350, Alpha: 1.0000
Epoch: 22, Training Loss: 0.8925, Validation Loss: 0.8077, Alpha: 1.0000
Epoch: 23, Training Loss: 0.8647, Validation Loss: 0.8266, Alpha: 1.0000
Epoch: 24, Training Loss: 0.7962, Validation Loss: 0.8224, Alpha: 1.0000
Epoch: 25, Training Loss: 0.7630, Validation Loss: 0.6707, Alpha: 1.0000
Epoch: 26, Training Loss: 0.7194, Validation Loss: 0.7030, Alpha: 1.0000
Epoch: 27, Training Loss: 0.7357, Validation Loss: 0.6487, Alpha: 1.0000
Epoch: 28, Training Loss: 0.7100, Validation Loss: 0.7766, Alpha: 1.0000
Epoch: 29, Training Loss: 0.6688, Validation Loss: 0.6689, Alpha: 1.0000
Epoch: 30, Training Loss: 0.5889, Validation Loss: 0.5372, Alpha: 1.0000
Epoch: 31, Training Loss: 0.5896, Validation Loss: 0.6295, Alpha: 1.0000
Epoch: 32, Training Loss: 0.5978, Validation Loss: 0.5595, Alpha: 1.0000
Epoch: 33, Training Loss: 0.6309, Validation Loss: 0.5585, Alpha: 1.0000
Epoch: 34, Training Loss: 0.6056, Validation Loss: 0.7127, Alpha: 1.0000
Epoch: 35, Training Loss: 0.5665, Validation Loss: 0.6210, Alpha: 1.0000
Epoch: 36, Training Loss: 0.5320, Validation Loss: 0.6769, Alpha: 1.0000
Epoch: 37, Training Loss: 0.5396, Validation Loss: 0.4842, Alpha: 1.0000
Epoch: 38, Training Loss: 0.4628, Validation Loss: 0.4841, Alpha: 1.0000
Epoch: 39, Training Loss: 0.6049, Validation Loss: 0.6403, Alpha: 1.0000
Epoch: 40, Training Loss: 0.5607, Validation Loss: 0.5289, Alpha: 1.0000
Epoch: 41, Training Loss: 0.4965, Validation Loss: 0.5723, Alpha: 1.0000
Epoch: 42, Training Loss: 0.4701, Validation Loss: 0.4856, Alpha: 1.0000
Epoch: 43, Training Loss: 0.4406, Validation Loss: 0.4964, Alpha: 1.0000
Epoch: 44, Training Loss: 0.4094, Validation Loss: 0.4848, Alpha: 1.0000
Epoch: 45, Training Loss: 0.4202, Validation Loss: 0.5170, Alpha: 1.0000
Epoch: 46, Training Loss: 0.4181, Validation Loss: 0.5310, Alpha: 1.0000
Epoch: 47, Training Loss: 0.3257, Validation Loss: 0.4906, Alpha: 1.0000
Epoch: 48, Training Loss: 0.3596, Validation Loss: 0.4295, Alpha: 1.0000
Epoch: 49, Training Loss: 0.3701, Validation Loss: 0.4661, Alpha: 1.0000
Epoch: 50, Training Loss: 0.3641, Validation Loss: 0.5719, Alpha: 1.0000
Epoch: 51, Training Loss: 0.3798, Validation Loss: 0.5032, Alpha: 1.0000
Epoch: 52, Training Loss: 0.3477, Validation Loss: 0.5372, Alpha: 1.0000
Epoch: 53, Training Loss: 0.3241, Validation Loss: 0.3962, Alpha: 1.0000
Epoch: 54, Training Loss: 0.3248, Validation Loss: 0.4492, Alpha: 1.0000
Epoch: 55, Training Loss: 0.3089, Validation Loss: 0.4488, Alpha: 1.0000
Epoch: 56, Training Loss: 0.3460, Validation Loss: 0.3953, Alpha: 1.0000
Epoch: 57, Training Loss: 0.3333, Validation Loss: 0.4707, Alpha: 1.0000
Epoch: 58, Training Loss: 0.3386, Validation Loss: 0.4731, Alpha: 1.0000
Epoch: 59, Training Loss: 0.3334, Validation Loss: 0.5330, Alpha: 1.0000
Epoch: 60, Training Loss: 0.3873, Validation Loss: 0.5048, Alpha: 1.0000
Epoch: 61, Training Loss: 0.3346, Validation Loss: 0.4568, Alpha: 1.0000
Epoch: 62, Training Loss: 0.2906, Validation Loss: 0.5607, Alpha: 1.0000
Epoch: 63, Training Loss: 0.2526, Validation Loss: 0.3617, Alpha: 1.0000
Epoch: 64, Training Loss: 0.2752, Validation Loss: 0.3779, Alpha: 1.0000
Epoch: 65, Training Loss: 0.2672, Validation Loss: 0.4390, Alpha: 1.0000
Epoch: 66, Training Loss: 0.2607, Validation Loss: 0.4655, Alpha: 1.0000
Epoch: 67, Training Loss: 0.2787, Validation Loss: 0.4691, Alpha: 1.0000
Epoch: 68, Training Loss: 0.2694, Validation Loss: 0.3957, Alpha: 1.0000
Epoch: 69, Training Loss: 0.1980, Validation Loss: 0.4301, Alpha: 1.0000
Epoch: 70, Training Loss: 0.2244, Validation Loss: 0.4435, Alpha: 1.0000
Epoch: 71, Training Loss: 0.1699, Validation Loss: 0.4038, Alpha: 1.0000
Epoch: 72, Training Loss: 0.2081, Validation Loss: 0.4583, Alpha: 1.0000
Epoch: 73, Training Loss: 0.1943, Validation Loss: 0.3621, Alpha: 1.0000
Epoch: 74, Training Loss: 0.1836, Validation Loss: 0.6847, Alpha: 1.0000
Epoch: 75, Training Loss: 0.1771, Validation Loss: 0.3416, Alpha: 1.0000
Epoch: 76, Training Loss: 0.1163, Validation Loss: 0.3076, Alpha: 1.0000
Epoch: 77, Training Loss: 0.1052, Validation Loss: 0.2898, Alpha: 1.0000
Epoch: 78, Training Loss: 0.1024, Validation Loss: 0.2847, Alpha: 1.0000
Epoch: 79, Training Loss: 0.0807, Validation Loss: 0.2874, Alpha: 1.0000
Epoch: 80, Training Loss: 0.0766, Validation Loss: 0.2785, Alpha: 1.0000
Epoch: 81, Training Loss: 0.0715, Validation Loss: 0.2804, Alpha: 1.0000
Epoch: 82, Training Loss: 0.0817, Validation Loss: 0.2821, Alpha: 1.0000
Epoch: 83, Training Loss: 0.0609, Validation Loss: 0.2902, Alpha: 1.0000
Epoch: 84, Training Loss: 0.0707, Validation Loss: 0.2894, Alpha: 1.0000
Epoch: 85, Training Loss: 0.0603, Validation Loss: 0.2826, Alpha: 1.0000
Epoch: 86, Training Loss: 0.0605, Validation Loss: 0.2658, Alpha: 1.0000
Epoch: 87, Training Loss: 0.0536, Validation Loss: 0.2779, Alpha: 1.0000
Epoch: 88, Training Loss: 0.0576, Validation Loss: 0.2893, Alpha: 1.0000
Epoch: 89, Training Loss: 0.0499, Validation Loss: 0.2752, Alpha: 1.0000
Epoch: 90, Training Loss: 0.0544, Validation Loss: 0.2868, Alpha: 1.0000
Epoch: 91, Training Loss: 0.0612, Validation Loss: 0.2875, Alpha: 1.0000
Epoch: 92, Training Loss: 0.0524, Validation Loss: 0.2918, Alpha: 1.0000
Epoch: 93, Training Loss: 0.0437, Validation Loss: 0.2961, Alpha: 1.0000
Epoch: 94, Training Loss: 0.0467, Validation Loss: 0.2945, Alpha: 1.0000
Epoch: 95, Training Loss: 0.0511, Validation Loss: 0.2877, Alpha: 1.0000
Epoch: 96, Training Loss: 0.0502, Validation Loss: 0.2901, Alpha: 1.0000
Epoch: 97, Training Loss: 0.0461, Validation Loss: 0.2842, Alpha: 1.0000
Epoch: 98, Training Loss: 0.0390, Validation Loss: 0.2849, Alpha: 1.0000
Epoch: 99, Training Loss: 0.0474, Validation Loss: 0.2808, Alpha: 1.0000
Epoch: 100, Training Loss: 0.0390, Validation Loss: 0.2810, Alpha: 1.0000
Running rtdetr experiments:
Running rtdetr classification training with alpha = 0 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.3889, Validation Loss: 5.5855, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 3.8828, Validation Loss: 2.8328, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 2.9079, Validation Loss: 2.3055, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.5066, Validation Loss: 2.1434, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.2713, Validation Loss: 1.8838, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.1325, Validation Loss: 1.7063, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 2.0454, Validation Loss: 1.8305, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.8856, Validation Loss: 1.4993, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.7981, Validation Loss: 1.4772, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.6838, Validation Loss: 1.4025, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.6512, Validation Loss: 1.5621, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.5021, Validation Loss: 1.2314, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.4018, Validation Loss: 1.1697, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.3699, Validation Loss: 1.1562, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.3976, Validation Loss: 1.2593, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 1.3390, Validation Loss: 1.1899, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 1.4201, Validation Loss: 1.0864, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 1.2953, Validation Loss: 1.0753, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 1.2465, Validation Loss: 1.0211, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 1.1472, Validation Loss: 1.0486, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 1.1205, Validation Loss: 1.0029, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 1.0988, Validation Loss: 1.0127, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 1.1931, Validation Loss: 1.0019, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 1.0521, Validation Loss: 1.0497, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 1.1497, Validation Loss: 1.0582, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 1.0708, Validation Loss: 0.9811, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 1.1359, Validation Loss: 1.1702, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 1.0878, Validation Loss: 0.9439, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 1.2315, Validation Loss: 1.0276, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 1.0249, Validation Loss: 1.0002, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.9628, Validation Loss: 1.0187, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 1.0447, Validation Loss: 0.9759, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.9637, Validation Loss: 0.9611, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.9080, Validation Loss: 1.0162, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.9476, Validation Loss: 0.8451, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.8713, Validation Loss: 0.8507, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.9219, Validation Loss: 0.9942, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.9146, Validation Loss: 0.8890, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.8740, Validation Loss: 0.9641, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.8447, Validation Loss: 0.8675, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.8588, Validation Loss: 0.9004, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.9522, Validation Loss: 0.9822, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.8343, Validation Loss: 0.9195, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.7698, Validation Loss: 0.9477, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.8109, Validation Loss: 0.8490, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.7904, Validation Loss: 0.8727, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.7253, Validation Loss: 0.8035, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.7157, Validation Loss: 0.7869, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.6161, Validation Loss: 0.7830, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.5896, Validation Loss: 0.7974, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.6508, Validation Loss: 0.7539, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.6256, Validation Loss: 0.7495, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.6132, Validation Loss: 0.7563, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.5775, Validation Loss: 0.7714, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.5881, Validation Loss: 0.7668, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.5688, Validation Loss: 0.7924, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.5562, Validation Loss: 0.7754, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.5791, Validation Loss: 0.7082, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.5358, Validation Loss: 0.7206, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.5651, Validation Loss: 0.7080, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.5760, Validation Loss: 0.7040, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.5165, Validation Loss: 0.7193, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.6036, Validation Loss: 0.7199, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.5445, Validation Loss: 0.7310, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.5199, Validation Loss: 0.7139, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.5428, Validation Loss: 0.7424, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.5704, Validation Loss: 0.7435, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.5056, Validation Loss: 0.7390, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.5696, Validation Loss: 0.7158, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.5608, Validation Loss: 0.7528, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.5997, Validation Loss: 0.7484, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.5160, Validation Loss: 0.7723, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.5033, Validation Loss: 0.7508, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.5078, Validation Loss: 0.7668, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.4887, Validation Loss: 0.7682, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.5143, Validation Loss: 0.7564, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.4707, Validation Loss: 0.7462, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.4900, Validation Loss: 0.7610, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.5463, Validation Loss: 0.7333, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.4696, Validation Loss: 0.7419, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.5003, Validation Loss: 0.7529, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Early stopping triggered.
Running rtdetr classification training with alpha = 0.2 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.9636, Validation Loss: 4.0822, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.0612, Validation Loss: 2.2339, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.3556, Validation Loss: 1.7616, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.0141, Validation Loss: 1.6196, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.8740, Validation Loss: 1.4515, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.7195, Validation Loss: 1.3497, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.5777, Validation Loss: 1.3381, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.4420, Validation Loss: 1.2117, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.4901, Validation Loss: 1.2382, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.3295, Validation Loss: 1.2642, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.3040, Validation Loss: 1.0452, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.2729, Validation Loss: 1.1899, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 1.2054, Validation Loss: 1.0463, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 1.2844, Validation Loss: 1.0570, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 1.2001, Validation Loss: 0.9499, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 1.1468, Validation Loss: 0.9371, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 1.0959, Validation Loss: 0.8728, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 1.0794, Validation Loss: 0.9719, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 1.1820, Validation Loss: 1.0455, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 1.1092, Validation Loss: 0.9073, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 1.0186, Validation Loss: 0.9292, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.9852, Validation Loss: 0.8621, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.8612, Validation Loss: 0.8359, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.9700, Validation Loss: 0.8616, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.8906, Validation Loss: 0.8163, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.8090, Validation Loss: 0.8485, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.8951, Validation Loss: 0.8034, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.8492, Validation Loss: 0.8469, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.8854, Validation Loss: 0.8227, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.8681, Validation Loss: 0.8391, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.8919, Validation Loss: 0.8129, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.7223, Validation Loss: 0.8645, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.7361, Validation Loss: 0.8049, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.7483, Validation Loss: 0.8642, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.7142, Validation Loss: 0.7978, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.7483, Validation Loss: 0.9022, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.7370, Validation Loss: 0.7690, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.7296, Validation Loss: 0.7772, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.7309, Validation Loss: 0.7578, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.7654, Validation Loss: 0.7571, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.6517, Validation Loss: 0.7447, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.7331, Validation Loss: 0.7763, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.6424, Validation Loss: 0.8712, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.7318, Validation Loss: 0.7988, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.6659, Validation Loss: 0.7690, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.6635, Validation Loss: 0.7134, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.6345, Validation Loss: 0.7982, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.6217, Validation Loss: 0.8314, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.5745, Validation Loss: 0.7533, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.7175, Validation Loss: 0.7121, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.6879, Validation Loss: 0.7759, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.6460, Validation Loss: 0.6587, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.6179, Validation Loss: 0.7574, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.6019, Validation Loss: 0.7956, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.5314, Validation Loss: 0.6714, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.6106, Validation Loss: 0.7596, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.5610, Validation Loss: 0.7495, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.5662, Validation Loss: 1.0442, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.5315, Validation Loss: 0.6796, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.5650, Validation Loss: 0.7581, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.4961, Validation Loss: 0.7289, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.5474, Validation Loss: 0.7133, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.6018, Validation Loss: 0.7186, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.4811, Validation Loss: 0.6500, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.4498, Validation Loss: 0.6402, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.4289, Validation Loss: 0.5988, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.4449, Validation Loss: 0.6166, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.4167, Validation Loss: 0.6080, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.3947, Validation Loss: 0.6058, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.4052, Validation Loss: 0.6063, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.4070, Validation Loss: 0.6027, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.3475, Validation Loss: 0.6260, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.3617, Validation Loss: 0.6237, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.3858, Validation Loss: 0.6219, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.4012, Validation Loss: 0.5967, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.4046, Validation Loss: 0.5828, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.3920, Validation Loss: 0.5981, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.3934, Validation Loss: 0.5923, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.3543, Validation Loss: 0.6347, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.4399, Validation Loss: 0.6091, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.3661, Validation Loss: 0.6275, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.4038, Validation Loss: 0.6112, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.3214, Validation Loss: 0.6008, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.3346, Validation Loss: 0.6058, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.3793, Validation Loss: 0.5952, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.3585, Validation Loss: 0.6073, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.3483, Validation Loss: 0.5965, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.3574, Validation Loss: 0.5865, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.3604, Validation Loss: 0.5918, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 90, Training Loss: 0.3353, Validation Loss: 0.5937, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 91, Training Loss: 0.4012, Validation Loss: 0.5838, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 92, Training Loss: 0.3486, Validation Loss: 0.5957, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 93, Training Loss: 0.3298, Validation Loss: 0.6037, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 94, Training Loss: 0.3473, Validation Loss: 0.5752, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 95, Training Loss: 0.3207, Validation Loss: 0.5911, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 96, Training Loss: 0.3305, Validation Loss: 0.5956, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 97, Training Loss: 0.3618, Validation Loss: 0.5849, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 98, Training Loss: 0.3405, Validation Loss: 0.5868, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 99, Training Loss: 0.3464, Validation Loss: 0.5990, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 100, Training Loss: 0.3473, Validation Loss: 0.5703, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Running rtdetr classification training with alpha = 0.5 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.9458, Validation Loss: 2.9234, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.3280, Validation Loss: 1.7571, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 1.8022, Validation Loss: 1.3970, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.5153, Validation Loss: 1.4187, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.4310, Validation Loss: 1.2170, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.3362, Validation Loss: 1.0196, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.2122, Validation Loss: 0.9919, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.1003, Validation Loss: 0.9208, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.0604, Validation Loss: 0.8874, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 0.9920, Validation Loss: 0.9636, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.9795, Validation Loss: 0.7640, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.9033, Validation Loss: 0.7441, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.8558, Validation Loss: 0.7446, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.9229, Validation Loss: 0.7565, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.8420, Validation Loss: 0.6736, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.8818, Validation Loss: 0.7520, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.9533, Validation Loss: 0.7147, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.8310, Validation Loss: 0.6758, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.7885, Validation Loss: 0.6912, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.8127, Validation Loss: 0.7259, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.7657, Validation Loss: 0.6541, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.7148, Validation Loss: 0.6219, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.7695, Validation Loss: 0.6066, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.7325, Validation Loss: 0.6995, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.6798, Validation Loss: 0.6164, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.7218, Validation Loss: 0.6069, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.6665, Validation Loss: 0.5915, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.6844, Validation Loss: 0.5606, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.6366, Validation Loss: 0.7744, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.6808, Validation Loss: 0.5838, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.6239, Validation Loss: 0.6094, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.5955, Validation Loss: 0.5975, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.6464, Validation Loss: 0.5271, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.6116, Validation Loss: 0.5959, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.6293, Validation Loss: 0.5864, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.6481, Validation Loss: 0.5345, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.5818, Validation Loss: 0.5176, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.5382, Validation Loss: 0.6136, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.5332, Validation Loss: 0.5455, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.5551, Validation Loss: 0.5371, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.5054, Validation Loss: 0.6672, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.5125, Validation Loss: 0.5232, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.4730, Validation Loss: 0.5803, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.5326, Validation Loss: 0.5668, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.5027, Validation Loss: 0.5195, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.4690, Validation Loss: 0.5292, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.4856, Validation Loss: 0.6563, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.4675, Validation Loss: 0.5233, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.5276, Validation Loss: 0.4780, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.4679, Validation Loss: 0.4614, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.4422, Validation Loss: 0.4662, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.4103, Validation Loss: 0.4559, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.4270, Validation Loss: 0.4940, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.3575, Validation Loss: 0.4854, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.3725, Validation Loss: 0.4793, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.3487, Validation Loss: 0.4782, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.3831, Validation Loss: 0.4674, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.3720, Validation Loss: 0.4533, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.3842, Validation Loss: 0.4510, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.3407, Validation Loss: 0.4695, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.3380, Validation Loss: 0.4669, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.3404, Validation Loss: 0.4637, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.3343, Validation Loss: 0.4426, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.3249, Validation Loss: 0.4463, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.3713, Validation Loss: 0.4600, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.3578, Validation Loss: 0.4766, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.3211, Validation Loss: 0.4709, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.3551, Validation Loss: 0.4769, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.3381, Validation Loss: 0.4372, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.3719, Validation Loss: 0.4395, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.3583, Validation Loss: 0.4378, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.3186, Validation Loss: 0.4420, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.3417, Validation Loss: 0.4523, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.3539, Validation Loss: 0.4437, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.3134, Validation Loss: 0.4583, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.3306, Validation Loss: 0.4387, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.3247, Validation Loss: 0.4341, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.3111, Validation Loss: 0.4306, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.3117, Validation Loss: 0.4356, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.2978, Validation Loss: 0.4225, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.2755, Validation Loss: 0.4281, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.2971, Validation Loss: 0.4279, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.2897, Validation Loss: 0.4176, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.2818, Validation Loss: 0.4253, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.3121, Validation Loss: 0.4493, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.3068, Validation Loss: 0.4546, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.3108, Validation Loss: 0.4633, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.3031, Validation Loss: 0.4503, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.2691, Validation Loss: 0.4537, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.3111, Validation Loss: 0.4504, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.3121, Validation Loss: 0.4438, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.2650, Validation Loss: 0.4439, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.2725, Validation Loss: 0.4118, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 94, Training Loss: 0.2699, Validation Loss: 0.4243, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 95, Training Loss: 0.2546, Validation Loss: 0.4432, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 96, Training Loss: 0.2587, Validation Loss: 0.4237, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 97, Training Loss: 0.2918, Validation Loss: 0.4339, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 98, Training Loss: 0.2845, Validation Loss: 0.4256, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 99, Training Loss: 0.3212, Validation Loss: 0.4425, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 100, Training Loss: 0.2589, Validation Loss: 0.4450, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Running rtdetr classification training with alpha = 0.8 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.2297, Validation Loss: 2.8816, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 1.9752, Validation Loss: 1.5963, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.5697, Validation Loss: 1.2441, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.4008, Validation Loss: 1.0555, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.2841, Validation Loss: 1.0445, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.1650, Validation Loss: 1.1426, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.0956, Validation Loss: 0.9028, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.0489, Validation Loss: 0.8532, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 1.0324, Validation Loss: 0.8472, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.9854, Validation Loss: 0.7457, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.9011, Validation Loss: 0.7661, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.9129, Validation Loss: 0.7290, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.8011, Validation Loss: 0.6716, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.8446, Validation Loss: 0.6887, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.7573, Validation Loss: 0.7358, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.7785, Validation Loss: 0.6374, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.7357, Validation Loss: 0.6001, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.7442, Validation Loss: 0.6622, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.8086, Validation Loss: 0.6196, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.7143, Validation Loss: 0.6211, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.6873, Validation Loss: 0.5715, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.6652, Validation Loss: 0.6048, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.6483, Validation Loss: 0.5507, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.6600, Validation Loss: 0.5599, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.6753, Validation Loss: 0.5669, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.6223, Validation Loss: 0.5527, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.6220, Validation Loss: 0.5361, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.6202, Validation Loss: 0.5141, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.5899, Validation Loss: 0.5348, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.5801, Validation Loss: 0.5260, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.6335, Validation Loss: 0.5237, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.5842, Validation Loss: 0.4953, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.5433, Validation Loss: 0.5202, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.5800, Validation Loss: 0.5067, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.5374, Validation Loss: 0.5135, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.5634, Validation Loss: 0.5551, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.5412, Validation Loss: 0.4922, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.5482, Validation Loss: 0.5615, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.5137, Validation Loss: 0.4998, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.5465, Validation Loss: 0.4905, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.5192, Validation Loss: 0.4558, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.4433, Validation Loss: 0.4693, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.4678, Validation Loss: 0.4589, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.4741, Validation Loss: 0.4776, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.5036, Validation Loss: 0.5186, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.4803, Validation Loss: 0.4219, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.4730, Validation Loss: 0.4647, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.4856, Validation Loss: 0.4486, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.4763, Validation Loss: 0.4814, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.4235, Validation Loss: 0.3912, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.4248, Validation Loss: 0.4185, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.4332, Validation Loss: 0.4140, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.4326, Validation Loss: 0.4488, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.4210, Validation Loss: 0.4176, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.4225, Validation Loss: 0.4217, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.3887, Validation Loss: 0.4523, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.3962, Validation Loss: 0.4015, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.3758, Validation Loss: 0.4602, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.3972, Validation Loss: 0.3960, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.4041, Validation Loss: 0.4105, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.3766, Validation Loss: 0.4212, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.3361, Validation Loss: 0.3986, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.3073, Validation Loss: 0.3818, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.3134, Validation Loss: 0.3723, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.3039, Validation Loss: 0.3733, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.2838, Validation Loss: 0.3624, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.3280, Validation Loss: 0.3674, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.2883, Validation Loss: 0.3697, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.2761, Validation Loss: 0.3731, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.3260, Validation Loss: 0.3616, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.2581, Validation Loss: 0.3686, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.2716, Validation Loss: 0.3728, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.2854, Validation Loss: 0.3648, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.2818, Validation Loss: 0.3625, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.2731, Validation Loss: 0.3580, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.2824, Validation Loss: 0.3681, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.2571, Validation Loss: 0.3690, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.2592, Validation Loss: 0.3734, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.2482, Validation Loss: 0.3508, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.2555, Validation Loss: 0.3569, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.2601, Validation Loss: 0.3632, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.2733, Validation Loss: 0.3502, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.2708, Validation Loss: 0.3318, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.2276, Validation Loss: 0.3480, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.2449, Validation Loss: 0.3448, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.2655, Validation Loss: 0.3759, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.2598, Validation Loss: 0.3560, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.2393, Validation Loss: 0.3296, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.2595, Validation Loss: 0.3320, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.2521, Validation Loss: 0.3424, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.2514, Validation Loss: 0.3226, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.2574, Validation Loss: 0.3240, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.2654, Validation Loss: 0.3452, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.2464, Validation Loss: 0.3565, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.2374, Validation Loss: 0.3546, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.2617, Validation Loss: 0.3604, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.2412, Validation Loss: 0.3616, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 98, Training Loss: 0.2260, Validation Loss: 0.3539, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 99, Training Loss: 0.2373, Validation Loss: 0.3303, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 100, Training Loss: 0.2293, Validation Loss: 0.3372, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Running rtdetr classification training with alpha = 1 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 2.9145, Validation Loss: 2.2335, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 1.7556, Validation Loss: 1.3139, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.3851, Validation Loss: 1.0716, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.1877, Validation Loss: 0.9136, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.0487, Validation Loss: 0.8825, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.0269, Validation Loss: 0.8472, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 0.9905, Validation Loss: 0.7861, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.8905, Validation Loss: 0.7133, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.8431, Validation Loss: 0.7008, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.8101, Validation Loss: 0.6925, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.7444, Validation Loss: 0.6285, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.7319, Validation Loss: 0.6232, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.6711, Validation Loss: 0.5953, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.6440, Validation Loss: 0.6253, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.6829, Validation Loss: 0.5512, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.6478, Validation Loss: 0.5818, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.5978, Validation Loss: 0.5607, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.6060, Validation Loss: 0.5379, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.5220, Validation Loss: 0.5006, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.5131, Validation Loss: 0.4810, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.5094, Validation Loss: 0.4959, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.4976, Validation Loss: 0.4645, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.5221, Validation Loss: 0.4593, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.5272, Validation Loss: 0.5620, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.4978, Validation Loss: 0.4665, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.5477, Validation Loss: 0.5927, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.5623, Validation Loss: 0.4437, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.5028, Validation Loss: 0.4742, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.4944, Validation Loss: 0.4405, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.4539, Validation Loss: 0.4273, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.4352, Validation Loss: 0.4890, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.4874, Validation Loss: 0.4745, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.4389, Validation Loss: 0.4532, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.5001, Validation Loss: 0.4742, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.4788, Validation Loss: 0.4761, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.4228, Validation Loss: 0.4589, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.4036, Validation Loss: 0.4526, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.3968, Validation Loss: 0.4089, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.3756, Validation Loss: 0.4206, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.3799, Validation Loss: 0.4666, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.4020, Validation Loss: 0.5132, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.3918, Validation Loss: 0.4211, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.3530, Validation Loss: 0.4092, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.3924, Validation Loss: 0.5221, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.3341, Validation Loss: 0.3829, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.3986, Validation Loss: 0.4037, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.3871, Validation Loss: 0.4870, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.3899, Validation Loss: 0.4272, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.4302, Validation Loss: 0.5124, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.3906, Validation Loss: 0.4011, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.3411, Validation Loss: 0.3938, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.3172, Validation Loss: 0.4639, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.3276, Validation Loss: 0.4165, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.3112, Validation Loss: 0.4348, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.2911, Validation Loss: 0.4952, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.3371, Validation Loss: 0.4409, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.3262, Validation Loss: 0.3999, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.2722, Validation Loss: 0.3897, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.2704, Validation Loss: 0.3740, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.2431, Validation Loss: 0.3795, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.2426, Validation Loss: 0.3663, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.2415, Validation Loss: 0.3709, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.2534, Validation Loss: 0.3879, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.2539, Validation Loss: 0.3801, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.2447, Validation Loss: 0.3731, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.2446, Validation Loss: 0.3797, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.2227, Validation Loss: 0.3629, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.2436, Validation Loss: 0.3588, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.2363, Validation Loss: 0.3608, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.2210, Validation Loss: 0.3483, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.2397, Validation Loss: 0.3656, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.2335, Validation Loss: 0.3754, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.2111, Validation Loss: 0.3742, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.2330, Validation Loss: 0.3773, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.1973, Validation Loss: 0.3784, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.2236, Validation Loss: 0.3792, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.2141, Validation Loss: 0.3679, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.1920, Validation Loss: 0.3660, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.2319, Validation Loss: 0.3451, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.1981, Validation Loss: 0.3434, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.2094, Validation Loss: 0.3407, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.1852, Validation Loss: 0.3378, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.2172, Validation Loss: 0.3540, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.2175, Validation Loss: 0.3436, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.2174, Validation Loss: 0.3363, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.1945, Validation Loss: 0.3359, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.1940, Validation Loss: 0.3339, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.2072, Validation Loss: 0.3365, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.1944, Validation Loss: 0.3348, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.1903, Validation Loss: 0.3218, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.1829, Validation Loss: 0.3240, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.2067, Validation Loss: 0.3321, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.1938, Validation Loss: 0.3276, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.1900, Validation Loss: 0.3276, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.2169, Validation Loss: 0.3208, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.1822, Validation Loss: 0.3194, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.1999, Validation Loss: 0.3272, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.2000, Validation Loss: 0.3402, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.1908, Validation Loss: 0.3433, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.1974, Validation Loss: 0.3454, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running yolov8 experiments:
Running yolov8 classification training with alpha = 0 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.4059, Validation Loss: 4.5466, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 4.3807, Validation Loss: 3.0581, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 3.3398, Validation Loss: 2.3624, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.8583, Validation Loss: 1.9240, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.3473, Validation Loss: 1.6606, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.2331, Validation Loss: 1.3958, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.8645, Validation Loss: 1.2413, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.7188, Validation Loss: 0.9921, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.5736, Validation Loss: 0.9535, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.4821, Validation Loss: 0.8947, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.3665, Validation Loss: 0.8102, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.4366, Validation Loss: 0.6841, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.2918, Validation Loss: 0.6922, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.1358, Validation Loss: 0.5741, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.1001, Validation Loss: 0.5309, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 0.8971, Validation Loss: 0.3995, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 0.9350, Validation Loss: 0.4380, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.9479, Validation Loss: 0.4090, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 1.0016, Validation Loss: 0.4344, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.8339, Validation Loss: 0.4220, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.7864, Validation Loss: 0.4071, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.6725, Validation Loss: 0.2921, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.7693, Validation Loss: 0.3973, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.7400, Validation Loss: 0.3273, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.6866, Validation Loss: 0.2737, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.6273, Validation Loss: 0.3140, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.6289, Validation Loss: 0.2304, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.6300, Validation Loss: 0.2813, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.5027, Validation Loss: 0.2337, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.5205, Validation Loss: 0.2379, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.5158, Validation Loss: 0.2926, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.6157, Validation Loss: 0.2707, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.5225, Validation Loss: 0.2664, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.4721, Validation Loss: 0.2120, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.5585, Validation Loss: 0.3308, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.4879, Validation Loss: 0.2030, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.4551, Validation Loss: 0.2780, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.5497, Validation Loss: 0.2143, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.5069, Validation Loss: 0.1920, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.4316, Validation Loss: 0.2706, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.4008, Validation Loss: 0.2926, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.4311, Validation Loss: 0.2499, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.4037, Validation Loss: 0.2077, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.4016, Validation Loss: 0.1969, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.3528, Validation Loss: 0.2458, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.3837, Validation Loss: 0.1815, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.3472, Validation Loss: 0.2319, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.3926, Validation Loss: 0.2053, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.4019, Validation Loss: 0.2725, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.3547, Validation Loss: 0.2583, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.3511, Validation Loss: 0.2026, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.4220, Validation Loss: 0.2169, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.4008, Validation Loss: 0.2420, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.2908, Validation Loss: 0.2545, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.3152, Validation Loss: 0.2178, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.3016, Validation Loss: 0.1822, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.3658, Validation Loss: 0.2098, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.3114, Validation Loss: 0.1486, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.2439, Validation Loss: 0.1477, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.2609, Validation Loss: 0.1480, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.2156, Validation Loss: 0.1369, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.2047, Validation Loss: 0.1449, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.1513, Validation Loss: 0.1383, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.1655, Validation Loss: 0.1408, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.2557, Validation Loss: 0.1433, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.2009, Validation Loss: 0.1359, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.2010, Validation Loss: 0.1355, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.1672, Validation Loss: 0.1330, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.2280, Validation Loss: 0.1437, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.1685, Validation Loss: 0.1346, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.1686, Validation Loss: 0.1361, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.1522, Validation Loss: 0.1400, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.1474, Validation Loss: 0.1432, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.1426, Validation Loss: 0.1441, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.1504, Validation Loss: 0.1349, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.1535, Validation Loss: 0.1334, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.1918, Validation Loss: 0.1410, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.1702, Validation Loss: 0.1355, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.1527, Validation Loss: 0.1433, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.1503, Validation Loss: 0.1360, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.1395, Validation Loss: 0.1377, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.1347, Validation Loss: 0.1306, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.1786, Validation Loss: 0.1287, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.1604, Validation Loss: 0.1359, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.1465, Validation Loss: 0.1326, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.1296, Validation Loss: 0.1300, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.1281, Validation Loss: 0.1339, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.1940, Validation Loss: 0.1349, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.1715, Validation Loss: 0.1330, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.1444, Validation Loss: 0.1307, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.1284, Validation Loss: 0.1326, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 92, Training Loss: 0.1297, Validation Loss: 0.1356, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 93, Training Loss: 0.2390, Validation Loss: 0.1324, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 94, Training Loss: 0.1334, Validation Loss: 0.1319, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 95, Training Loss: 0.1276, Validation Loss: 0.1389, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 96, Training Loss: 0.1489, Validation Loss: 0.1335, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 97, Training Loss: 0.1583, Validation Loss: 0.1349, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 98, Training Loss: 0.1195, Validation Loss: 0.1356, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 99, Training Loss: 0.1204, Validation Loss: 0.1328, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 100, Training Loss: 0.1170, Validation Loss: 0.1366, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Running yolov8 classification training with alpha = 0.2 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.1871, Validation Loss: 3.7409, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.4458, Validation Loss: 2.3434, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.7240, Validation Loss: 1.8958, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.2463, Validation Loss: 1.5724, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.9995, Validation Loss: 1.3130, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.8450, Validation Loss: 1.2289, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.6285, Validation Loss: 1.0073, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.4641, Validation Loss: 0.9075, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.4226, Validation Loss: 0.8380, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.3429, Validation Loss: 0.8364, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.2960, Validation Loss: 0.7087, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.1007, Validation Loss: 0.6617, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 1.1046, Validation Loss: 0.6072, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 1.0105, Validation Loss: 0.4928, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.9135, Validation Loss: 0.5100, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.8034, Validation Loss: 0.3639, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.7843, Validation Loss: 0.3604, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.7921, Validation Loss: 0.3453, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.7564, Validation Loss: 0.3833, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.6430, Validation Loss: 0.2977, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.6571, Validation Loss: 0.2636, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.6162, Validation Loss: 0.2651, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.5552, Validation Loss: 0.2563, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.5849, Validation Loss: 0.2261, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.4998, Validation Loss: 0.2340, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.5548, Validation Loss: 0.1988, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.4571, Validation Loss: 0.2111, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.4477, Validation Loss: 0.1608, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.4435, Validation Loss: 0.1699, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.4664, Validation Loss: 0.2027, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.4897, Validation Loss: 0.1550, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.4106, Validation Loss: 0.1950, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.3441, Validation Loss: 0.1478, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.5005, Validation Loss: 0.1850, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.3383, Validation Loss: 0.1582, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.3690, Validation Loss: 0.1537, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.3505, Validation Loss: 0.1886, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.4191, Validation Loss: 0.1627, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.3532, Validation Loss: 0.1341, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.3533, Validation Loss: 0.1427, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.3566, Validation Loss: 0.1900, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.3402, Validation Loss: 0.1740, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.4383, Validation Loss: 0.2547, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.4633, Validation Loss: 0.1938, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.3370, Validation Loss: 0.1329, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.3413, Validation Loss: 0.1717, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.3492, Validation Loss: 0.1329, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.3453, Validation Loss: 0.1396, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.2971, Validation Loss: 0.2607, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.3043, Validation Loss: 0.1400, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.2792, Validation Loss: 0.1310, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.2711, Validation Loss: 0.1342, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.2431, Validation Loss: 0.1199, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.2320, Validation Loss: 0.1476, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.2686, Validation Loss: 0.1411, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.3129, Validation Loss: 0.1423, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.2801, Validation Loss: 0.1258, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.2617, Validation Loss: 0.1248, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.2448, Validation Loss: 0.1179, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.2276, Validation Loss: 0.1237, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.2442, Validation Loss: 0.1282, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.2281, Validation Loss: 0.1493, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.2792, Validation Loss: 0.1270, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.3393, Validation Loss: 0.1580, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.2503, Validation Loss: 0.1731, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.2609, Validation Loss: 0.1341, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.2164, Validation Loss: 0.1369, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.2672, Validation Loss: 0.1750, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.3081, Validation Loss: 0.1192, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.2266, Validation Loss: 0.1596, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.1861, Validation Loss: 0.1190, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.1857, Validation Loss: 0.1039, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.1330, Validation Loss: 0.0903, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.1482, Validation Loss: 0.0922, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.1296, Validation Loss: 0.0891, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.1045, Validation Loss: 0.0899, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.1268, Validation Loss: 0.1008, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.1482, Validation Loss: 0.0938, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.1337, Validation Loss: 0.0898, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.1349, Validation Loss: 0.0896, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.1273, Validation Loss: 0.0804, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.1179, Validation Loss: 0.0855, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.1137, Validation Loss: 0.0873, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.1512, Validation Loss: 0.0890, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.1095, Validation Loss: 0.0836, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.0978, Validation Loss: 0.0904, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.1249, Validation Loss: 0.0916, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.0990, Validation Loss: 0.0893, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.1526, Validation Loss: 0.0889, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 90, Training Loss: 0.1117, Validation Loss: 0.0829, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 91, Training Loss: 0.1063, Validation Loss: 0.0846, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 92, Training Loss: 0.0833, Validation Loss: 0.0866, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 93, Training Loss: 0.0847, Validation Loss: 0.0860, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 94, Training Loss: 0.0943, Validation Loss: 0.0870, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 95, Training Loss: 0.1157, Validation Loss: 0.0873, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 96, Training Loss: 0.0842, Validation Loss: 0.0929, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 97, Training Loss: 0.0912, Validation Loss: 0.0891, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 98, Training Loss: 0.1094, Validation Loss: 0.0860, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 99, Training Loss: 0.0905, Validation Loss: 0.0870, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 100, Training Loss: 0.1021, Validation Loss: 0.0896, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Running yolov8 classification training with alpha = 0.5 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1713, Validation Loss: 2.9471, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.9293, Validation Loss: 2.1323, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 2.3366, Validation Loss: 1.8041, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.9491, Validation Loss: 1.3723, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.6620, Validation Loss: 1.1786, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.4495, Validation Loss: 1.0408, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.2366, Validation Loss: 0.7744, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.0708, Validation Loss: 0.6967, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.0005, Validation Loss: 0.5255, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 0.9832, Validation Loss: 0.4826, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.8844, Validation Loss: 0.4241, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.7007, Validation Loss: 0.3587, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.6868, Validation Loss: 0.3163, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.6496, Validation Loss: 0.3275, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.5899, Validation Loss: 0.2938, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.5995, Validation Loss: 0.2922, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.5665, Validation Loss: 0.3383, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.5395, Validation Loss: 0.2399, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.5316, Validation Loss: 0.2952, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.4507, Validation Loss: 0.3745, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.5373, Validation Loss: 0.2110, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.4425, Validation Loss: 0.1987, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.4897, Validation Loss: 0.1889, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.4470, Validation Loss: 0.1721, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.4558, Validation Loss: 0.1901, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.3284, Validation Loss: 0.1710, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.4122, Validation Loss: 0.1693, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.4557, Validation Loss: 0.1772, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.3897, Validation Loss: 0.1914, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.4550, Validation Loss: 0.1937, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.3728, Validation Loss: 0.1988, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.3368, Validation Loss: 0.1323, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.2990, Validation Loss: 0.2511, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.3266, Validation Loss: 0.1533, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.2971, Validation Loss: 0.1428, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.2808, Validation Loss: 0.1757, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.3159, Validation Loss: 0.1351, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.3349, Validation Loss: 0.1692, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.2982, Validation Loss: 0.1120, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.2911, Validation Loss: 0.1999, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.2566, Validation Loss: 0.1185, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.3363, Validation Loss: 0.1231, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.2743, Validation Loss: 0.1422, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.3048, Validation Loss: 0.1412, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.4145, Validation Loss: 0.1187, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.2985, Validation Loss: 0.1956, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.2395, Validation Loss: 0.1423, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.2564, Validation Loss: 0.2018, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.2598, Validation Loss: 0.1344, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.3233, Validation Loss: 0.1451, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.1892, Validation Loss: 0.1235, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.1742, Validation Loss: 0.1117, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.2264, Validation Loss: 0.1047, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.1642, Validation Loss: 0.0944, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.1523, Validation Loss: 0.0970, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.1607, Validation Loss: 0.0975, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.1412, Validation Loss: 0.0922, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.1505, Validation Loss: 0.0917, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.1408, Validation Loss: 0.0904, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.1403, Validation Loss: 0.0915, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.1445, Validation Loss: 0.0904, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.1567, Validation Loss: 0.0929, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.1377, Validation Loss: 0.0863, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.1625, Validation Loss: 0.0877, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.1551, Validation Loss: 0.0865, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.1284, Validation Loss: 0.0860, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.1129, Validation Loss: 0.0826, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.1295, Validation Loss: 0.0822, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.1290, Validation Loss: 0.0863, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.1196, Validation Loss: 0.0877, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.1318, Validation Loss: 0.0924, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.1202, Validation Loss: 0.0858, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.1077, Validation Loss: 0.0852, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.1286, Validation Loss: 0.0872, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.1263, Validation Loss: 0.0853, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.1285, Validation Loss: 0.0860, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.1487, Validation Loss: 0.0893, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.1301, Validation Loss: 0.0864, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.1530, Validation Loss: 0.0865, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.1020, Validation Loss: 0.0835, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.1117, Validation Loss: 0.0847, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.1189, Validation Loss: 0.0842, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.0993, Validation Loss: 0.0821, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.1141, Validation Loss: 0.0855, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0962, Validation Loss: 0.0838, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.0922, Validation Loss: 0.0838, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.1041, Validation Loss: 0.0829, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0847, Validation Loss: 0.0811, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.1017, Validation Loss: 0.0841, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.0978, Validation Loss: 0.0823, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.1335, Validation Loss: 0.0844, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.0897, Validation Loss: 0.0803, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.1150, Validation Loss: 0.0813, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 94, Training Loss: 0.1081, Validation Loss: 0.0828, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 95, Training Loss: 0.1034, Validation Loss: 0.0836, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 96, Training Loss: 0.0870, Validation Loss: 0.0844, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 97, Training Loss: 0.0797, Validation Loss: 0.0825, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 98, Training Loss: 0.0875, Validation Loss: 0.0834, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 99, Training Loss: 0.1250, Validation Loss: 0.0827, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 100, Training Loss: 0.1530, Validation Loss: 0.0836, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Running yolov8 classification training with alpha = 0.8 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.4528, Validation Loss: 2.4271, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 2.3492, Validation Loss: 1.6184, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.8501, Validation Loss: 1.3336, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.5379, Validation Loss: 1.0805, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.3224, Validation Loss: 0.9964, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.2001, Validation Loss: 0.7473, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.1493, Validation Loss: 0.7896, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.0834, Validation Loss: 0.6683, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.9959, Validation Loss: 0.6477, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.8941, Validation Loss: 0.6147, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.8956, Validation Loss: 0.6076, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.8803, Validation Loss: 0.5364, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.7825, Validation Loss: 0.4292, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.7345, Validation Loss: 0.5188, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.7522, Validation Loss: 0.3835, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.6964, Validation Loss: 0.3379, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.6037, Validation Loss: 0.2976, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.5007, Validation Loss: 0.3380, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.5924, Validation Loss: 0.2518, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.5006, Validation Loss: 0.3221, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.5328, Validation Loss: 0.2534, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.3994, Validation Loss: 0.2299, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.4298, Validation Loss: 0.1896, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.4473, Validation Loss: 0.2464, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.4272, Validation Loss: 0.1847, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.3583, Validation Loss: 0.2001, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.3550, Validation Loss: 0.1765, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.3526, Validation Loss: 0.1476, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.3405, Validation Loss: 0.1484, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.3533, Validation Loss: 0.1768, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.2846, Validation Loss: 0.1832, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.2966, Validation Loss: 0.1464, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.3310, Validation Loss: 0.1134, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.3265, Validation Loss: 0.2184, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.2832, Validation Loss: 0.1304, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.2437, Validation Loss: 0.2483, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.3230, Validation Loss: 0.1057, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.2294, Validation Loss: 0.1523, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.2469, Validation Loss: 0.1530, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.2582, Validation Loss: 0.1367, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.2220, Validation Loss: 0.1309, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.2228, Validation Loss: 0.1623, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.3023, Validation Loss: 0.1548, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.2450, Validation Loss: 0.1180, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.2607, Validation Loss: 0.1383, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.2072, Validation Loss: 0.1060, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.1953, Validation Loss: 0.0952, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.2003, Validation Loss: 0.1101, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.2503, Validation Loss: 0.1255, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.1683, Validation Loss: 0.1217, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.1959, Validation Loss: 0.0947, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.1726, Validation Loss: 0.1242, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.2301, Validation Loss: 0.1157, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.1692, Validation Loss: 0.0964, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.1522, Validation Loss: 0.1516, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.1709, Validation Loss: 0.1008, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.1623, Validation Loss: 0.1100, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.2036, Validation Loss: 0.1039, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.2012, Validation Loss: 0.1584, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.1497, Validation Loss: 0.0930, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.1426, Validation Loss: 0.0897, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.1160, Validation Loss: 0.1003, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.1288, Validation Loss: 0.1133, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.1700, Validation Loss: 0.1119, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.2275, Validation Loss: 0.0941, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.2075, Validation Loss: 0.0908, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.1655, Validation Loss: 0.1330, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.2135, Validation Loss: 0.1279, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.1465, Validation Loss: 0.1338, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.1418, Validation Loss: 0.1001, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.1768, Validation Loss: 0.0845, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.1913, Validation Loss: 0.0896, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.1067, Validation Loss: 0.1010, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.2200, Validation Loss: 0.0870, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.1205, Validation Loss: 0.0938, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.1432, Validation Loss: 0.1250, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.1451, Validation Loss: 0.1179, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.1537, Validation Loss: 0.1169, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.1196, Validation Loss: 0.0839, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.1300, Validation Loss: 0.1372, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.1275, Validation Loss: 0.1205, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.1638, Validation Loss: 0.0974, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.1025, Validation Loss: 0.1303, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.1337, Validation Loss: 0.0926, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.1277, Validation Loss: 0.0835, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.1259, Validation Loss: 0.0644, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.0924, Validation Loss: 0.0932, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.0921, Validation Loss: 0.0758, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.0704, Validation Loss: 0.0620, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.1179, Validation Loss: 0.0871, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.1022, Validation Loss: 0.1394, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.1371, Validation Loss: 0.1098, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.0836, Validation Loss: 0.0968, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.1449, Validation Loss: 0.1129, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.1088, Validation Loss: 0.0972, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.1569, Validation Loss: 0.0907, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.0960, Validation Loss: 0.0943, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 98, Training Loss: 0.0948, Validation Loss: 0.1150, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 99, Training Loss: 0.0829, Validation Loss: 0.1143, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 100, Training Loss: 0.1423, Validation Loss: 0.1114, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Running yolov8 classification training with alpha = 1 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.1909, Validation Loss: 2.2753, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 2.1816, Validation Loss: 1.5485, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.7401, Validation Loss: 1.2417, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.4775, Validation Loss: 1.3517, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.2455, Validation Loss: 0.8476, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.1431, Validation Loss: 0.6999, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 0.9881, Validation Loss: 0.6219, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.8629, Validation Loss: 0.5319, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.8017, Validation Loss: 0.4694, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.7750, Validation Loss: 0.3778, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.7601, Validation Loss: 0.4946, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.7182, Validation Loss: 0.3453, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.6543, Validation Loss: 0.2879, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.6516, Validation Loss: 0.3471, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.5681, Validation Loss: 0.2655, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.4910, Validation Loss: 0.2888, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.5113, Validation Loss: 0.2139, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.4680, Validation Loss: 0.2449, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.5108, Validation Loss: 0.2008, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.4231, Validation Loss: 0.1596, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.4506, Validation Loss: 0.1915, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.4038, Validation Loss: 0.1577, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.3961, Validation Loss: 0.1300, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.4140, Validation Loss: 0.1882, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.3633, Validation Loss: 0.1515, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.3398, Validation Loss: 0.1320, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.3786, Validation Loss: 0.1447, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.3202, Validation Loss: 0.1400, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.3628, Validation Loss: 0.1185, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.2881, Validation Loss: 0.0971, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.2996, Validation Loss: 0.1033, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.3165, Validation Loss: 0.1158, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.2597, Validation Loss: 0.1224, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.2972, Validation Loss: 0.1562, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.2854, Validation Loss: 0.1097, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.2504, Validation Loss: 0.1086, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.2387, Validation Loss: 0.1079, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.2149, Validation Loss: 0.0959, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.2596, Validation Loss: 0.0851, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.2262, Validation Loss: 0.1030, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.1966, Validation Loss: 0.1681, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.2230, Validation Loss: 0.1001, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.1867, Validation Loss: 0.0922, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.2403, Validation Loss: 0.0996, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.2006, Validation Loss: 0.1087, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.2020, Validation Loss: 0.1076, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.2514, Validation Loss: 0.1344, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.2003, Validation Loss: 0.1105, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.1892, Validation Loss: 0.0856, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.2033, Validation Loss: 0.0956, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.1738, Validation Loss: 0.0712, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.1469, Validation Loss: 0.0644, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.1461, Validation Loss: 0.0593, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.1208, Validation Loss: 0.0557, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.1120, Validation Loss: 0.0573, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.1519, Validation Loss: 0.0544, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.1195, Validation Loss: 0.0582, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.1071, Validation Loss: 0.0598, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.0874, Validation Loss: 0.0553, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.1068, Validation Loss: 0.0561, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.0920, Validation Loss: 0.0547, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.1017, Validation Loss: 0.0525, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.1227, Validation Loss: 0.0512, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.1194, Validation Loss: 0.0559, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.0891, Validation Loss: 0.0523, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.0837, Validation Loss: 0.0526, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.0854, Validation Loss: 0.0513, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.0948, Validation Loss: 0.0509, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.0715, Validation Loss: 0.0522, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.0883, Validation Loss: 0.0540, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.0760, Validation Loss: 0.0538, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.0752, Validation Loss: 0.0553, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.0906, Validation Loss: 0.0516, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.1002, Validation Loss: 0.0518, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.0662, Validation Loss: 0.0529, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.0772, Validation Loss: 0.0503, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.0916, Validation Loss: 0.0557, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.0868, Validation Loss: 0.0575, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.1049, Validation Loss: 0.0545, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.0647, Validation Loss: 0.0536, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.0787, Validation Loss: 0.0518, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.0631, Validation Loss: 0.0575, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.0924, Validation Loss: 0.0537, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.0671, Validation Loss: 0.0514, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0766, Validation Loss: 0.0527, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.0666, Validation Loss: 0.0592, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.0682, Validation Loss: 0.0516, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.0608, Validation Loss: 0.0539, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.0715, Validation Loss: 0.0503, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.0682, Validation Loss: 0.0520, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.0617, Validation Loss: 0.0525, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.0772, Validation Loss: 0.0533, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.0648, Validation Loss: 0.0528, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.0595, Validation Loss: 0.0504, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.0672, Validation Loss: 0.0502, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.0722, Validation Loss: 0.0500, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.0713, Validation Loss: 0.0530, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.0755, Validation Loss: 0.0527, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.0553, Validation Loss: 0.0532, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.0741, Validation Loss: 0.0513, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running yolov9 experiments:
Running yolov9 classification training with alpha = 0 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.3919, Validation Loss: 4.8243, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 4.4839, Validation Loss: 3.2447, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 3.4197, Validation Loss: 2.4654, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.8224, Validation Loss: 1.9331, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.5181, Validation Loss: 1.7415, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.3131, Validation Loss: 1.5373, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 2.0720, Validation Loss: 1.3241, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.8495, Validation Loss: 1.1014, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.7443, Validation Loss: 1.1192, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.5756, Validation Loss: 0.8466, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.4134, Validation Loss: 0.8443, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.3250, Validation Loss: 0.6903, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.1706, Validation Loss: 0.6927, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.2936, Validation Loss: 0.7720, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.0163, Validation Loss: 0.5217, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 1.0395, Validation Loss: 0.6606, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 1.0045, Validation Loss: 0.5410, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.9436, Validation Loss: 0.4887, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.8636, Validation Loss: 0.4599, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.8921, Validation Loss: 0.4510, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.7779, Validation Loss: 0.3769, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.6883, Validation Loss: 0.4030, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.7522, Validation Loss: 0.3415, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.6932, Validation Loss: 0.4410, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.6320, Validation Loss: 0.3122, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.5991, Validation Loss: 0.3496, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.6339, Validation Loss: 0.2809, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.6489, Validation Loss: 0.3102, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.5434, Validation Loss: 0.3183, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.5134, Validation Loss: 0.2794, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.5198, Validation Loss: 0.2731, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.4984, Validation Loss: 0.2646, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.5016, Validation Loss: 0.3050, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.5518, Validation Loss: 0.2503, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.5838, Validation Loss: 0.3154, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.5271, Validation Loss: 0.2914, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.5705, Validation Loss: 0.3093, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.4310, Validation Loss: 0.2695, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.6080, Validation Loss: 0.2429, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.5180, Validation Loss: 0.2597, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.4663, Validation Loss: 0.3134, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.4716, Validation Loss: 0.3090, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.3818, Validation Loss: 0.2734, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.5044, Validation Loss: 0.2323, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.3761, Validation Loss: 0.2402, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.4256, Validation Loss: 0.2178, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.3359, Validation Loss: 0.2435, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.4263, Validation Loss: 0.2493, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.3897, Validation Loss: 0.2018, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.3607, Validation Loss: 0.2246, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.4069, Validation Loss: 0.2983, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.4197, Validation Loss: 0.2407, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.2654, Validation Loss: 0.2197, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.3427, Validation Loss: 0.2306, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.2818, Validation Loss: 0.2431, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.3963, Validation Loss: 0.2483, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.4117, Validation Loss: 0.2122, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.3250, Validation Loss: 0.2865, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.3678, Validation Loss: 0.2374, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.2730, Validation Loss: 0.2757, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.2905, Validation Loss: 0.1802, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.2786, Validation Loss: 0.1670, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.2649, Validation Loss: 0.1631, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.3053, Validation Loss: 0.1801, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.3073, Validation Loss: 0.1998, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.2000, Validation Loss: 0.1803, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.1955, Validation Loss: 0.1772, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.2070, Validation Loss: 0.1762, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.1669, Validation Loss: 0.1656, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.1695, Validation Loss: 0.1724, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.1733, Validation Loss: 0.1719, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.2061, Validation Loss: 0.1728, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.1739, Validation Loss: 0.1682, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.2367, Validation Loss: 0.1729, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.1347, Validation Loss: 0.1696, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.1646, Validation Loss: 0.1677, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.1822, Validation Loss: 0.1695, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.1583, Validation Loss: 0.1711, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.1510, Validation Loss: 0.1591, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.1476, Validation Loss: 0.1686, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.1930, Validation Loss: 0.1695, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.1822, Validation Loss: 0.1740, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.1332, Validation Loss: 0.1631, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.1973, Validation Loss: 0.1631, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.1558, Validation Loss: 0.1599, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.1604, Validation Loss: 0.1593, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.1473, Validation Loss: 0.1666, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.1784, Validation Loss: 0.1696, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.1564, Validation Loss: 0.1652, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.1494, Validation Loss: 0.1640, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.1892, Validation Loss: 0.1657, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 92, Training Loss: 0.1495, Validation Loss: 0.1724, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 93, Training Loss: 0.1265, Validation Loss: 0.1643, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 94, Training Loss: 0.1578, Validation Loss: 0.1601, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 95, Training Loss: 0.2019, Validation Loss: 0.1673, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 96, Training Loss: 0.1363, Validation Loss: 0.1630, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 97, Training Loss: 0.1246, Validation Loss: 0.1610, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 98, Training Loss: 0.1351, Validation Loss: 0.1629, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 99, Training Loss: 0.1481, Validation Loss: 0.1655, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Early stopping triggered.
Running yolov9 classification training with alpha = 0.2 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.2274, Validation Loss: 3.6401, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.6458, Validation Loss: 2.8133, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.8606, Validation Loss: 2.0346, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.3142, Validation Loss: 1.5782, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.9655, Validation Loss: 1.3462, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.8215, Validation Loss: 1.1251, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.5954, Validation Loss: 0.9293, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.5896, Validation Loss: 0.8490, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.3819, Validation Loss: 0.8214, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.0660, Validation Loss: 0.6917, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 0.9792, Validation Loss: 0.5137, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.0408, Validation Loss: 0.5182, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 0.8319, Validation Loss: 0.4314, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 0.7520, Validation Loss: 0.3916, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.8650, Validation Loss: 0.5155, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.7328, Validation Loss: 0.3342, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.6932, Validation Loss: 0.3224, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.6163, Validation Loss: 0.3335, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.6866, Validation Loss: 0.2654, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.6154, Validation Loss: 0.2485, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.5357, Validation Loss: 0.2742, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.6079, Validation Loss: 0.2517, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.5992, Validation Loss: 0.2368, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.5103, Validation Loss: 0.2470, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.5633, Validation Loss: 0.2731, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.5530, Validation Loss: 0.2285, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.4297, Validation Loss: 0.2162, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.5021, Validation Loss: 0.2271, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.4037, Validation Loss: 0.2344, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.4587, Validation Loss: 0.2452, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.3734, Validation Loss: 0.2130, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.4412, Validation Loss: 0.1734, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.3111, Validation Loss: 0.1635, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.3784, Validation Loss: 0.1658, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.3312, Validation Loss: 0.2398, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.3650, Validation Loss: 0.2713, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.3902, Validation Loss: 0.2618, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.3636, Validation Loss: 0.1793, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.3646, Validation Loss: 0.1837, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.3479, Validation Loss: 0.1579, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.3188, Validation Loss: 0.1864, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.3278, Validation Loss: 0.1716, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.3829, Validation Loss: 0.1653, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.3273, Validation Loss: 0.2147, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.2951, Validation Loss: 0.2016, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.3736, Validation Loss: 0.1791, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.3777, Validation Loss: 0.2333, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.3324, Validation Loss: 0.1880, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.3391, Validation Loss: 0.1810, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.4078, Validation Loss: 0.3156, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.3610, Validation Loss: 0.2226, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.2949, Validation Loss: 0.1637, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.2681, Validation Loss: 0.1408, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.2157, Validation Loss: 0.1343, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.1680, Validation Loss: 0.1383, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.2071, Validation Loss: 0.1457, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.1828, Validation Loss: 0.1384, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.1653, Validation Loss: 0.1318, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.1741, Validation Loss: 0.1311, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.1736, Validation Loss: 0.1296, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.1933, Validation Loss: 0.1344, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.1584, Validation Loss: 0.1292, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.1376, Validation Loss: 0.1318, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.1599, Validation Loss: 0.1358, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.1460, Validation Loss: 0.1376, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.1518, Validation Loss: 0.1431, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.1359, Validation Loss: 0.1402, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.1221, Validation Loss: 0.1336, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.1807, Validation Loss: 0.1335, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.1568, Validation Loss: 0.1449, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.1597, Validation Loss: 0.1404, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.1342, Validation Loss: 0.1379, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.1526, Validation Loss: 0.1450, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.1691, Validation Loss: 0.1407, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.1588, Validation Loss: 0.1380, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.1591, Validation Loss: 0.1395, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.1495, Validation Loss: 0.1337, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.1574, Validation Loss: 0.1414, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.1332, Validation Loss: 0.1376, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.1270, Validation Loss: 0.1332, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.1348, Validation Loss: 0.1343, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.1692, Validation Loss: 0.1406, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Early stopping triggered.
Running yolov9 classification training with alpha = 0.5 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1331, Validation Loss: 2.9909, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.8755, Validation Loss: 2.1560, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 2.2544, Validation Loss: 1.6133, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.9318, Validation Loss: 1.3187, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.7460, Validation Loss: 1.1694, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.5347, Validation Loss: 0.9566, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.3443, Validation Loss: 0.9024, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.2613, Validation Loss: 0.8390, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.1326, Validation Loss: 0.6219, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 1.1713, Validation Loss: 0.6443, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 1.0047, Validation Loss: 0.5437, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.7836, Validation Loss: 0.5256, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.8236, Validation Loss: 0.4073, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.8365, Validation Loss: 0.5107, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.8014, Validation Loss: 0.4956, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.6597, Validation Loss: 0.3589, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.6189, Validation Loss: 0.3083, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.5949, Validation Loss: 0.3048, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.6899, Validation Loss: 0.2492, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.5796, Validation Loss: 0.2943, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.5096, Validation Loss: 0.2736, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.4636, Validation Loss: 0.2693, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.4226, Validation Loss: 0.1966, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.4181, Validation Loss: 0.2309, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.5546, Validation Loss: 0.2710, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.4136, Validation Loss: 0.3349, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.4624, Validation Loss: 0.2149, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.4330, Validation Loss: 0.2426, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.4258, Validation Loss: 0.2132, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.3633, Validation Loss: 0.2035, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.3657, Validation Loss: 0.1925, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.3586, Validation Loss: 0.1968, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.3366, Validation Loss: 0.1899, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.3082, Validation Loss: 0.1760, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.3269, Validation Loss: 0.1907, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.3670, Validation Loss: 0.1872, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.2811, Validation Loss: 0.2182, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.3121, Validation Loss: 0.1826, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.4184, Validation Loss: 0.1800, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.3471, Validation Loss: 0.2214, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.3475, Validation Loss: 0.2225, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.3275, Validation Loss: 0.1716, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.2783, Validation Loss: 0.1839, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.2564, Validation Loss: 0.1697, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.2564, Validation Loss: 0.1505, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.2691, Validation Loss: 0.1617, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.3075, Validation Loss: 0.1730, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.2338, Validation Loss: 0.1948, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.2774, Validation Loss: 0.1411, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.3023, Validation Loss: 0.1814, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.2291, Validation Loss: 0.1432, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.2377, Validation Loss: 0.1548, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.2087, Validation Loss: 0.1268, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.2297, Validation Loss: 0.1936, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.2194, Validation Loss: 0.1316, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.2171, Validation Loss: 0.1627, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.2512, Validation Loss: 0.1633, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.2183, Validation Loss: 0.1490, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.2029, Validation Loss: 0.1417, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.2119, Validation Loss: 0.1514, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.1861, Validation Loss: 0.1310, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.2132, Validation Loss: 0.1378, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.1999, Validation Loss: 0.1378, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.2039, Validation Loss: 0.1700, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.1747, Validation Loss: 0.1201, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.1136, Validation Loss: 0.1158, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.1561, Validation Loss: 0.1157, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.1320, Validation Loss: 0.1192, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.1121, Validation Loss: 0.1214, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.1110, Validation Loss: 0.1106, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.1084, Validation Loss: 0.1101, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.1038, Validation Loss: 0.1054, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.0988, Validation Loss: 0.1114, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.1098, Validation Loss: 0.1114, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.0879, Validation Loss: 0.1113, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.1031, Validation Loss: 0.1066, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.0777, Validation Loss: 0.1143, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.1053, Validation Loss: 0.1123, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.0897, Validation Loss: 0.1055, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.1014, Validation Loss: 0.1057, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.1627, Validation Loss: 0.1173, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.0916, Validation Loss: 0.1069, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.0863, Validation Loss: 0.1057, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.0728, Validation Loss: 0.1032, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0789, Validation Loss: 0.1068, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.0686, Validation Loss: 0.1036, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.0935, Validation Loss: 0.1056, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0906, Validation Loss: 0.1085, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.0860, Validation Loss: 0.1060, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.1353, Validation Loss: 0.1062, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.0705, Validation Loss: 0.1039, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.0818, Validation Loss: 0.1065, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.1060, Validation Loss: 0.1025, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 94, Training Loss: 0.0916, Validation Loss: 0.1045, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 95, Training Loss: 0.0902, Validation Loss: 0.1079, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 96, Training Loss: 0.1188, Validation Loss: 0.1054, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 97, Training Loss: 0.0847, Validation Loss: 0.1056, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 98, Training Loss: 0.0803, Validation Loss: 0.1105, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 99, Training Loss: 0.0942, Validation Loss: 0.1033, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 100, Training Loss: 0.0884, Validation Loss: 0.1099, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Running yolov9 classification training with alpha = 0.8 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.5123, Validation Loss: 2.6164, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 2.4427, Validation Loss: 1.8165, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.9821, Validation Loss: 1.4395, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.6658, Validation Loss: 1.1670, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.4286, Validation Loss: 0.9818, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.2397, Validation Loss: 0.8017, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.0830, Validation Loss: 0.6923, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 0.9450, Validation Loss: 0.6400, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.9305, Validation Loss: 0.4655, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.8762, Validation Loss: 0.4588, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.7745, Validation Loss: 0.4189, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.7253, Validation Loss: 0.3898, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.6405, Validation Loss: 0.3096, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.5828, Validation Loss: 0.4805, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.4880, Validation Loss: 0.2402, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.5678, Validation Loss: 0.2924, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.4675, Validation Loss: 0.1844, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.4815, Validation Loss: 0.2242, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.4284, Validation Loss: 0.1966, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.4791, Validation Loss: 0.1943, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.3853, Validation Loss: 0.1770, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.4021, Validation Loss: 0.2519, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.3922, Validation Loss: 0.1724, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.3673, Validation Loss: 0.1965, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.2997, Validation Loss: 0.1238, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.3517, Validation Loss: 0.1639, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.3239, Validation Loss: 0.1540, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.3639, Validation Loss: 0.1627, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.3455, Validation Loss: 0.1419, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.2813, Validation Loss: 0.1675, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.2892, Validation Loss: 0.1249, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.3029, Validation Loss: 0.1548, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.2841, Validation Loss: 0.1457, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.3050, Validation Loss: 0.1351, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.3182, Validation Loss: 0.1404, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.3270, Validation Loss: 0.1484, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.2174, Validation Loss: 0.1105, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.2076, Validation Loss: 0.0916, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.2037, Validation Loss: 0.0831, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.1617, Validation Loss: 0.0809, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.2416, Validation Loss: 0.0821, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.1887, Validation Loss: 0.0893, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.1419, Validation Loss: 0.0845, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.2332, Validation Loss: 0.0839, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.1670, Validation Loss: 0.0832, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.1346, Validation Loss: 0.0790, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.1414, Validation Loss: 0.0841, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.1584, Validation Loss: 0.0831, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.1393, Validation Loss: 0.0806, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.1423, Validation Loss: 0.0870, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.1129, Validation Loss: 0.0903, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.1571, Validation Loss: 0.0861, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.1538, Validation Loss: 0.0921, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.1381, Validation Loss: 0.0889, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.1332, Validation Loss: 0.0883, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.1399, Validation Loss: 0.0819, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.1244, Validation Loss: 0.0801, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.1214, Validation Loss: 0.0810, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.1299, Validation Loss: 0.0801, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.1225, Validation Loss: 0.0809, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.1526, Validation Loss: 0.0818, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.1131, Validation Loss: 0.0815, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.1247, Validation Loss: 0.0834, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.1068, Validation Loss: 0.0843, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.1456, Validation Loss: 0.0832, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.1085, Validation Loss: 0.0886, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Early stopping triggered.
Running yolov9 classification training with alpha = 1 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.1716, Validation Loss: 2.3920, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 2.1849, Validation Loss: 1.7367, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.7786, Validation Loss: 1.3029, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.5087, Validation Loss: 1.1155, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.3244, Validation Loss: 0.9118, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.1330, Validation Loss: 0.7509, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 1.0774, Validation Loss: 0.8264, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.9703, Validation Loss: 0.5980, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.8871, Validation Loss: 0.4994, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.8019, Validation Loss: 0.4461, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.8266, Validation Loss: 0.4488, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.6906, Validation Loss: 0.4148, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.6659, Validation Loss: 0.3081, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.6176, Validation Loss: 0.3068, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.6671, Validation Loss: 0.2831, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.5583, Validation Loss: 0.4366, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.5676, Validation Loss: 0.2642, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.5288, Validation Loss: 0.2692, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.5086, Validation Loss: 0.2407, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.4892, Validation Loss: 0.2303, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.4685, Validation Loss: 0.2075, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.4819, Validation Loss: 0.2422, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.3971, Validation Loss: 0.2081, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.3852, Validation Loss: 0.1797, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.4746, Validation Loss: 0.1798, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.4025, Validation Loss: 0.1776, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.4304, Validation Loss: 0.1867, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.3735, Validation Loss: 0.1763, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.3651, Validation Loss: 0.1607, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.3588, Validation Loss: 0.1628, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.2983, Validation Loss: 0.2491, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.3500, Validation Loss: 0.1565, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.3135, Validation Loss: 0.1421, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.3445, Validation Loss: 0.1594, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.2770, Validation Loss: 0.1067, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.2548, Validation Loss: 0.1285, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.2556, Validation Loss: 0.1469, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.3152, Validation Loss: 0.1303, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.2771, Validation Loss: 0.1184, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.2901, Validation Loss: 0.1423, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.2628, Validation Loss: 0.1060, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.2307, Validation Loss: 0.1193, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.2080, Validation Loss: 0.1095, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.2146, Validation Loss: 0.1141, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.2277, Validation Loss: 0.1055, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.2259, Validation Loss: 0.1036, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.2673, Validation Loss: 0.0992, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.1990, Validation Loss: 0.0877, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.2554, Validation Loss: 0.1109, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.2237, Validation Loss: 0.1248, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.1828, Validation Loss: 0.1104, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.1890, Validation Loss: 0.1089, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.1800, Validation Loss: 0.1025, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.2056, Validation Loss: 0.1187, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.2008, Validation Loss: 0.0971, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.1833, Validation Loss: 0.0844, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.1718, Validation Loss: 0.0881, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.1651, Validation Loss: 0.0777, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.1764, Validation Loss: 0.0997, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.1369, Validation Loss: 0.0964, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.1589, Validation Loss: 0.1307, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.2117, Validation Loss: 0.1018, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.2051, Validation Loss: 0.1355, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.1825, Validation Loss: 0.0952, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.1617, Validation Loss: 0.0919, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.1463, Validation Loss: 0.1305, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.1905, Validation Loss: 0.0795, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.1679, Validation Loss: 0.0943, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.2295, Validation Loss: 0.1429, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.1743, Validation Loss: 0.1003, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.1447, Validation Loss: 0.0843, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.1792, Validation Loss: 0.0813, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.0992, Validation Loss: 0.0811, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.1355, Validation Loss: 0.0751, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.1030, Validation Loss: 0.0764, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.1629, Validation Loss: 0.0764, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.1065, Validation Loss: 0.0744, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.0661, Validation Loss: 0.0759, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.0874, Validation Loss: 0.0766, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.1021, Validation Loss: 0.0738, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.1111, Validation Loss: 0.0734, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.1045, Validation Loss: 0.0746, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.0762, Validation Loss: 0.0778, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.0658, Validation Loss: 0.0765, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0912, Validation Loss: 0.0784, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.0823, Validation Loss: 0.0743, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.0811, Validation Loss: 0.0743, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.0694, Validation Loss: 0.0727, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.1414, Validation Loss: 0.0701, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.0732, Validation Loss: 0.0731, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.0654, Validation Loss: 0.0762, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.0916, Validation Loss: 0.0709, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.0671, Validation Loss: 0.0679, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.0928, Validation Loss: 0.0686, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.0684, Validation Loss: 0.0672, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.0853, Validation Loss: 0.0672, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.0785, Validation Loss: 0.0643, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.0791, Validation Loss: 0.0648, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.0885, Validation Loss: 0.0673, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.0686, Validation Loss: 0.0667, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running decreased_branch_complexity experiments:
Running decreased_branch_complexity classification training with alpha = 0 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.9468, Validation Loss: 4.5089, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 2.7757, Validation Loss: 2.0439, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 2.1871, Validation Loss: 1.6813, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 1.6709, Validation Loss: 1.1469, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 1.4887, Validation Loss: 0.9652, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 1.3209, Validation Loss: 0.8051, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.1410, Validation Loss: 0.7630, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.0110, Validation Loss: 0.7522, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.0237, Validation Loss: 0.8703, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 0.8704, Validation Loss: 0.6048, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 0.7352, Validation Loss: 0.5424, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 0.7130, Validation Loss: 0.4351, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 0.7450, Validation Loss: 0.4933, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 0.6030, Validation Loss: 0.3896, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 0.6403, Validation Loss: 0.4307, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 0.5545, Validation Loss: 0.3822, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 0.6440, Validation Loss: 0.4309, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.6250, Validation Loss: 0.5627, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.5798, Validation Loss: 0.4284, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.5028, Validation Loss: 0.3559, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.5266, Validation Loss: 0.3338, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.4907, Validation Loss: 0.3561, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.4685, Validation Loss: 0.4099, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.5105, Validation Loss: 0.2996, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.4044, Validation Loss: 0.4632, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.5186, Validation Loss: 0.3286, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.4229, Validation Loss: 0.3553, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.4031, Validation Loss: 0.2874, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.3766, Validation Loss: 0.2377, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.3489, Validation Loss: 0.3892, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.3588, Validation Loss: 0.3117, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.2917, Validation Loss: 0.2841, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.3319, Validation Loss: 0.2854, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.3104, Validation Loss: 0.2304, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.3482, Validation Loss: 0.3924, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.3151, Validation Loss: 0.2483, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.3006, Validation Loss: 0.2099, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.3232, Validation Loss: 0.2723, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.2842, Validation Loss: 0.2336, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.2630, Validation Loss: 0.2500, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.2726, Validation Loss: 0.2573, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.2808, Validation Loss: 0.1984, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.2036, Validation Loss: 0.2165, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.2290, Validation Loss: 0.3351, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.1752, Validation Loss: 0.2115, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.2081, Validation Loss: 0.2292, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.2144, Validation Loss: 0.2635, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.2508, Validation Loss: 0.3020, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.2856, Validation Loss: 0.4126, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.2189, Validation Loss: 0.2521, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.1547, Validation Loss: 0.2882, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.1866, Validation Loss: 0.2348, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.1791, Validation Loss: 0.3515, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.1852, Validation Loss: 0.2051, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.1368, Validation Loss: 0.1832, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.1228, Validation Loss: 0.1908, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.0884, Validation Loss: 0.1674, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.0855, Validation Loss: 0.1628, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.0821, Validation Loss: 0.1635, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.0804, Validation Loss: 0.1654, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.0761, Validation Loss: 0.1782, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.0817, Validation Loss: 0.1943, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.0752, Validation Loss: 0.1813, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.0574, Validation Loss: 0.1690, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.0525, Validation Loss: 0.1738, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.0657, Validation Loss: 0.1630, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.0758, Validation Loss: 0.1772, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.0691, Validation Loss: 0.1679, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.0579, Validation Loss: 0.1760, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.0473, Validation Loss: 0.1742, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.0334, Validation Loss: 0.1742, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.0512, Validation Loss: 0.1762, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.0645, Validation Loss: 0.1705, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.0489, Validation Loss: 0.1727, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.0582, Validation Loss: 0.1754, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.0616, Validation Loss: 0.1697, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.0663, Validation Loss: 0.1716, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.0625, Validation Loss: 0.1709, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Early stopping triggered.
Running decreased_branch_complexity classification training with alpha = 0.2 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1766, Validation Loss: 3.7418, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 2.3110, Validation Loss: 1.7190, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 1.7728, Validation Loss: 1.2382, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 1.4158, Validation Loss: 1.0227, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.1858, Validation Loss: 0.8893, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.0166, Validation Loss: 0.7653, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 0.9010, Validation Loss: 0.6162, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 0.7807, Validation Loss: 0.5225, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 0.6724, Validation Loss: 0.4743, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 0.6916, Validation Loss: 0.4876, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 0.6230, Validation Loss: 0.3904, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 0.5550, Validation Loss: 0.3871, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 0.5262, Validation Loss: 0.3345, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 0.4852, Validation Loss: 0.3135, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.4736, Validation Loss: 0.3306, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.4965, Validation Loss: 0.6025, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.4980, Validation Loss: 0.2974, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.4472, Validation Loss: 0.3100, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.4566, Validation Loss: 0.2750, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.3857, Validation Loss: 0.2634, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.3153, Validation Loss: 0.2735, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.3468, Validation Loss: 0.2855, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.3543, Validation Loss: 0.2831, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.3767, Validation Loss: 0.2463, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.3689, Validation Loss: 0.2737, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.3393, Validation Loss: 0.2890, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.3580, Validation Loss: 0.2577, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.3074, Validation Loss: 0.2290, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.3231, Validation Loss: 0.2513, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.2914, Validation Loss: 0.2290, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.3043, Validation Loss: 0.2784, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.3024, Validation Loss: 0.2863, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.2083, Validation Loss: 0.2424, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.2882, Validation Loss: 0.2451, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.2828, Validation Loss: 0.2962, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.2739, Validation Loss: 0.2295, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.2429, Validation Loss: 0.2514, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.2415, Validation Loss: 0.2355, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.2688, Validation Loss: 0.1983, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.2531, Validation Loss: 0.1992, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.2276, Validation Loss: 0.2135, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.2093, Validation Loss: 0.2910, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.2120, Validation Loss: 0.2431, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.1833, Validation Loss: 0.2180, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.2005, Validation Loss: 0.3000, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.2293, Validation Loss: 0.2559, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.1673, Validation Loss: 0.2231, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.1874, Validation Loss: 0.2234, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.1433, Validation Loss: 0.2169, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.1544, Validation Loss: 0.1656, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.1624, Validation Loss: 0.2201, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.2090, Validation Loss: 0.2420, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.1749, Validation Loss: 0.2610, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.1678, Validation Loss: 0.2642, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.1409, Validation Loss: 0.2656, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.1703, Validation Loss: 0.2334, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.1861, Validation Loss: 0.1979, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.1231, Validation Loss: 0.2457, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.1236, Validation Loss: 0.2224, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.1225, Validation Loss: 0.2039, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.1428, Validation Loss: 0.2455, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.1386, Validation Loss: 0.1805, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.0684, Validation Loss: 0.1513, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.0802, Validation Loss: 0.1504, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.0580, Validation Loss: 0.1510, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.0712, Validation Loss: 0.1631, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.0601, Validation Loss: 0.1567, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.0454, Validation Loss: 0.1601, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.0471, Validation Loss: 0.1455, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.0496, Validation Loss: 0.1561, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.0455, Validation Loss: 0.1419, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.0453, Validation Loss: 0.1431, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.0385, Validation Loss: 0.1428, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.0478, Validation Loss: 0.1485, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.0380, Validation Loss: 0.1468, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.0373, Validation Loss: 0.1476, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.0343, Validation Loss: 0.1489, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.0419, Validation Loss: 0.1398, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.0377, Validation Loss: 0.1452, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.0366, Validation Loss: 0.1402, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.0335, Validation Loss: 0.1347, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.0450, Validation Loss: 0.1381, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.0460, Validation Loss: 0.1458, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.0332, Validation Loss: 0.1499, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.0373, Validation Loss: 0.1463, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.0372, Validation Loss: 0.1469, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.0269, Validation Loss: 0.1424, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.0293, Validation Loss: 0.1415, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.0465, Validation Loss: 0.1420, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 90, Training Loss: 0.0296, Validation Loss: 0.1463, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 91, Training Loss: 0.0466, Validation Loss: 0.1435, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 92, Training Loss: 0.0303, Validation Loss: 0.1341, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 93, Training Loss: 0.0260, Validation Loss: 0.1438, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 94, Training Loss: 0.0272, Validation Loss: 0.1459, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 95, Training Loss: 0.0336, Validation Loss: 0.1469, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 96, Training Loss: 0.0365, Validation Loss: 0.1397, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 97, Training Loss: 0.0274, Validation Loss: 0.1523, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 98, Training Loss: 0.0185, Validation Loss: 0.1568, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 99, Training Loss: 0.0260, Validation Loss: 0.1570, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 100, Training Loss: 0.0182, Validation Loss: 0.1454, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Running decreased_branch_complexity classification training with alpha = 0.5 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.1338, Validation Loss: 2.8299, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 1.7812, Validation Loss: 1.1754, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 1.2987, Validation Loss: 0.8566, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.0559, Validation Loss: 0.7916, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 0.9103, Validation Loss: 0.6107, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 0.7895, Validation Loss: 0.6039, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 0.7023, Validation Loss: 0.6032, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 0.6509, Validation Loss: 0.5327, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 0.6008, Validation Loss: 0.3795, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 0.5315, Validation Loss: 0.3968, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.5162, Validation Loss: 0.3842, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.4588, Validation Loss: 0.3602, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.4262, Validation Loss: 0.3351, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.3965, Validation Loss: 0.2515, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.3757, Validation Loss: 0.2629, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.3500, Validation Loss: 0.2688, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.2953, Validation Loss: 0.2055, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.3191, Validation Loss: 0.4183, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.2797, Validation Loss: 0.1983, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.2903, Validation Loss: 0.1932, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.3013, Validation Loss: 0.2304, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.2879, Validation Loss: 0.1971, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.2637, Validation Loss: 0.2301, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.2874, Validation Loss: 0.2626, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.3033, Validation Loss: 0.2445, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.2453, Validation Loss: 0.2598, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.2499, Validation Loss: 0.2618, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.3127, Validation Loss: 0.1998, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.1968, Validation Loss: 0.1902, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.3089, Validation Loss: 0.2471, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.2338, Validation Loss: 0.1789, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.1830, Validation Loss: 0.1620, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.2265, Validation Loss: 0.1687, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.1927, Validation Loss: 0.1717, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.1495, Validation Loss: 0.2502, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.1436, Validation Loss: 0.1782, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.1519, Validation Loss: 0.1886, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.1663, Validation Loss: 0.1631, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.1495, Validation Loss: 0.1568, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.1308, Validation Loss: 0.1530, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.1570, Validation Loss: 0.1940, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.1679, Validation Loss: 0.1941, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.1419, Validation Loss: 0.1832, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.1515, Validation Loss: 0.1996, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.1496, Validation Loss: 0.2410, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.1194, Validation Loss: 0.1739, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.1631, Validation Loss: 0.2128, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.1222, Validation Loss: 0.1448, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.0854, Validation Loss: 0.2620, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.1310, Validation Loss: 0.2681, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.1353, Validation Loss: 0.2009, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.1011, Validation Loss: 0.1886, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.1025, Validation Loss: 0.2040, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.1062, Validation Loss: 0.1832, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.1157, Validation Loss: 0.1914, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.1274, Validation Loss: 0.1504, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.1029, Validation Loss: 0.1720, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.1113, Validation Loss: 0.1771, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.1113, Validation Loss: 0.2004, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.0990, Validation Loss: 0.1634, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.0634, Validation Loss: 0.1374, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.0523, Validation Loss: 0.1380, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.0567, Validation Loss: 0.1369, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.0357, Validation Loss: 0.1287, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.0450, Validation Loss: 0.1245, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.0379, Validation Loss: 0.1292, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.0500, Validation Loss: 0.1284, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.0394, Validation Loss: 0.1320, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.0391, Validation Loss: 0.1312, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.0337, Validation Loss: 0.1403, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.0278, Validation Loss: 0.1385, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.0311, Validation Loss: 0.1317, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.0315, Validation Loss: 0.1401, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.0280, Validation Loss: 0.1349, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.0214, Validation Loss: 0.1285, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.0233, Validation Loss: 0.1302, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.0363, Validation Loss: 0.1240, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.0352, Validation Loss: 0.1287, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.0326, Validation Loss: 0.1266, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.0276, Validation Loss: 0.1270, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.0271, Validation Loss: 0.1245, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.0250, Validation Loss: 0.1259, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.0228, Validation Loss: 0.1274, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.0355, Validation Loss: 0.1257, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0302, Validation Loss: 0.1246, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.0202, Validation Loss: 0.1246, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.0311, Validation Loss: 0.1241, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0293, Validation Loss: 0.1261, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.0359, Validation Loss: 0.1245, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.0241, Validation Loss: 0.1262, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.0231, Validation Loss: 0.1251, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.0267, Validation Loss: 0.1243, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.0310, Validation Loss: 0.1269, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 94, Training Loss: 0.0272, Validation Loss: 0.1251, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 95, Training Loss: 0.0247, Validation Loss: 0.1247, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 96, Training Loss: 0.0243, Validation Loss: 0.1274, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 97, Training Loss: 0.0219, Validation Loss: 0.1286, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Early stopping triggered.
Running decreased_branch_complexity classification training with alpha = 0.8 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 2.7100, Validation Loss: 2.5207, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 1.5362, Validation Loss: 1.0756, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.1499, Validation Loss: 0.7524, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 0.9282, Validation Loss: 0.7194, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 0.7958, Validation Loss: 0.5020, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 0.6398, Validation Loss: 0.5108, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 0.5940, Validation Loss: 0.4103, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 0.5434, Validation Loss: 0.3609, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.4908, Validation Loss: 0.3313, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.4745, Validation Loss: 0.2433, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.4101, Validation Loss: 0.3747, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.3532, Validation Loss: 0.2469, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.3637, Validation Loss: 0.2623, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.3507, Validation Loss: 0.1835, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.3602, Validation Loss: 0.3194, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.2928, Validation Loss: 0.2560, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.3171, Validation Loss: 0.1949, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.3117, Validation Loss: 0.2249, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.2951, Validation Loss: 0.1723, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.2789, Validation Loss: 0.1996, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.3028, Validation Loss: 0.2072, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.2290, Validation Loss: 0.2081, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.2346, Validation Loss: 0.1693, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.2296, Validation Loss: 0.1668, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.2263, Validation Loss: 0.2016, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.2064, Validation Loss: 0.1480, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.1950, Validation Loss: 0.1672, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.2262, Validation Loss: 0.1923, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.2106, Validation Loss: 0.1464, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.1829, Validation Loss: 0.1697, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.2213, Validation Loss: 0.1858, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.2356, Validation Loss: 0.1516, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.1850, Validation Loss: 0.1670, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.1887, Validation Loss: 0.1436, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.1917, Validation Loss: 0.1141, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.1513, Validation Loss: 0.1512, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.1657, Validation Loss: 0.1270, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.1623, Validation Loss: 0.1767, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.1656, Validation Loss: 0.1691, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.1518, Validation Loss: 0.1636, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.1679, Validation Loss: 0.1266, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.1384, Validation Loss: 0.1156, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.1307, Validation Loss: 0.1753, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.1399, Validation Loss: 0.1726, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.1896, Validation Loss: 0.1469, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.0996, Validation Loss: 0.1180, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.1028, Validation Loss: 0.1032, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.0704, Validation Loss: 0.1035, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.0778, Validation Loss: 0.1113, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.0569, Validation Loss: 0.1059, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.0705, Validation Loss: 0.0996, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.0611, Validation Loss: 0.1025, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.0502, Validation Loss: 0.1038, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.0394, Validation Loss: 0.1039, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.0480, Validation Loss: 0.0991, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.0569, Validation Loss: 0.1047, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.0394, Validation Loss: 0.0989, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.0369, Validation Loss: 0.0999, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.0422, Validation Loss: 0.0993, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.0524, Validation Loss: 0.1023, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.0459, Validation Loss: 0.1033, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.0398, Validation Loss: 0.1047, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.0518, Validation Loss: 0.1114, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.0379, Validation Loss: 0.1060, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.0373, Validation Loss: 0.1052, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.0579, Validation Loss: 0.1140, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.0478, Validation Loss: 0.1074, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.0370, Validation Loss: 0.1059, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.0314, Validation Loss: 0.1120, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.0428, Validation Loss: 0.1082, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.0324, Validation Loss: 0.1096, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.0335, Validation Loss: 0.1067, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.0401, Validation Loss: 0.1026, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.0333, Validation Loss: 0.1019, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.0298, Validation Loss: 0.1048, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.0249, Validation Loss: 0.1024, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.0402, Validation Loss: 0.1053, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Early stopping triggered.
Running decreased_branch_complexity classification training with alpha = 1 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 2.4753, Validation Loss: 2.1553, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 1.3965, Validation Loss: 1.0808, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.0040, Validation Loss: 0.7319, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 0.7654, Validation Loss: 0.5419, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 0.6603, Validation Loss: 0.5068, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 0.6366, Validation Loss: 0.5232, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 0.5208, Validation Loss: 0.3538, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.4496, Validation Loss: 0.3332, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.4434, Validation Loss: 0.3209, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.3905, Validation Loss: 0.3423, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.3979, Validation Loss: 0.2859, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.3407, Validation Loss: 0.2312, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.3193, Validation Loss: 0.2396, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.3181, Validation Loss: 0.2166, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.2756, Validation Loss: 0.2134, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.3086, Validation Loss: 0.2599, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.3223, Validation Loss: 0.2397, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.2863, Validation Loss: 0.3043, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.2897, Validation Loss: 0.1977, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.2428, Validation Loss: 0.2076, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.2068, Validation Loss: 0.1837, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.2393, Validation Loss: 0.2343, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.2218, Validation Loss: 0.1789, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.2020, Validation Loss: 0.2233, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.1848, Validation Loss: 0.1598, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.1498, Validation Loss: 0.2205, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.2117, Validation Loss: 0.1495, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.2196, Validation Loss: 0.2203, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.1924, Validation Loss: 0.1601, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.1908, Validation Loss: 0.1383, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.1663, Validation Loss: 0.1518, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.1502, Validation Loss: 0.1784, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.1362, Validation Loss: 0.1661, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.1738, Validation Loss: 0.2272, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.1477, Validation Loss: 0.1375, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.1578, Validation Loss: 0.1534, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.1660, Validation Loss: 0.1319, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.1504, Validation Loss: 0.1908, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.1640, Validation Loss: 0.1508, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.1168, Validation Loss: 0.1271, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.0912, Validation Loss: 0.1119, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.1095, Validation Loss: 0.1360, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.1373, Validation Loss: 0.1975, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.1185, Validation Loss: 0.1556, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.1245, Validation Loss: 0.1258, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.0931, Validation Loss: 0.1204, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.1007, Validation Loss: 0.1405, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.0849, Validation Loss: 0.1699, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.0985, Validation Loss: 0.1038, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.1000, Validation Loss: 0.1233, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.1153, Validation Loss: 0.1018, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.0764, Validation Loss: 0.1194, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.0871, Validation Loss: 0.1433, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.0898, Validation Loss: 0.1565, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.0689, Validation Loss: 0.1231, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.0634, Validation Loss: 0.1198, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.0661, Validation Loss: 0.1127, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.0559, Validation Loss: 0.1469, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.0607, Validation Loss: 0.1206, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.0544, Validation Loss: 0.1181, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.0647, Validation Loss: 0.1673, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.0804, Validation Loss: 0.2066, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.0748, Validation Loss: 0.1134, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.0421, Validation Loss: 0.0992, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.0359, Validation Loss: 0.1011, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.0316, Validation Loss: 0.0984, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.0249, Validation Loss: 0.0927, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.0295, Validation Loss: 0.0947, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.0224, Validation Loss: 0.0912, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.0220, Validation Loss: 0.0923, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.0241, Validation Loss: 0.0941, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.0264, Validation Loss: 0.0993, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.0154, Validation Loss: 0.1006, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.0252, Validation Loss: 0.0978, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.0228, Validation Loss: 0.0963, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.0189, Validation Loss: 0.1013, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.0188, Validation Loss: 0.0993, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.0177, Validation Loss: 0.0974, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.0190, Validation Loss: 0.1004, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.0180, Validation Loss: 0.1030, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.0203, Validation Loss: 0.1028, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.0176, Validation Loss: 0.1004, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.0170, Validation Loss: 0.0958, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.0186, Validation Loss: 0.0969, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0238, Validation Loss: 0.0992, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.0236, Validation Loss: 0.0980, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.0149, Validation Loss: 0.0989, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.0143, Validation Loss: 0.1000, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.0199, Validation Loss: 0.0986, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Early stopping triggered.
Running increased_features_complexity experiments:
Running increased_features_complexity classification training with alpha = 0 using script scripts/increased_features_complexity/hierarchical-classification-training.py
Traceback (most recent call last):
  File "/home/bcw/gits/FjordVision/scripts/increased_features_complexity/hierarchical-classification-training.py", line 65, in <module>
    model = HierarchicalCNN(num_classes_hierarchy, num_additional_features, dropout_rate=args.dropout_rate).to(device)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/hierarchical_cnn.py", line 95, in __init__
    self.binary_branch = BranchCNN(64 + num_additional_features, num_classes_hierarchy[0], dropout_rate)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/branch_cnn.py", line 16, in __init__
    nn.Linear(combined_features_size, 4096),
  File "/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 98, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
TypeError: empty(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got float"
Error running increased_features_complexity classification training with alpha = 0
Running increased_features_complexity classification training with alpha = 0.2 using script scripts/increased_features_complexity/hierarchical-classification-training.py
Traceback (most recent call last):
  File "/home/bcw/gits/FjordVision/scripts/increased_features_complexity/hierarchical-classification-training.py", line 65, in <module>
    model = HierarchicalCNN(num_classes_hierarchy, num_additional_features, dropout_rate=args.dropout_rate).to(device)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/hierarchical_cnn.py", line 95, in __init__
    self.binary_branch = BranchCNN(64 + num_additional_features, num_classes_hierarchy[0], dropout_rate)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/branch_cnn.py", line 16, in __init__
    nn.Linear(combined_features_size, 4096),
  File "/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 98, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
TypeError: empty(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got float"
Error running increased_features_complexity classification training with alpha = 0.2
Running increased_features_complexity classification training with alpha = 0.5 using script scripts/increased_features_complexity/hierarchical-classification-training.py
Traceback (most recent call last):
  File "/home/bcw/gits/FjordVision/scripts/increased_features_complexity/hierarchical-classification-training.py", line 65, in <module>
    model = HierarchicalCNN(num_classes_hierarchy, num_additional_features, dropout_rate=args.dropout_rate).to(device)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/hierarchical_cnn.py", line 95, in __init__
    self.binary_branch = BranchCNN(64 + num_additional_features, num_classes_hierarchy[0], dropout_rate)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/branch_cnn.py", line 16, in __init__
    nn.Linear(combined_features_size, 4096),
  File "/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 98, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
TypeError: empty(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got float"
Error running increased_features_complexity classification training with alpha = 0.5
Running increased_features_complexity classification training with alpha = 0.8 using script scripts/increased_features_complexity/hierarchical-classification-training.py
Traceback (most recent call last):
  File "/home/bcw/gits/FjordVision/scripts/increased_features_complexity/hierarchical-classification-training.py", line 65, in <module>
    model = HierarchicalCNN(num_classes_hierarchy, num_additional_features, dropout_rate=args.dropout_rate).to(device)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/hierarchical_cnn.py", line 95, in __init__
    self.binary_branch = BranchCNN(64 + num_additional_features, num_classes_hierarchy[0], dropout_rate)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/branch_cnn.py", line 16, in __init__
    nn.Linear(combined_features_size, 4096),
  File "/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 98, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
TypeError: empty(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got float"
Error running increased_features_complexity classification training with alpha = 0.8
Running increased_features_complexity classification training with alpha = 1 using script scripts/increased_features_complexity/hierarchical-classification-training.py
Traceback (most recent call last):
  File "/home/bcw/gits/FjordVision/scripts/increased_features_complexity/hierarchical-classification-training.py", line 65, in <module>
    model = HierarchicalCNN(num_classes_hierarchy, num_additional_features, dropout_rate=args.dropout_rate).to(device)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/hierarchical_cnn.py", line 95, in __init__
    self.binary_branch = BranchCNN(64 + num_additional_features, num_classes_hierarchy[0], dropout_rate)
  File "/home/bcw/gits/FjordVision/./models/ablations/increased_features_complexity/branch_cnn.py", line 16, in __init__
    nn.Linear(combined_features_size, 4096),
  File "/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 98, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
TypeError: empty(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got float"
Error running increased_features_complexity classification training with alpha = 1
Experiment finished at Mon Jun 24 20:13:47 CEST 2024
