Experiment started at Wed Jun 26 14:52:15 CEST 2024
Running attention_removed experiments:
Running attention_removed classification training with alpha = 0 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.3976, Validation Loss: 4.7527, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 4.2770, Validation Loss: 2.9581, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 3.2637, Validation Loss: 2.2196, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.8005, Validation Loss: 1.8564, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.3027, Validation Loss: 1.5274, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.2275, Validation Loss: 1.3320, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.8691, Validation Loss: 1.1409, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.7643, Validation Loss: 0.9457, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.5373, Validation Loss: 0.8938, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.4943, Validation Loss: 0.8079, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.3440, Validation Loss: 0.6783, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.1976, Validation Loss: 0.5947, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.1018, Validation Loss: 0.5638, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 0.9816, Validation Loss: 0.4576, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.0587, Validation Loss: 0.5140, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 1.1261, Validation Loss: 0.4322, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 0.9608, Validation Loss: 0.4659, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.8583, Validation Loss: 0.4728, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.8157, Validation Loss: 0.3799, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.8301, Validation Loss: 0.3492, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.9049, Validation Loss: 0.4115, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.7353, Validation Loss: 0.3465, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.7958, Validation Loss: 0.3202, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.8572, Validation Loss: 0.3423, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.6990, Validation Loss: 0.3173, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.6356, Validation Loss: 0.3230, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.6445, Validation Loss: 0.2864, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.6568, Validation Loss: 0.2799, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.6349, Validation Loss: 0.3802, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.6860, Validation Loss: 0.3141, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.5328, Validation Loss: 0.3244, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.5791, Validation Loss: 0.3206, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.5696, Validation Loss: 0.2513, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.5351, Validation Loss: 0.2366, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.4903, Validation Loss: 0.2162, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.5327, Validation Loss: 0.2190, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.4936, Validation Loss: 0.3944, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.5444, Validation Loss: 0.2614, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.5054, Validation Loss: 0.2700, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.4777, Validation Loss: 0.1891, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.5582, Validation Loss: 0.4056, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.5938, Validation Loss: 0.3931, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.3822, Validation Loss: 0.2248, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.4430, Validation Loss: 0.2958, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.3923, Validation Loss: 0.2067, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.3435, Validation Loss: 0.2205, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.4020, Validation Loss: 0.2375, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.3930, Validation Loss: 0.2712, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.3837, Validation Loss: 0.2039, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.4098, Validation Loss: 0.2159, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.3602, Validation Loss: 0.2179, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.3012, Validation Loss: 0.1690, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.2707, Validation Loss: 0.1534, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.2164, Validation Loss: 0.1463, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.2091, Validation Loss: 0.1468, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.2394, Validation Loss: 0.1463, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.2909, Validation Loss: 0.1383, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.2282, Validation Loss: 0.1347, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.2135, Validation Loss: 0.1481, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.1766, Validation Loss: 0.1449, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.1601, Validation Loss: 0.1483, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.1924, Validation Loss: 0.1466, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.2023, Validation Loss: 0.1421, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.1943, Validation Loss: 0.1359, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.2026, Validation Loss: 0.1376, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.1886, Validation Loss: 0.1513, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.1937, Validation Loss: 0.1518, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.1845, Validation Loss: 0.1449, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.1957, Validation Loss: 0.1424, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.2459, Validation Loss: 0.1448, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.1535, Validation Loss: 0.1360, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.1992, Validation Loss: 0.1381, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.1600, Validation Loss: 0.1432, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.1987, Validation Loss: 0.1419, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.2035, Validation Loss: 0.1398, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.1554, Validation Loss: 0.1465, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.1652, Validation Loss: 0.1446, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.1469, Validation Loss: 0.1413, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Early stopping triggered.
Running attention_removed classification training with alpha = 0.2 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.3776, Validation Loss: 4.2319, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.5235, Validation Loss: 2.5011, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.7233, Validation Loss: 1.9132, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.2773, Validation Loss: 1.6301, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 2.0038, Validation Loss: 1.4472, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.8579, Validation Loss: 1.1893, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.5796, Validation Loss: 1.0033, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.4481, Validation Loss: 0.8600, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.3150, Validation Loss: 0.7791, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.2238, Validation Loss: 0.8444, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.1225, Validation Loss: 0.5483, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.0272, Validation Loss: 0.5753, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 0.9081, Validation Loss: 0.5795, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 0.9436, Validation Loss: 0.5383, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.7718, Validation Loss: 0.3307, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.7366, Validation Loss: 0.4217, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.6572, Validation Loss: 0.3414, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.7306, Validation Loss: 0.3469, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.7077, Validation Loss: 0.2678, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.6360, Validation Loss: 0.4249, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.6991, Validation Loss: 0.2776, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.6576, Validation Loss: 0.3602, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.6971, Validation Loss: 0.2827, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.6624, Validation Loss: 0.3099, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.5529, Validation Loss: 0.2606, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.5295, Validation Loss: 0.2232, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.5677, Validation Loss: 0.6664, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.5330, Validation Loss: 0.2038, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.5071, Validation Loss: 0.2785, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.4722, Validation Loss: 0.2675, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.4901, Validation Loss: 0.2216, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.4491, Validation Loss: 0.2107, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.4286, Validation Loss: 0.2470, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.4588, Validation Loss: 0.2619, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.4719, Validation Loss: 0.2299, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.4577, Validation Loss: 0.2632, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.4039, Validation Loss: 0.2591, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.3613, Validation Loss: 0.1881, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.3402, Validation Loss: 0.1544, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.3692, Validation Loss: 0.1746, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.4716, Validation Loss: 0.2150, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.4409, Validation Loss: 0.1897, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.3369, Validation Loss: 0.1501, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.3844, Validation Loss: 0.3064, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.4437, Validation Loss: 0.1973, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.3651, Validation Loss: 0.2135, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.3688, Validation Loss: 0.1997, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.3260, Validation Loss: 0.2108, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.3474, Validation Loss: 0.2664, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.4061, Validation Loss: 0.1529, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.2911, Validation Loss: 0.1863, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.3381, Validation Loss: 0.1652, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.3719, Validation Loss: 0.1611, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.3215, Validation Loss: 0.2473, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.2693, Validation Loss: 0.1425, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.2249, Validation Loss: 0.1267, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.2086, Validation Loss: 0.1187, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.1961, Validation Loss: 0.1182, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.2088, Validation Loss: 0.1106, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.1954, Validation Loss: 0.1082, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.2162, Validation Loss: 0.1158, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.1324, Validation Loss: 0.1216, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.1701, Validation Loss: 0.1057, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.1774, Validation Loss: 0.1074, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.1410, Validation Loss: 0.1081, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.1770, Validation Loss: 0.1082, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.1557, Validation Loss: 0.1074, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.1518, Validation Loss: 0.1117, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.1645, Validation Loss: 0.1050, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.1366, Validation Loss: 0.1067, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.1883, Validation Loss: 0.1115, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.1806, Validation Loss: 0.1069, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.1414, Validation Loss: 0.1037, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.1466, Validation Loss: 0.1021, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.1503, Validation Loss: 0.1182, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.1639, Validation Loss: 0.1047, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.1216, Validation Loss: 0.1045, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.1776, Validation Loss: 0.1075, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.1353, Validation Loss: 0.1091, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.1551, Validation Loss: 0.0964, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.1658, Validation Loss: 0.0974, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.1446, Validation Loss: 0.1085, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.1166, Validation Loss: 0.1060, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.1667, Validation Loss: 0.1045, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.1088, Validation Loss: 0.0973, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.1081, Validation Loss: 0.1119, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.1252, Validation Loss: 0.1055, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.1213, Validation Loss: 0.1063, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.1272, Validation Loss: 0.1127, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 90, Training Loss: 0.1157, Validation Loss: 0.1072, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 91, Training Loss: 0.1116, Validation Loss: 0.1085, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 92, Training Loss: 0.1322, Validation Loss: 0.1038, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 93, Training Loss: 0.1212, Validation Loss: 0.1014, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 94, Training Loss: 0.1408, Validation Loss: 0.1033, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 95, Training Loss: 0.0956, Validation Loss: 0.1022, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 96, Training Loss: 0.1205, Validation Loss: 0.1000, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 97, Training Loss: 0.1012, Validation Loss: 0.1016, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 98, Training Loss: 0.1182, Validation Loss: 0.1076, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 99, Training Loss: 0.1050, Validation Loss: 0.1028, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 100, Training Loss: 0.0819, Validation Loss: 0.1050, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Early stopping triggered.
Running attention_removed classification training with alpha = 0.5 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1915, Validation Loss: 3.1430, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.8722, Validation Loss: 1.9894, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 2.1992, Validation Loss: 1.5491, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.8907, Validation Loss: 1.3905, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.6252, Validation Loss: 1.2182, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.4862, Validation Loss: 1.0290, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.3006, Validation Loss: 0.8425, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.2484, Validation Loss: 0.7856, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.1742, Validation Loss: 0.6735, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 1.0602, Validation Loss: 0.6705, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.9857, Validation Loss: 0.5713, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.9713, Validation Loss: 0.6164, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.9343, Validation Loss: 0.5808, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.8665, Validation Loss: 0.4526, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.7192, Validation Loss: 0.3833, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.6267, Validation Loss: 0.3484, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.6471, Validation Loss: 0.3038, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.5771, Validation Loss: 0.3202, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.6271, Validation Loss: 0.4423, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.5914, Validation Loss: 0.2381, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.4618, Validation Loss: 0.2382, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.5690, Validation Loss: 0.2372, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.4623, Validation Loss: 0.2136, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.4630, Validation Loss: 0.1999, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.4712, Validation Loss: 0.1839, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.4378, Validation Loss: 0.1960, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.3947, Validation Loss: 0.1928, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.4180, Validation Loss: 0.1646, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.3993, Validation Loss: 0.2485, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.3213, Validation Loss: 0.2414, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.3939, Validation Loss: 0.1562, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.3783, Validation Loss: 0.1648, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.4159, Validation Loss: 0.2067, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.3264, Validation Loss: 0.1929, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.3083, Validation Loss: 0.2137, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.3648, Validation Loss: 0.1680, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.3243, Validation Loss: 0.1420, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.3253, Validation Loss: 0.1837, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.3679, Validation Loss: 0.1473, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.3352, Validation Loss: 0.1390, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.2756, Validation Loss: 0.1335, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.3058, Validation Loss: 0.1356, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.2699, Validation Loss: 0.1571, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.3046, Validation Loss: 0.1483, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.2471, Validation Loss: 0.1617, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.2332, Validation Loss: 0.1383, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.2838, Validation Loss: 0.1332, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.2784, Validation Loss: 0.1399, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.2629, Validation Loss: 0.1767, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.2638, Validation Loss: 0.1291, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.2023, Validation Loss: 0.1460, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.2803, Validation Loss: 0.2164, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.2524, Validation Loss: 0.1371, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.2601, Validation Loss: 0.1290, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.1939, Validation Loss: 0.1362, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.2228, Validation Loss: 0.1215, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.2287, Validation Loss: 0.1171, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.2175, Validation Loss: 0.1669, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.2783, Validation Loss: 0.1498, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.2011, Validation Loss: 0.1122, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.2197, Validation Loss: 0.1930, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.2990, Validation Loss: 0.1384, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.1894, Validation Loss: 0.1360, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.1754, Validation Loss: 0.1486, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.2359, Validation Loss: 0.1497, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.1809, Validation Loss: 0.1508, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.1862, Validation Loss: 0.1461, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.2166, Validation Loss: 0.1428, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.1845, Validation Loss: 0.1424, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.1930, Validation Loss: 0.0964, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.1764, Validation Loss: 0.1249, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.2008, Validation Loss: 0.1550, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.2192, Validation Loss: 0.1291, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.1647, Validation Loss: 0.1084, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.1670, Validation Loss: 0.1525, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.1556, Validation Loss: 0.1249, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.2128, Validation Loss: 0.1270, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.1944, Validation Loss: 0.1296, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.1741, Validation Loss: 0.1126, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.1523, Validation Loss: 0.1139, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.1519, Validation Loss: 0.1419, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.1112, Validation Loss: 0.1264, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.1082, Validation Loss: 0.1144, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.0991, Validation Loss: 0.1091, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0894, Validation Loss: 0.1087, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.1019, Validation Loss: 0.1059, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.0803, Validation Loss: 0.1017, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0664, Validation Loss: 0.1033, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.0844, Validation Loss: 0.1033, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.0751, Validation Loss: 0.1012, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Early stopping triggered.
Running attention_removed classification training with alpha = 0.8 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.5118, Validation Loss: 2.7093, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 2.4332, Validation Loss: 1.7564, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.9236, Validation Loss: 1.5104, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.6362, Validation Loss: 1.1399, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.4193, Validation Loss: 1.0616, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.2559, Validation Loss: 0.8881, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.0928, Validation Loss: 0.7603, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.0334, Validation Loss: 0.5776, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.9016, Validation Loss: 0.6181, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.8975, Validation Loss: 0.6657, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.8131, Validation Loss: 0.6242, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.8074, Validation Loss: 0.4358, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.7002, Validation Loss: 0.3823, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.6645, Validation Loss: 0.4426, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.6059, Validation Loss: 0.2995, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.5696, Validation Loss: 0.4091, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.5574, Validation Loss: 0.3123, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.5119, Validation Loss: 0.3266, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.5450, Validation Loss: 0.4484, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.5083, Validation Loss: 0.2078, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.4264, Validation Loss: 0.2817, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.5043, Validation Loss: 0.3801, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.4743, Validation Loss: 0.2541, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.4621, Validation Loss: 0.2300, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.3762, Validation Loss: 0.2374, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.4228, Validation Loss: 0.3262, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.3931, Validation Loss: 0.1715, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.3454, Validation Loss: 0.1719, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.3524, Validation Loss: 0.2197, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.3053, Validation Loss: 0.1914, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.3684, Validation Loss: 0.1729, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.3338, Validation Loss: 0.1684, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.3219, Validation Loss: 0.2779, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.2641, Validation Loss: 0.1335, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.3301, Validation Loss: 0.1533, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.3066, Validation Loss: 0.1563, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.3591, Validation Loss: 0.1800, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.2537, Validation Loss: 0.1417, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.2625, Validation Loss: 0.0997, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.2542, Validation Loss: 0.1067, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.2493, Validation Loss: 0.1315, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.2744, Validation Loss: 0.1509, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.2697, Validation Loss: 0.1626, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.2323, Validation Loss: 0.1295, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.2400, Validation Loss: 0.1317, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.2646, Validation Loss: 0.1438, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.2214, Validation Loss: 0.1264, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.1981, Validation Loss: 0.1286, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.2251, Validation Loss: 0.1456, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.2251, Validation Loss: 0.1058, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.1700, Validation Loss: 0.0898, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.1529, Validation Loss: 0.0869, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.1408, Validation Loss: 0.0752, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.1162, Validation Loss: 0.0699, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.1885, Validation Loss: 0.0734, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.1110, Validation Loss: 0.0751, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.1786, Validation Loss: 0.0785, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.1244, Validation Loss: 0.0831, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.1136, Validation Loss: 0.0719, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.1184, Validation Loss: 0.0726, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.0958, Validation Loss: 0.0796, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.1365, Validation Loss: 0.0698, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.1011, Validation Loss: 0.0711, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.1150, Validation Loss: 0.0696, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.1099, Validation Loss: 0.0695, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.1171, Validation Loss: 0.0707, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.1007, Validation Loss: 0.0739, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.0917, Validation Loss: 0.0720, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.1146, Validation Loss: 0.0684, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.1119, Validation Loss: 0.0742, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.1106, Validation Loss: 0.0711, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.1127, Validation Loss: 0.0729, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.0993, Validation Loss: 0.0692, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.1218, Validation Loss: 0.0856, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.1177, Validation Loss: 0.0815, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.1040, Validation Loss: 0.0715, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.1162, Validation Loss: 0.0740, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.1172, Validation Loss: 0.0776, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.0944, Validation Loss: 0.0716, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.0879, Validation Loss: 0.0693, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.0832, Validation Loss: 0.0713, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.1102, Validation Loss: 0.0697, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.0864, Validation Loss: 0.0708, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.0801, Validation Loss: 0.0640, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.0977, Validation Loss: 0.0794, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.0823, Validation Loss: 0.0645, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.0908, Validation Loss: 0.0659, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.0889, Validation Loss: 0.0665, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.0801, Validation Loss: 0.0633, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.0727, Validation Loss: 0.0663, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.0969, Validation Loss: 0.0622, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.0824, Validation Loss: 0.0621, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.0890, Validation Loss: 0.0644, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.1009, Validation Loss: 0.0599, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.0779, Validation Loss: 0.0625, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.0771, Validation Loss: 0.0677, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.0850, Validation Loss: 0.0641, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 98, Training Loss: 0.0881, Validation Loss: 0.0598, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 99, Training Loss: 0.0715, Validation Loss: 0.0687, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 100, Training Loss: 0.0801, Validation Loss: 0.0650, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Running attention_removed classification training with alpha = 1 using script scripts/attention_removed/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.2462, Validation Loss: 2.5478, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 2.2981, Validation Loss: 1.8268, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.8762, Validation Loss: 1.3891, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.6274, Validation Loss: 1.2011, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.4161, Validation Loss: 1.1311, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.2950, Validation Loss: 0.9053, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 1.1642, Validation Loss: 0.8097, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 1.1099, Validation Loss: 0.7376, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.9963, Validation Loss: 0.6747, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 1.0053, Validation Loss: 0.6051, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.8844, Validation Loss: 0.5502, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.8147, Validation Loss: 0.4850, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.7632, Validation Loss: 0.4481, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.7282, Validation Loss: 0.4375, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.6404, Validation Loss: 0.3614, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.6872, Validation Loss: 0.4031, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.6298, Validation Loss: 0.3982, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.5573, Validation Loss: 0.2937, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.5429, Validation Loss: 0.2561, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.5868, Validation Loss: 0.3455, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.5278, Validation Loss: 0.2510, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.4363, Validation Loss: 0.2097, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.4422, Validation Loss: 0.2320, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.4095, Validation Loss: 0.1700, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.4031, Validation Loss: 0.1838, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.3894, Validation Loss: 0.1841, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.3754, Validation Loss: 0.1594, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.3739, Validation Loss: 0.1645, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.3178, Validation Loss: 0.1517, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.3411, Validation Loss: 0.1199, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.3609, Validation Loss: 0.1610, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.3702, Validation Loss: 0.1570, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.3942, Validation Loss: 0.1754, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.3799, Validation Loss: 0.2109, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.3437, Validation Loss: 0.1663, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.3118, Validation Loss: 0.1454, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.3067, Validation Loss: 0.1436, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.2888, Validation Loss: 0.1401, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.2755, Validation Loss: 0.1536, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.2625, Validation Loss: 0.1445, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.2988, Validation Loss: 0.1218, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.2020, Validation Loss: 0.0969, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.1815, Validation Loss: 0.0878, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.2140, Validation Loss: 0.0871, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.1904, Validation Loss: 0.0864, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.1763, Validation Loss: 0.0805, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.1932, Validation Loss: 0.0781, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.1599, Validation Loss: 0.0754, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.1772, Validation Loss: 0.0746, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.1576, Validation Loss: 0.0863, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.1332, Validation Loss: 0.0791, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.1232, Validation Loss: 0.0779, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.1167, Validation Loss: 0.0750, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.1496, Validation Loss: 0.0726, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.1632, Validation Loss: 0.0785, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.1249, Validation Loss: 0.0773, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.1500, Validation Loss: 0.0794, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.1370, Validation Loss: 0.0756, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.1209, Validation Loss: 0.0766, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.1609, Validation Loss: 0.0819, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.1198, Validation Loss: 0.0817, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.1322, Validation Loss: 0.0796, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.1185, Validation Loss: 0.0757, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.1129, Validation Loss: 0.0763, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.1119, Validation Loss: 0.0807, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.1383, Validation Loss: 0.0765, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.1110, Validation Loss: 0.0743, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.1192, Validation Loss: 0.0745, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.1004, Validation Loss: 0.0755, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.0977, Validation Loss: 0.0728, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.1049, Validation Loss: 0.0738, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.1037, Validation Loss: 0.0720, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.1207, Validation Loss: 0.0716, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.1193, Validation Loss: 0.0728, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.0976, Validation Loss: 0.0723, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.1032, Validation Loss: 0.0705, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.1199, Validation Loss: 0.0744, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.1140, Validation Loss: 0.0733, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.1117, Validation Loss: 0.0745, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.1165, Validation Loss: 0.0718, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.1030, Validation Loss: 0.0714, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.0973, Validation Loss: 0.0739, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.1246, Validation Loss: 0.0753, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.1106, Validation Loss: 0.0737, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0966, Validation Loss: 0.0734, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.1186, Validation Loss: 0.0752, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.1091, Validation Loss: 0.0754, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.0995, Validation Loss: 0.0739, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.1218, Validation Loss: 0.0735, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.1099, Validation Loss: 0.0751, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.1295, Validation Loss: 0.0730, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.1040, Validation Loss: 0.0784, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.1011, Validation Loss: 0.0765, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.1008, Validation Loss: 0.0766, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.1218, Validation Loss: 0.0713, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.1176, Validation Loss: 0.0719, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Early stopping triggered.
Running remove_features experiments:
Running remove_features classification training with alpha = 0 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 7.4733, Validation Loss: 8.0713, Alpha: 0.0000
Epoch: 2, Training Loss: 5.9309, Validation Loss: 7.1270, Alpha: 0.0000
Epoch: 3, Training Loss: 5.0737, Validation Loss: 4.8299, Alpha: 0.0000
Epoch: 4, Training Loss: 4.4705, Validation Loss: 3.7301, Alpha: 0.0000
Epoch: 5, Training Loss: 4.1044, Validation Loss: 3.6783, Alpha: 0.0000
Epoch: 6, Training Loss: 3.8920, Validation Loss: 3.6165, Alpha: 0.0000
Epoch: 7, Training Loss: 3.5499, Validation Loss: 2.9231, Alpha: 0.0000
Epoch: 8, Training Loss: 3.3578, Validation Loss: 2.6693, Alpha: 0.0000
Epoch: 9, Training Loss: 3.0672, Validation Loss: 2.6335, Alpha: 0.0000
Epoch: 10, Training Loss: 2.8909, Validation Loss: 2.5604, Alpha: 0.0000
Epoch: 11, Training Loss: 2.6495, Validation Loss: 2.1841, Alpha: 0.0000
Epoch: 12, Training Loss: 2.6068, Validation Loss: 2.2907, Alpha: 0.0000
Epoch: 13, Training Loss: 2.4284, Validation Loss: 2.1496, Alpha: 0.0000
Epoch: 14, Training Loss: 2.4066, Validation Loss: 2.0660, Alpha: 0.0000
Epoch: 15, Training Loss: 2.4112, Validation Loss: 1.9281, Alpha: 0.0000
Epoch: 16, Training Loss: 2.1132, Validation Loss: 1.9197, Alpha: 0.0000
Epoch: 17, Training Loss: 2.0901, Validation Loss: 1.9206, Alpha: 0.0000
Epoch: 18, Training Loss: 2.0046, Validation Loss: 1.8103, Alpha: 0.0000
Epoch: 19, Training Loss: 2.0261, Validation Loss: 1.9369, Alpha: 0.0000
Epoch: 20, Training Loss: 1.8373, Validation Loss: 1.4318, Alpha: 0.0000
Epoch: 21, Training Loss: 1.7682, Validation Loss: 1.6730, Alpha: 0.0000
Epoch: 22, Training Loss: 1.7461, Validation Loss: 1.6343, Alpha: 0.0000
Epoch: 23, Training Loss: 1.7029, Validation Loss: 1.5163, Alpha: 0.0000
Epoch: 24, Training Loss: 1.5293, Validation Loss: 1.3337, Alpha: 0.0000
Epoch: 25, Training Loss: 1.5816, Validation Loss: 1.3060, Alpha: 0.0000
Epoch: 26, Training Loss: 1.5707, Validation Loss: 1.2381, Alpha: 0.0000
Epoch: 27, Training Loss: 1.3954, Validation Loss: 1.3533, Alpha: 0.0000
Epoch: 28, Training Loss: 1.4914, Validation Loss: 1.3295, Alpha: 0.0000
Epoch: 29, Training Loss: 1.4443, Validation Loss: 1.5670, Alpha: 0.0000
Epoch: 30, Training Loss: 1.3220, Validation Loss: 1.2906, Alpha: 0.0000
Epoch: 31, Training Loss: 1.3224, Validation Loss: 1.4995, Alpha: 0.0000
Epoch: 32, Training Loss: 1.2988, Validation Loss: 1.0564, Alpha: 0.0000
Epoch: 33, Training Loss: 1.3095, Validation Loss: 1.3147, Alpha: 0.0000
Epoch: 34, Training Loss: 1.3002, Validation Loss: 1.3491, Alpha: 0.0000
Epoch: 35, Training Loss: 1.2437, Validation Loss: 1.1052, Alpha: 0.0000
Epoch: 36, Training Loss: 1.2676, Validation Loss: 1.2373, Alpha: 0.0000
Epoch: 37, Training Loss: 1.1890, Validation Loss: 1.2188, Alpha: 0.0000
Epoch: 38, Training Loss: 1.1179, Validation Loss: 1.2000, Alpha: 0.0000
Epoch: 39, Training Loss: 1.1905, Validation Loss: 1.2806, Alpha: 0.0000
Epoch: 40, Training Loss: 1.0806, Validation Loss: 1.1595, Alpha: 0.0000
Epoch: 41, Training Loss: 0.9787, Validation Loss: 1.1088, Alpha: 0.0000
Epoch: 42, Training Loss: 0.9555, Validation Loss: 1.2627, Alpha: 0.0000
Epoch: 43, Training Loss: 0.9989, Validation Loss: 1.0320, Alpha: 0.0000
Epoch: 44, Training Loss: 0.9994, Validation Loss: 1.3891, Alpha: 0.0000
Epoch: 45, Training Loss: 0.9958, Validation Loss: 1.1412, Alpha: 0.0000
Epoch: 46, Training Loss: 0.9924, Validation Loss: 1.1170, Alpha: 0.0000
Epoch: 47, Training Loss: 0.9061, Validation Loss: 1.1673, Alpha: 0.0000
Epoch: 48, Training Loss: 0.9561, Validation Loss: 0.9468, Alpha: 0.0000
Epoch: 49, Training Loss: 0.8901, Validation Loss: 1.1315, Alpha: 0.0000
Epoch: 50, Training Loss: 0.8397, Validation Loss: 1.1003, Alpha: 0.0000
Epoch: 51, Training Loss: 0.9745, Validation Loss: 1.0625, Alpha: 0.0000
Epoch: 52, Training Loss: 0.8549, Validation Loss: 1.1843, Alpha: 0.0000
Epoch: 53, Training Loss: 0.7864, Validation Loss: 1.0841, Alpha: 0.0000
Epoch: 54, Training Loss: 0.8153, Validation Loss: 1.0358, Alpha: 0.0000
Epoch: 55, Training Loss: 0.6985, Validation Loss: 1.2603, Alpha: 0.0000
Epoch: 56, Training Loss: 0.6805, Validation Loss: 0.9547, Alpha: 0.0000
Epoch: 57, Training Loss: 0.6545, Validation Loss: 1.0519, Alpha: 0.0000
Epoch: 58, Training Loss: 0.6321, Validation Loss: 1.0945, Alpha: 0.0000
Epoch: 59, Training Loss: 0.7679, Validation Loss: 1.3494, Alpha: 0.0000
Epoch: 60, Training Loss: 0.6325, Validation Loss: 0.8192, Alpha: 0.0000
Epoch: 61, Training Loss: 0.5575, Validation Loss: 0.7304, Alpha: 0.0000
Epoch: 62, Training Loss: 0.4104, Validation Loss: 0.7038, Alpha: 0.0000
Epoch: 63, Training Loss: 0.3643, Validation Loss: 0.6814, Alpha: 0.0000
Epoch: 64, Training Loss: 0.3672, Validation Loss: 0.6668, Alpha: 0.0000
Epoch: 65, Training Loss: 0.3305, Validation Loss: 0.6541, Alpha: 0.0000
Epoch: 66, Training Loss: 0.3587, Validation Loss: 0.6618, Alpha: 0.0000
Epoch: 67, Training Loss: 0.3270, Validation Loss: 0.6341, Alpha: 0.0000
Epoch: 68, Training Loss: 0.2886, Validation Loss: 0.6284, Alpha: 0.0000
Epoch: 69, Training Loss: 0.2953, Validation Loss: 0.6387, Alpha: 0.0000
Epoch: 70, Training Loss: 0.3028, Validation Loss: 0.6380, Alpha: 0.0000
Epoch: 71, Training Loss: 0.3407, Validation Loss: 0.6198, Alpha: 0.0000
Epoch: 72, Training Loss: 0.3014, Validation Loss: 0.6114, Alpha: 0.0000
Epoch: 73, Training Loss: 0.2933, Validation Loss: 0.6472, Alpha: 0.0000
Epoch: 74, Training Loss: 0.2454, Validation Loss: 0.6501, Alpha: 0.0000
Epoch: 75, Training Loss: 0.2977, Validation Loss: 0.6612, Alpha: 0.0000
Epoch: 76, Training Loss: 0.2628, Validation Loss: 0.6381, Alpha: 0.0000
Epoch: 77, Training Loss: 0.2247, Validation Loss: 0.6258, Alpha: 0.0000
Epoch: 78, Training Loss: 0.2535, Validation Loss: 0.6356, Alpha: 0.0000
Epoch: 79, Training Loss: 0.2645, Validation Loss: 0.6303, Alpha: 0.0000
Epoch: 80, Training Loss: 0.2650, Validation Loss: 0.6437, Alpha: 0.0000
Epoch: 81, Training Loss: 0.2382, Validation Loss: 0.6270, Alpha: 0.0000
Epoch: 82, Training Loss: 0.2131, Validation Loss: 0.6346, Alpha: 0.0000
Epoch: 83, Training Loss: 0.2299, Validation Loss: 0.6078, Alpha: 0.0000
Epoch: 84, Training Loss: 0.2074, Validation Loss: 0.6480, Alpha: 0.0000
Epoch: 85, Training Loss: 0.2349, Validation Loss: 0.6276, Alpha: 0.0000
Epoch: 86, Training Loss: 0.2362, Validation Loss: 0.6264, Alpha: 0.0000
Epoch: 87, Training Loss: 0.2052, Validation Loss: 0.6187, Alpha: 0.0000
Epoch: 88, Training Loss: 0.2255, Validation Loss: 0.6136, Alpha: 0.0000
Epoch: 89, Training Loss: 0.1910, Validation Loss: 0.6190, Alpha: 0.0000
Epoch: 90, Training Loss: 0.1894, Validation Loss: 0.6167, Alpha: 0.0000
Epoch: 91, Training Loss: 0.1796, Validation Loss: 0.5992, Alpha: 0.0000
Epoch: 92, Training Loss: 0.1871, Validation Loss: 0.6294, Alpha: 0.0000
Epoch: 93, Training Loss: 0.1879, Validation Loss: 0.6114, Alpha: 0.0000
Epoch: 94, Training Loss: 0.1890, Validation Loss: 0.6162, Alpha: 0.0000
Epoch: 95, Training Loss: 0.2032, Validation Loss: 0.6001, Alpha: 0.0000
Epoch: 96, Training Loss: 0.1899, Validation Loss: 0.6302, Alpha: 0.0000
Epoch: 97, Training Loss: 0.1754, Validation Loss: 0.6420, Alpha: 0.0000
Epoch: 98, Training Loss: 0.1563, Validation Loss: 0.6255, Alpha: 0.0000
Epoch: 99, Training Loss: 0.1835, Validation Loss: 0.6520, Alpha: 0.0000
Epoch: 100, Training Loss: 0.1680, Validation Loss: 0.6228, Alpha: 0.0000
Running remove_features classification training with alpha = 0.2 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.1637, Validation Loss: 6.2592, Alpha: 0.2000
Epoch: 2, Training Loss: 4.8159, Validation Loss: 4.5377, Alpha: 0.2000
Epoch: 3, Training Loss: 4.1098, Validation Loss: 3.4183, Alpha: 0.2000
Epoch: 4, Training Loss: 3.6318, Validation Loss: 3.2751, Alpha: 0.2000
Epoch: 5, Training Loss: 3.2936, Validation Loss: 3.0556, Alpha: 0.2000
Epoch: 6, Training Loss: 2.9678, Validation Loss: 2.8406, Alpha: 0.2000
Epoch: 7, Training Loss: 2.7492, Validation Loss: 2.2884, Alpha: 0.2000
Epoch: 8, Training Loss: 2.5494, Validation Loss: 2.2254, Alpha: 0.2000
Epoch: 9, Training Loss: 2.4003, Validation Loss: 1.9914, Alpha: 0.2000
Epoch: 10, Training Loss: 2.2377, Validation Loss: 2.1907, Alpha: 0.2000
Epoch: 11, Training Loss: 2.0948, Validation Loss: 1.7709, Alpha: 0.2000
Epoch: 12, Training Loss: 2.0718, Validation Loss: 1.5826, Alpha: 0.2000
Epoch: 13, Training Loss: 1.9715, Validation Loss: 1.7356, Alpha: 0.2000
Epoch: 14, Training Loss: 1.8179, Validation Loss: 1.6257, Alpha: 0.2000
Epoch: 15, Training Loss: 1.7764, Validation Loss: 1.6790, Alpha: 0.2000
Epoch: 16, Training Loss: 1.6966, Validation Loss: 1.3719, Alpha: 0.2000
Epoch: 17, Training Loss: 1.6063, Validation Loss: 1.3581, Alpha: 0.2000
Epoch: 18, Training Loss: 1.5826, Validation Loss: 1.5873, Alpha: 0.2000
Epoch: 19, Training Loss: 1.5470, Validation Loss: 1.4446, Alpha: 0.2000
Epoch: 20, Training Loss: 1.4328, Validation Loss: 1.3154, Alpha: 0.2000
Epoch: 21, Training Loss: 1.3459, Validation Loss: 1.3859, Alpha: 0.2000
Epoch: 22, Training Loss: 1.3313, Validation Loss: 1.0857, Alpha: 0.2000
Epoch: 23, Training Loss: 1.2613, Validation Loss: 1.2795, Alpha: 0.2000
Epoch: 24, Training Loss: 1.1684, Validation Loss: 1.2460, Alpha: 0.2000
Epoch: 25, Training Loss: 1.2097, Validation Loss: 1.2636, Alpha: 0.2000
Epoch: 26, Training Loss: 1.1663, Validation Loss: 1.0484, Alpha: 0.2000
Epoch: 27, Training Loss: 1.0541, Validation Loss: 1.0353, Alpha: 0.2000
Epoch: 28, Training Loss: 1.1454, Validation Loss: 1.1210, Alpha: 0.2000
Epoch: 29, Training Loss: 1.1353, Validation Loss: 1.2077, Alpha: 0.2000
Epoch: 30, Training Loss: 1.0123, Validation Loss: 1.1128, Alpha: 0.2000
Epoch: 31, Training Loss: 0.9356, Validation Loss: 0.9362, Alpha: 0.2000
Epoch: 32, Training Loss: 0.8902, Validation Loss: 0.8237, Alpha: 0.2000
Epoch: 33, Training Loss: 0.9375, Validation Loss: 0.7919, Alpha: 0.2000
Epoch: 34, Training Loss: 0.8029, Validation Loss: 0.7973, Alpha: 0.2000
Epoch: 35, Training Loss: 0.7978, Validation Loss: 0.7966, Alpha: 0.2000
Epoch: 36, Training Loss: 0.9363, Validation Loss: 0.9550, Alpha: 0.2000
Epoch: 37, Training Loss: 0.8060, Validation Loss: 0.7598, Alpha: 0.2000
Epoch: 38, Training Loss: 0.8123, Validation Loss: 0.7325, Alpha: 0.2000
Epoch: 39, Training Loss: 0.8151, Validation Loss: 0.8658, Alpha: 0.2000
Epoch: 40, Training Loss: 0.7830, Validation Loss: 0.9191, Alpha: 0.2000
Epoch: 41, Training Loss: 0.7173, Validation Loss: 0.8202, Alpha: 0.2000
Epoch: 42, Training Loss: 0.7781, Validation Loss: 0.8095, Alpha: 0.2000
Epoch: 43, Training Loss: 0.6591, Validation Loss: 0.7640, Alpha: 0.2000
Epoch: 44, Training Loss: 0.5748, Validation Loss: 0.7135, Alpha: 0.2000
Epoch: 45, Training Loss: 0.6007, Validation Loss: 0.9748, Alpha: 0.2000
Epoch: 46, Training Loss: 0.7326, Validation Loss: 0.7523, Alpha: 0.2000
Epoch: 47, Training Loss: 0.6410, Validation Loss: 0.7562, Alpha: 0.2000
Epoch: 48, Training Loss: 0.6138, Validation Loss: 0.8492, Alpha: 0.2000
Epoch: 49, Training Loss: 0.5979, Validation Loss: 0.8856, Alpha: 0.2000
Epoch: 50, Training Loss: 0.6020, Validation Loss: 0.7332, Alpha: 0.2000
Epoch: 51, Training Loss: 0.6515, Validation Loss: 1.0529, Alpha: 0.2000
Epoch: 52, Training Loss: 0.5340, Validation Loss: 0.6219, Alpha: 0.2000
Epoch: 53, Training Loss: 0.5460, Validation Loss: 0.8369, Alpha: 0.2000
Epoch: 54, Training Loss: 0.5370, Validation Loss: 0.9595, Alpha: 0.2000
Epoch: 55, Training Loss: 0.4980, Validation Loss: 0.7068, Alpha: 0.2000
Epoch: 56, Training Loss: 0.5296, Validation Loss: 0.8219, Alpha: 0.2000
Epoch: 57, Training Loss: 0.5101, Validation Loss: 0.7633, Alpha: 0.2000
Epoch: 58, Training Loss: 0.5718, Validation Loss: 1.1020, Alpha: 0.2000
Epoch: 59, Training Loss: 0.5338, Validation Loss: 0.8793, Alpha: 0.2000
Epoch: 60, Training Loss: 0.4401, Validation Loss: 0.7114, Alpha: 0.2000
Epoch: 61, Training Loss: 0.4982, Validation Loss: 0.8779, Alpha: 0.2000
Epoch: 62, Training Loss: 0.4489, Validation Loss: 1.1777, Alpha: 0.2000
Epoch: 63, Training Loss: 0.3726, Validation Loss: 0.8929, Alpha: 0.2000
Epoch: 64, Training Loss: 0.3293, Validation Loss: 0.5237, Alpha: 0.2000
Epoch: 65, Training Loss: 0.2632, Validation Loss: 0.4827, Alpha: 0.2000
Epoch: 66, Training Loss: 0.2233, Validation Loss: 0.4625, Alpha: 0.2000
Epoch: 67, Training Loss: 0.2100, Validation Loss: 0.4622, Alpha: 0.2000
Epoch: 68, Training Loss: 0.2007, Validation Loss: 0.4644, Alpha: 0.2000
Epoch: 69, Training Loss: 0.1886, Validation Loss: 0.4573, Alpha: 0.2000
Epoch: 70, Training Loss: 0.2121, Validation Loss: 0.4413, Alpha: 0.2000
Epoch: 71, Training Loss: 0.1765, Validation Loss: 0.4383, Alpha: 0.2000
Epoch: 72, Training Loss: 0.1636, Validation Loss: 0.4626, Alpha: 0.2000
Epoch: 73, Training Loss: 0.1658, Validation Loss: 0.4537, Alpha: 0.2000
Epoch: 74, Training Loss: 0.1459, Validation Loss: 0.4622, Alpha: 0.2000
Epoch: 75, Training Loss: 0.1857, Validation Loss: 0.4552, Alpha: 0.2000
Epoch: 76, Training Loss: 0.1263, Validation Loss: 0.4402, Alpha: 0.2000
Epoch: 77, Training Loss: 0.1456, Validation Loss: 0.4517, Alpha: 0.2000
Epoch: 78, Training Loss: 0.1382, Validation Loss: 0.4454, Alpha: 0.2000
Epoch: 79, Training Loss: 0.1456, Validation Loss: 0.4436, Alpha: 0.2000
Epoch: 80, Training Loss: 0.1295, Validation Loss: 0.4548, Alpha: 0.2000
Epoch: 81, Training Loss: 0.1393, Validation Loss: 0.4578, Alpha: 0.2000
Epoch: 82, Training Loss: 0.1101, Validation Loss: 0.4408, Alpha: 0.2000
Epoch: 83, Training Loss: 0.1092, Validation Loss: 0.4483, Alpha: 0.2000
Epoch: 84, Training Loss: 0.1231, Validation Loss: 0.4399, Alpha: 0.2000
Epoch: 85, Training Loss: 0.1064, Validation Loss: 0.4405, Alpha: 0.2000
Epoch: 86, Training Loss: 0.1199, Validation Loss: 0.4457, Alpha: 0.2000
Epoch: 87, Training Loss: 0.1123, Validation Loss: 0.4387, Alpha: 0.2000
Epoch: 88, Training Loss: 0.1072, Validation Loss: 0.4418, Alpha: 0.2000
Epoch: 89, Training Loss: 0.1342, Validation Loss: 0.4414, Alpha: 0.2000
Epoch: 90, Training Loss: 0.0967, Validation Loss: 0.4408, Alpha: 0.2000
Epoch: 91, Training Loss: 0.1043, Validation Loss: 0.4434, Alpha: 0.2000
Early stopping triggered.
Running remove_features classification training with alpha = 0.5 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.8433, Validation Loss: 5.2344, Alpha: 0.5000
Epoch: 2, Training Loss: 3.9772, Validation Loss: 3.3591, Alpha: 0.5000
Epoch: 3, Training Loss: 3.4419, Validation Loss: 3.1457, Alpha: 0.5000
Epoch: 4, Training Loss: 3.0191, Validation Loss: 2.7806, Alpha: 0.5000
Epoch: 5, Training Loss: 2.7293, Validation Loss: 2.5449, Alpha: 0.5000
Epoch: 6, Training Loss: 2.4801, Validation Loss: 2.1829, Alpha: 0.5000
Epoch: 7, Training Loss: 2.2654, Validation Loss: 2.0602, Alpha: 0.5000
Epoch: 8, Training Loss: 2.1357, Validation Loss: 1.9833, Alpha: 0.5000
Epoch: 9, Training Loss: 1.9998, Validation Loss: 2.1931, Alpha: 0.5000
Epoch: 10, Training Loss: 1.8635, Validation Loss: 1.5579, Alpha: 0.5000
Epoch: 11, Training Loss: 1.7651, Validation Loss: 1.6908, Alpha: 0.5000
Epoch: 12, Training Loss: 1.7183, Validation Loss: 1.4568, Alpha: 0.5000
Epoch: 13, Training Loss: 1.5131, Validation Loss: 1.3598, Alpha: 0.5000
Epoch: 14, Training Loss: 1.4743, Validation Loss: 1.9449, Alpha: 0.5000
Epoch: 15, Training Loss: 1.4541, Validation Loss: 1.3108, Alpha: 0.5000
Epoch: 16, Training Loss: 1.3744, Validation Loss: 1.2746, Alpha: 0.5000
Epoch: 17, Training Loss: 1.3260, Validation Loss: 1.0813, Alpha: 0.5000
Epoch: 18, Training Loss: 1.2196, Validation Loss: 1.2720, Alpha: 0.5000
Epoch: 19, Training Loss: 1.2030, Validation Loss: 1.0796, Alpha: 0.5000
Epoch: 20, Training Loss: 1.1760, Validation Loss: 1.3781, Alpha: 0.5000
Epoch: 21, Training Loss: 1.1663, Validation Loss: 1.3826, Alpha: 0.5000
Epoch: 22, Training Loss: 1.1936, Validation Loss: 1.0318, Alpha: 0.5000
Epoch: 23, Training Loss: 1.0791, Validation Loss: 1.1318, Alpha: 0.5000
Epoch: 24, Training Loss: 1.0344, Validation Loss: 0.9639, Alpha: 0.5000
Epoch: 25, Training Loss: 0.9577, Validation Loss: 1.1368, Alpha: 0.5000
Epoch: 26, Training Loss: 0.9294, Validation Loss: 1.3248, Alpha: 0.5000
Epoch: 27, Training Loss: 1.0074, Validation Loss: 0.8724, Alpha: 0.5000
Epoch: 28, Training Loss: 0.8859, Validation Loss: 0.7778, Alpha: 0.5000
Epoch: 29, Training Loss: 0.8194, Validation Loss: 0.9134, Alpha: 0.5000
Epoch: 30, Training Loss: 0.8162, Validation Loss: 1.5358, Alpha: 0.5000
Epoch: 31, Training Loss: 0.8532, Validation Loss: 1.3323, Alpha: 0.5000
Epoch: 32, Training Loss: 0.7231, Validation Loss: 0.8429, Alpha: 0.5000
Epoch: 33, Training Loss: 0.7308, Validation Loss: 0.8585, Alpha: 0.5000
Epoch: 34, Training Loss: 0.7949, Validation Loss: 0.7336, Alpha: 0.5000
Epoch: 35, Training Loss: 0.7329, Validation Loss: 0.9085, Alpha: 0.5000
Epoch: 36, Training Loss: 0.7147, Validation Loss: 0.9268, Alpha: 0.5000
Epoch: 37, Training Loss: 0.7022, Validation Loss: 0.8218, Alpha: 0.5000
Epoch: 38, Training Loss: 0.6790, Validation Loss: 0.9535, Alpha: 0.5000
Epoch: 39, Training Loss: 0.6188, Validation Loss: 0.9086, Alpha: 0.5000
Epoch: 40, Training Loss: 0.5951, Validation Loss: 0.7051, Alpha: 0.5000
Epoch: 41, Training Loss: 0.6534, Validation Loss: 0.7124, Alpha: 0.5000
Epoch: 42, Training Loss: 0.5888, Validation Loss: 0.6552, Alpha: 0.5000
Epoch: 43, Training Loss: 0.6040, Validation Loss: 1.0683, Alpha: 0.5000
Epoch: 44, Training Loss: 0.5359, Validation Loss: 0.6752, Alpha: 0.5000
Epoch: 45, Training Loss: 0.5404, Validation Loss: 0.6962, Alpha: 0.5000
Epoch: 46, Training Loss: 0.5102, Validation Loss: 0.8589, Alpha: 0.5000
Epoch: 47, Training Loss: 0.5171, Validation Loss: 0.9148, Alpha: 0.5000
Epoch: 48, Training Loss: 0.5676, Validation Loss: 0.9377, Alpha: 0.5000
Epoch: 49, Training Loss: 0.5296, Validation Loss: 1.0944, Alpha: 0.5000
Epoch: 50, Training Loss: 0.5139, Validation Loss: 0.7788, Alpha: 0.5000
Epoch: 51, Training Loss: 0.4815, Validation Loss: 0.7710, Alpha: 0.5000
Epoch: 52, Training Loss: 0.4312, Validation Loss: 0.7700, Alpha: 0.5000
Epoch: 53, Training Loss: 0.5039, Validation Loss: 0.8705, Alpha: 0.5000
Epoch: 54, Training Loss: 0.3938, Validation Loss: 0.5080, Alpha: 0.5000
Epoch: 55, Training Loss: 0.3298, Validation Loss: 0.4448, Alpha: 0.5000
Epoch: 56, Training Loss: 0.2785, Validation Loss: 0.4311, Alpha: 0.5000
Epoch: 57, Training Loss: 0.2508, Validation Loss: 0.4349, Alpha: 0.5000
Epoch: 58, Training Loss: 0.2409, Validation Loss: 0.4216, Alpha: 0.5000
Epoch: 59, Training Loss: 0.2217, Validation Loss: 0.4145, Alpha: 0.5000
Epoch: 60, Training Loss: 0.2210, Validation Loss: 0.4374, Alpha: 0.5000
Epoch: 61, Training Loss: 0.2228, Validation Loss: 0.4306, Alpha: 0.5000
Epoch: 62, Training Loss: 0.2061, Validation Loss: 0.4096, Alpha: 0.5000
Epoch: 63, Training Loss: 0.2153, Validation Loss: 0.4109, Alpha: 0.5000
Epoch: 64, Training Loss: 0.2038, Validation Loss: 0.3940, Alpha: 0.5000
Epoch: 65, Training Loss: 0.2015, Validation Loss: 0.4064, Alpha: 0.5000
Epoch: 66, Training Loss: 0.2056, Validation Loss: 0.4066, Alpha: 0.5000
Epoch: 67, Training Loss: 0.1733, Validation Loss: 0.3937, Alpha: 0.5000
Epoch: 68, Training Loss: 0.1989, Validation Loss: 0.3952, Alpha: 0.5000
Epoch: 69, Training Loss: 0.1786, Validation Loss: 0.4192, Alpha: 0.5000
Epoch: 70, Training Loss: 0.1713, Validation Loss: 0.4332, Alpha: 0.5000
Epoch: 71, Training Loss: 0.1683, Validation Loss: 0.4100, Alpha: 0.5000
Epoch: 72, Training Loss: 0.1665, Validation Loss: 0.4493, Alpha: 0.5000
Epoch: 73, Training Loss: 0.1788, Validation Loss: 0.4198, Alpha: 0.5000
Epoch: 74, Training Loss: 0.1747, Validation Loss: 0.4122, Alpha: 0.5000
Epoch: 75, Training Loss: 0.1560, Validation Loss: 0.4055, Alpha: 0.5000
Epoch: 76, Training Loss: 0.1609, Validation Loss: 0.4063, Alpha: 0.5000
Epoch: 77, Training Loss: 0.1583, Validation Loss: 0.4122, Alpha: 0.5000
Epoch: 78, Training Loss: 0.1722, Validation Loss: 0.4172, Alpha: 0.5000
Epoch: 79, Training Loss: 0.1500, Validation Loss: 0.4073, Alpha: 0.5000
Epoch: 80, Training Loss: 0.1651, Validation Loss: 0.3961, Alpha: 0.5000
Epoch: 81, Training Loss: 0.1351, Validation Loss: 0.3927, Alpha: 0.5000
Epoch: 82, Training Loss: 0.1378, Validation Loss: 0.3983, Alpha: 0.5000
Epoch: 83, Training Loss: 0.1430, Validation Loss: 0.3999, Alpha: 0.5000
Epoch: 84, Training Loss: 0.1442, Validation Loss: 0.3999, Alpha: 0.5000
Epoch: 85, Training Loss: 0.1354, Validation Loss: 0.3910, Alpha: 0.5000
Epoch: 86, Training Loss: 0.1318, Validation Loss: 0.4083, Alpha: 0.5000
Epoch: 87, Training Loss: 0.1433, Validation Loss: 0.3959, Alpha: 0.5000
Epoch: 88, Training Loss: 0.1528, Validation Loss: 0.4028, Alpha: 0.5000
Epoch: 89, Training Loss: 0.1506, Validation Loss: 0.3896, Alpha: 0.5000
Epoch: 90, Training Loss: 0.1391, Validation Loss: 0.3939, Alpha: 0.5000
Epoch: 91, Training Loss: 0.1444, Validation Loss: 0.3902, Alpha: 0.5000
Epoch: 92, Training Loss: 0.1344, Validation Loss: 0.3858, Alpha: 0.5000
Epoch: 93, Training Loss: 0.1234, Validation Loss: 0.3921, Alpha: 0.5000
Epoch: 94, Training Loss: 0.1167, Validation Loss: 0.3930, Alpha: 0.5000
Epoch: 95, Training Loss: 0.1343, Validation Loss: 0.3892, Alpha: 0.5000
Epoch: 96, Training Loss: 0.1274, Validation Loss: 0.3894, Alpha: 0.5000
Epoch: 97, Training Loss: 0.1305, Validation Loss: 0.3936, Alpha: 0.5000
Epoch: 98, Training Loss: 0.1377, Validation Loss: 0.3843, Alpha: 0.5000
Epoch: 99, Training Loss: 0.1325, Validation Loss: 0.3879, Alpha: 0.5000
Epoch: 100, Training Loss: 0.1286, Validation Loss: 0.3815, Alpha: 0.5000
Running remove_features classification training with alpha = 0.8 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.9806, Validation Loss: 4.0375, Alpha: 0.8000
Epoch: 2, Training Loss: 3.2733, Validation Loss: 2.8062, Alpha: 0.8000
Epoch: 3, Training Loss: 2.8316, Validation Loss: 2.5401, Alpha: 0.8000
Epoch: 4, Training Loss: 2.5163, Validation Loss: 2.1026, Alpha: 0.8000
Epoch: 5, Training Loss: 2.2748, Validation Loss: 1.9915, Alpha: 0.8000
Epoch: 6, Training Loss: 2.0852, Validation Loss: 2.0947, Alpha: 0.8000
Epoch: 7, Training Loss: 1.9086, Validation Loss: 1.6947, Alpha: 0.8000
Epoch: 8, Training Loss: 1.8192, Validation Loss: 1.7133, Alpha: 0.8000
Epoch: 9, Training Loss: 1.6890, Validation Loss: 1.5781, Alpha: 0.8000
Epoch: 10, Training Loss: 1.5969, Validation Loss: 1.3657, Alpha: 0.8000
Epoch: 11, Training Loss: 1.5244, Validation Loss: 1.4740, Alpha: 0.8000
Epoch: 12, Training Loss: 1.4802, Validation Loss: 1.1682, Alpha: 0.8000
Epoch: 13, Training Loss: 1.3947, Validation Loss: 1.3450, Alpha: 0.8000
Epoch: 14, Training Loss: 1.3683, Validation Loss: 1.1013, Alpha: 0.8000
Epoch: 15, Training Loss: 1.3135, Validation Loss: 1.2566, Alpha: 0.8000
Epoch: 16, Training Loss: 1.2021, Validation Loss: 1.0383, Alpha: 0.8000
Epoch: 17, Training Loss: 1.0812, Validation Loss: 0.9528, Alpha: 0.8000
Epoch: 18, Training Loss: 1.0618, Validation Loss: 0.9179, Alpha: 0.8000
Epoch: 19, Training Loss: 1.0305, Validation Loss: 0.7990, Alpha: 0.8000
Epoch: 20, Training Loss: 0.8955, Validation Loss: 0.9154, Alpha: 0.8000
Epoch: 21, Training Loss: 0.9391, Validation Loss: 0.8136, Alpha: 0.8000
Epoch: 22, Training Loss: 0.8891, Validation Loss: 0.9663, Alpha: 0.8000
Epoch: 23, Training Loss: 0.8374, Validation Loss: 0.7690, Alpha: 0.8000
Epoch: 24, Training Loss: 0.8597, Validation Loss: 0.7869, Alpha: 0.8000
Epoch: 25, Training Loss: 0.7712, Validation Loss: 0.6699, Alpha: 0.8000
Epoch: 26, Training Loss: 0.7545, Validation Loss: 0.6522, Alpha: 0.8000
Epoch: 27, Training Loss: 0.7733, Validation Loss: 0.9349, Alpha: 0.8000
Epoch: 28, Training Loss: 0.6895, Validation Loss: 0.6902, Alpha: 0.8000
Epoch: 29, Training Loss: 0.7151, Validation Loss: 0.7843, Alpha: 0.8000
Epoch: 30, Training Loss: 0.7750, Validation Loss: 0.9344, Alpha: 0.8000
Epoch: 31, Training Loss: 0.6945, Validation Loss: 0.7160, Alpha: 0.8000
Epoch: 32, Training Loss: 0.6627, Validation Loss: 0.7192, Alpha: 0.8000
Epoch: 33, Training Loss: 0.5963, Validation Loss: 0.5970, Alpha: 0.8000
Epoch: 34, Training Loss: 0.6745, Validation Loss: 0.6565, Alpha: 0.8000
Epoch: 35, Training Loss: 0.6067, Validation Loss: 0.5584, Alpha: 0.8000
Epoch: 36, Training Loss: 0.5472, Validation Loss: 0.5922, Alpha: 0.8000
Epoch: 37, Training Loss: 0.5611, Validation Loss: 1.0162, Alpha: 0.8000
Epoch: 38, Training Loss: 0.5028, Validation Loss: 0.4874, Alpha: 0.8000
Epoch: 39, Training Loss: 0.5087, Validation Loss: 0.5311, Alpha: 0.8000
Epoch: 40, Training Loss: 0.5076, Validation Loss: 0.5670, Alpha: 0.8000
Epoch: 41, Training Loss: 0.4828, Validation Loss: 0.5392, Alpha: 0.8000
Epoch: 42, Training Loss: 0.4686, Validation Loss: 0.7150, Alpha: 0.8000
Epoch: 43, Training Loss: 0.4407, Validation Loss: 0.4644, Alpha: 0.8000
Epoch: 44, Training Loss: 0.4395, Validation Loss: 0.6263, Alpha: 0.8000
Epoch: 45, Training Loss: 0.3973, Validation Loss: 0.7582, Alpha: 0.8000
Epoch: 46, Training Loss: 0.4327, Validation Loss: 0.7172, Alpha: 0.8000
Epoch: 47, Training Loss: 0.4055, Validation Loss: 0.5683, Alpha: 0.8000
Epoch: 48, Training Loss: 0.4562, Validation Loss: 0.5216, Alpha: 0.8000
Epoch: 49, Training Loss: 0.4031, Validation Loss: 0.6451, Alpha: 0.8000
Epoch: 50, Training Loss: 0.4291, Validation Loss: 0.5467, Alpha: 0.8000
Epoch: 51, Training Loss: 0.4090, Validation Loss: 0.6251, Alpha: 0.8000
Epoch: 52, Training Loss: 0.4001, Validation Loss: 0.6592, Alpha: 0.8000
Epoch: 53, Training Loss: 0.3930, Validation Loss: 0.4377, Alpha: 0.8000
Epoch: 54, Training Loss: 0.3795, Validation Loss: 0.4644, Alpha: 0.8000
Epoch: 55, Training Loss: 0.3076, Validation Loss: 0.4624, Alpha: 0.8000
Epoch: 56, Training Loss: 0.3456, Validation Loss: 0.7456, Alpha: 0.8000
Epoch: 57, Training Loss: 0.3361, Validation Loss: 0.5349, Alpha: 0.8000
Epoch: 58, Training Loss: 0.3176, Validation Loss: 0.4814, Alpha: 0.8000
Epoch: 59, Training Loss: 0.3291, Validation Loss: 0.6926, Alpha: 0.8000
Epoch: 60, Training Loss: 0.3725, Validation Loss: 0.6685, Alpha: 0.8000
Epoch: 61, Training Loss: 0.3385, Validation Loss: 0.4316, Alpha: 0.8000
Epoch: 62, Training Loss: 0.2806, Validation Loss: 0.5582, Alpha: 0.8000
Epoch: 63, Training Loss: 0.3011, Validation Loss: 0.4176, Alpha: 0.8000
Epoch: 64, Training Loss: 0.2663, Validation Loss: 0.4658, Alpha: 0.8000
Epoch: 65, Training Loss: 0.2836, Validation Loss: 0.5001, Alpha: 0.8000
Epoch: 66, Training Loss: 0.3104, Validation Loss: 0.5447, Alpha: 0.8000
Epoch: 67, Training Loss: 0.2951, Validation Loss: 0.4689, Alpha: 0.8000
Epoch: 68, Training Loss: 0.2422, Validation Loss: 0.4524, Alpha: 0.8000
Epoch: 69, Training Loss: 0.2472, Validation Loss: 0.4701, Alpha: 0.8000
Epoch: 70, Training Loss: 0.2186, Validation Loss: 0.4781, Alpha: 0.8000
Epoch: 71, Training Loss: 0.2540, Validation Loss: 0.5448, Alpha: 0.8000
Epoch: 72, Training Loss: 0.2454, Validation Loss: 0.5309, Alpha: 0.8000
Epoch: 73, Training Loss: 0.2252, Validation Loss: 0.4239, Alpha: 0.8000
Epoch: 74, Training Loss: 0.2234, Validation Loss: 0.4538, Alpha: 0.8000
Epoch: 75, Training Loss: 0.2112, Validation Loss: 0.3766, Alpha: 0.8000
Epoch: 76, Training Loss: 0.1402, Validation Loss: 0.3266, Alpha: 0.8000
Epoch: 77, Training Loss: 0.1075, Validation Loss: 0.3185, Alpha: 0.8000
Epoch: 78, Training Loss: 0.1043, Validation Loss: 0.3188, Alpha: 0.8000
Epoch: 79, Training Loss: 0.0905, Validation Loss: 0.3240, Alpha: 0.8000
Epoch: 80, Training Loss: 0.0916, Validation Loss: 0.3162, Alpha: 0.8000
Epoch: 81, Training Loss: 0.0864, Validation Loss: 0.3109, Alpha: 0.8000
Epoch: 82, Training Loss: 0.0767, Validation Loss: 0.3056, Alpha: 0.8000
Epoch: 83, Training Loss: 0.0780, Validation Loss: 0.2844, Alpha: 0.8000
Epoch: 84, Training Loss: 0.0692, Validation Loss: 0.2796, Alpha: 0.8000
Epoch: 85, Training Loss: 0.0757, Validation Loss: 0.2954, Alpha: 0.8000
Epoch: 86, Training Loss: 0.0687, Validation Loss: 0.3003, Alpha: 0.8000
Epoch: 87, Training Loss: 0.0733, Validation Loss: 0.3009, Alpha: 0.8000
Epoch: 88, Training Loss: 0.0696, Validation Loss: 0.2842, Alpha: 0.8000
Epoch: 89, Training Loss: 0.0606, Validation Loss: 0.2809, Alpha: 0.8000
Epoch: 90, Training Loss: 0.0739, Validation Loss: 0.2958, Alpha: 0.8000
Epoch: 91, Training Loss: 0.0676, Validation Loss: 0.2970, Alpha: 0.8000
Epoch: 92, Training Loss: 0.0505, Validation Loss: 0.3012, Alpha: 0.8000
Epoch: 93, Training Loss: 0.0603, Validation Loss: 0.3016, Alpha: 0.8000
Epoch: 94, Training Loss: 0.0566, Validation Loss: 0.2969, Alpha: 0.8000
Epoch: 95, Training Loss: 0.0586, Validation Loss: 0.2957, Alpha: 0.8000
Epoch: 96, Training Loss: 0.0599, Validation Loss: 0.2959, Alpha: 0.8000
Epoch: 97, Training Loss: 0.0595, Validation Loss: 0.2906, Alpha: 0.8000
Epoch: 98, Training Loss: 0.0549, Validation Loss: 0.2890, Alpha: 0.8000
Epoch: 99, Training Loss: 0.0510, Validation Loss: 0.2952, Alpha: 0.8000
Epoch: 100, Training Loss: 0.0466, Validation Loss: 0.2923, Alpha: 0.8000
Running remove_features classification training with alpha = 1 using script scripts/remove_features/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.8148, Validation Loss: 3.6480, Alpha: 1.0000
Epoch: 2, Training Loss: 3.0086, Validation Loss: 2.4937, Alpha: 1.0000
Epoch: 3, Training Loss: 2.6026, Validation Loss: 2.2785, Alpha: 1.0000
Epoch: 4, Training Loss: 2.3025, Validation Loss: 1.8600, Alpha: 1.0000
Epoch: 5, Training Loss: 2.0604, Validation Loss: 1.9536, Alpha: 1.0000
Epoch: 6, Training Loss: 1.9304, Validation Loss: 1.6732, Alpha: 1.0000
Epoch: 7, Training Loss: 1.7554, Validation Loss: 1.4298, Alpha: 1.0000
Epoch: 8, Training Loss: 1.6549, Validation Loss: 1.6243, Alpha: 1.0000
Epoch: 9, Training Loss: 1.5738, Validation Loss: 1.3235, Alpha: 1.0000
Epoch: 10, Training Loss: 1.4962, Validation Loss: 1.4814, Alpha: 1.0000
Epoch: 11, Training Loss: 1.3434, Validation Loss: 1.2481, Alpha: 1.0000
Epoch: 12, Training Loss: 1.3093, Validation Loss: 1.1208, Alpha: 1.0000
Epoch: 13, Training Loss: 1.2051, Validation Loss: 1.0660, Alpha: 1.0000
Epoch: 14, Training Loss: 1.0925, Validation Loss: 0.9487, Alpha: 1.0000
Epoch: 15, Training Loss: 1.0665, Validation Loss: 0.9465, Alpha: 1.0000
Epoch: 16, Training Loss: 0.9662, Validation Loss: 0.7986, Alpha: 1.0000
Epoch: 17, Training Loss: 0.9471, Validation Loss: 0.7421, Alpha: 1.0000
Epoch: 18, Training Loss: 0.8570, Validation Loss: 0.7201, Alpha: 1.0000
Epoch: 19, Training Loss: 0.7570, Validation Loss: 0.6632, Alpha: 1.0000
Epoch: 20, Training Loss: 0.7962, Validation Loss: 0.6767, Alpha: 1.0000
Epoch: 21, Training Loss: 0.7910, Validation Loss: 0.7525, Alpha: 1.0000
Epoch: 22, Training Loss: 0.7167, Validation Loss: 0.7402, Alpha: 1.0000
Epoch: 23, Training Loss: 0.7070, Validation Loss: 0.7456, Alpha: 1.0000
Epoch: 24, Training Loss: 0.7454, Validation Loss: 0.7971, Alpha: 1.0000
Epoch: 25, Training Loss: 0.6665, Validation Loss: 0.5940, Alpha: 1.0000
Epoch: 26, Training Loss: 0.5999, Validation Loss: 0.6311, Alpha: 1.0000
Epoch: 27, Training Loss: 0.5741, Validation Loss: 0.6296, Alpha: 1.0000
Epoch: 28, Training Loss: 0.6136, Validation Loss: 0.6251, Alpha: 1.0000
Epoch: 29, Training Loss: 0.6646, Validation Loss: 0.6932, Alpha: 1.0000
Epoch: 30, Training Loss: 0.5176, Validation Loss: 0.6105, Alpha: 1.0000
Epoch: 31, Training Loss: 0.5108, Validation Loss: 0.6424, Alpha: 1.0000
Epoch: 32, Training Loss: 0.4987, Validation Loss: 0.4813, Alpha: 1.0000
Epoch: 33, Training Loss: 0.4855, Validation Loss: 0.4668, Alpha: 1.0000
Epoch: 34, Training Loss: 0.5030, Validation Loss: 0.4857, Alpha: 1.0000
Epoch: 35, Training Loss: 0.4851, Validation Loss: 0.5183, Alpha: 1.0000
Epoch: 36, Training Loss: 0.4401, Validation Loss: 0.5064, Alpha: 1.0000
Epoch: 37, Training Loss: 0.4268, Validation Loss: 0.4777, Alpha: 1.0000
Epoch: 38, Training Loss: 0.4293, Validation Loss: 0.4387, Alpha: 1.0000
Epoch: 39, Training Loss: 0.3729, Validation Loss: 0.4360, Alpha: 1.0000
Epoch: 40, Training Loss: 0.4035, Validation Loss: 0.7129, Alpha: 1.0000
Epoch: 41, Training Loss: 0.4321, Validation Loss: 0.5154, Alpha: 1.0000
Epoch: 42, Training Loss: 0.3645, Validation Loss: 0.4488, Alpha: 1.0000
Epoch: 43, Training Loss: 0.3832, Validation Loss: 0.4112, Alpha: 1.0000
Epoch: 44, Training Loss: 0.3338, Validation Loss: 0.4257, Alpha: 1.0000
Epoch: 45, Training Loss: 0.3241, Validation Loss: 0.4574, Alpha: 1.0000
Epoch: 46, Training Loss: 0.3656, Validation Loss: 0.5485, Alpha: 1.0000
Epoch: 47, Training Loss: 0.3178, Validation Loss: 0.4179, Alpha: 1.0000
Epoch: 48, Training Loss: 0.3235, Validation Loss: 0.4286, Alpha: 1.0000
Epoch: 49, Training Loss: 0.3128, Validation Loss: 0.3902, Alpha: 1.0000
Epoch: 50, Training Loss: 0.3002, Validation Loss: 0.4151, Alpha: 1.0000
Epoch: 51, Training Loss: 0.2670, Validation Loss: 0.4675, Alpha: 1.0000
Epoch: 52, Training Loss: 0.3072, Validation Loss: 0.4066, Alpha: 1.0000
Epoch: 53, Training Loss: 0.2366, Validation Loss: 0.4963, Alpha: 1.0000
Epoch: 54, Training Loss: 0.2447, Validation Loss: 0.4272, Alpha: 1.0000
Epoch: 55, Training Loss: 0.2421, Validation Loss: 0.5268, Alpha: 1.0000
Epoch: 56, Training Loss: 0.2370, Validation Loss: 0.7283, Alpha: 1.0000
Epoch: 57, Training Loss: 0.2729, Validation Loss: 0.4296, Alpha: 1.0000
Epoch: 58, Training Loss: 0.2219, Validation Loss: 0.4381, Alpha: 1.0000
Epoch: 59, Training Loss: 0.2472, Validation Loss: 0.5767, Alpha: 1.0000
Epoch: 60, Training Loss: 0.2358, Validation Loss: 0.5268, Alpha: 1.0000
Epoch: 61, Training Loss: 0.2253, Validation Loss: 0.3339, Alpha: 1.0000
Epoch: 62, Training Loss: 0.1615, Validation Loss: 0.3025, Alpha: 1.0000
Epoch: 63, Training Loss: 0.1244, Validation Loss: 0.3011, Alpha: 1.0000
Epoch: 64, Training Loss: 0.1223, Validation Loss: 0.2885, Alpha: 1.0000
Epoch: 65, Training Loss: 0.1031, Validation Loss: 0.3017, Alpha: 1.0000
Epoch: 66, Training Loss: 0.1159, Validation Loss: 0.2951, Alpha: 1.0000
Epoch: 67, Training Loss: 0.0999, Validation Loss: 0.2758, Alpha: 1.0000
Epoch: 68, Training Loss: 0.0863, Validation Loss: 0.2823, Alpha: 1.0000
Epoch: 69, Training Loss: 0.0712, Validation Loss: 0.2717, Alpha: 1.0000
Epoch: 70, Training Loss: 0.0807, Validation Loss: 0.2690, Alpha: 1.0000
Epoch: 71, Training Loss: 0.0813, Validation Loss: 0.2571, Alpha: 1.0000
Epoch: 72, Training Loss: 0.0846, Validation Loss: 0.2559, Alpha: 1.0000
Epoch: 73, Training Loss: 0.0739, Validation Loss: 0.2646, Alpha: 1.0000
Epoch: 74, Training Loss: 0.0728, Validation Loss: 0.2771, Alpha: 1.0000
Epoch: 75, Training Loss: 0.0777, Validation Loss: 0.2787, Alpha: 1.0000
Epoch: 76, Training Loss: 0.0868, Validation Loss: 0.2758, Alpha: 1.0000
Epoch: 77, Training Loss: 0.0706, Validation Loss: 0.2711, Alpha: 1.0000
Epoch: 78, Training Loss: 0.0779, Validation Loss: 0.2737, Alpha: 1.0000
Epoch: 79, Training Loss: 0.0788, Validation Loss: 0.2756, Alpha: 1.0000
Epoch: 80, Training Loss: 0.0730, Validation Loss: 0.2640, Alpha: 1.0000
Epoch: 81, Training Loss: 0.0728, Validation Loss: 0.2822, Alpha: 1.0000
Epoch: 82, Training Loss: 0.0587, Validation Loss: 0.2820, Alpha: 1.0000
Epoch: 83, Training Loss: 0.0716, Validation Loss: 0.2733, Alpha: 1.0000
Epoch: 84, Training Loss: 0.0508, Validation Loss: 0.2690, Alpha: 1.0000
Epoch: 85, Training Loss: 0.0701, Validation Loss: 0.2744, Alpha: 1.0000
Epoch: 86, Training Loss: 0.0630, Validation Loss: 0.2775, Alpha: 1.0000
Epoch: 87, Training Loss: 0.0566, Validation Loss: 0.2812, Alpha: 1.0000
Epoch: 88, Training Loss: 0.0496, Validation Loss: 0.2692, Alpha: 1.0000
Epoch: 89, Training Loss: 0.0539, Validation Loss: 0.2686, Alpha: 1.0000
Epoch: 90, Training Loss: 0.0593, Validation Loss: 0.2665, Alpha: 1.0000
Epoch: 91, Training Loss: 0.0565, Validation Loss: 0.2692, Alpha: 1.0000
Epoch: 92, Training Loss: 0.0516, Validation Loss: 0.2636, Alpha: 1.0000
Early stopping triggered.
Running rtdetr experiments:
Running rtdetr classification training with alpha = 0 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.2026, Validation Loss: 5.3584, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 3.6582, Validation Loss: 2.8728, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 2.9085, Validation Loss: 2.3006, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.4570, Validation Loss: 2.0158, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.2949, Validation Loss: 1.8993, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.0869, Validation Loss: 1.6311, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.8773, Validation Loss: 1.8139, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.8993, Validation Loss: 1.4758, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.7505, Validation Loss: 1.5042, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.7221, Validation Loss: 1.7393, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.6054, Validation Loss: 1.3898, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.5316, Validation Loss: 1.3461, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.4633, Validation Loss: 1.2646, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.4640, Validation Loss: 1.1797, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.3389, Validation Loss: 1.2223, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 1.5043, Validation Loss: 1.2952, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 1.3824, Validation Loss: 1.2549, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 1.2329, Validation Loss: 1.1844, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 1.3047, Validation Loss: 1.2315, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 1.2394, Validation Loss: 1.1567, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 1.1442, Validation Loss: 1.2491, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 1.2105, Validation Loss: 1.1214, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 1.2205, Validation Loss: 1.0636, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 1.1244, Validation Loss: 1.1139, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 1.1559, Validation Loss: 1.0752, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 1.1076, Validation Loss: 1.0186, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 1.1009, Validation Loss: 1.0763, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.9904, Validation Loss: 1.1446, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 1.0930, Validation Loss: 1.0231, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 1.0340, Validation Loss: 1.0803, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 1.0445, Validation Loss: 1.1649, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.9577, Validation Loss: 1.0623, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 1.0317, Validation Loss: 1.0650, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.9913, Validation Loss: 1.1238, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.9065, Validation Loss: 0.9688, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.9472, Validation Loss: 0.9723, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.9562, Validation Loss: 1.0462, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.8729, Validation Loss: 1.0709, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.8611, Validation Loss: 0.9108, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.9165, Validation Loss: 0.9378, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.8111, Validation Loss: 0.8360, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.9065, Validation Loss: 0.8947, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.9007, Validation Loss: 0.8993, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.8418, Validation Loss: 0.9923, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.8111, Validation Loss: 0.9033, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.8115, Validation Loss: 1.0834, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.7817, Validation Loss: 0.8351, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.7385, Validation Loss: 1.0324, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.7016, Validation Loss: 0.9766, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.7796, Validation Loss: 0.8741, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.6305, Validation Loss: 0.8151, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.7753, Validation Loss: 0.9318, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.8069, Validation Loss: 1.0621, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.7682, Validation Loss: 0.9340, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.7939, Validation Loss: 0.9388, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.7269, Validation Loss: 0.8580, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.7524, Validation Loss: 0.9072, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.6577, Validation Loss: 0.8948, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.7810, Validation Loss: 0.8854, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.7373, Validation Loss: 0.9385, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.7224, Validation Loss: 0.8580, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.6636, Validation Loss: 0.9089, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.5790, Validation Loss: 0.7954, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.6102, Validation Loss: 0.8013, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.5663, Validation Loss: 0.8200, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.5214, Validation Loss: 0.8063, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.4781, Validation Loss: 0.7952, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.5573, Validation Loss: 0.7900, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.4782, Validation Loss: 0.7458, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.4517, Validation Loss: 0.7414, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.4768, Validation Loss: 0.7293, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.4731, Validation Loss: 0.7472, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.4585, Validation Loss: 0.7206, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.4721, Validation Loss: 0.7534, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.4724, Validation Loss: 0.7580, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.4726, Validation Loss: 0.7556, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.4309, Validation Loss: 0.7450, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.4540, Validation Loss: 0.7687, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.4525, Validation Loss: 0.7716, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.4711, Validation Loss: 0.7392, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.4596, Validation Loss: 0.7223, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.4232, Validation Loss: 0.7364, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.4698, Validation Loss: 0.7224, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.3907, Validation Loss: 0.7250, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.4406, Validation Loss: 0.7344, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.4225, Validation Loss: 0.7541, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.4244, Validation Loss: 0.7400, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.4066, Validation Loss: 0.7176, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.4367, Validation Loss: 0.7389, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.3834, Validation Loss: 0.7217, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.3905, Validation Loss: 0.7358, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 92, Training Loss: 0.4549, Validation Loss: 0.7281, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 93, Training Loss: 0.4122, Validation Loss: 0.7523, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 94, Training Loss: 0.4015, Validation Loss: 0.7264, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 95, Training Loss: 0.4091, Validation Loss: 0.7336, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 96, Training Loss: 0.3812, Validation Loss: 0.7442, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 97, Training Loss: 0.4247, Validation Loss: 0.7545, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 98, Training Loss: 0.4252, Validation Loss: 0.7514, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 99, Training Loss: 0.4539, Validation Loss: 0.7257, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 100, Training Loss: 0.3890, Validation Loss: 0.7418, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Running rtdetr classification training with alpha = 0.2 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.1510, Validation Loss: 4.5418, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.1889, Validation Loss: 2.4917, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.4697, Validation Loss: 1.8338, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.0607, Validation Loss: 1.8781, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.8562, Validation Loss: 1.5243, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.7056, Validation Loss: 1.4094, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.6003, Validation Loss: 1.3702, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.5013, Validation Loss: 1.2827, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.5400, Validation Loss: 1.1923, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.3912, Validation Loss: 1.1612, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.3108, Validation Loss: 1.0972, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.2474, Validation Loss: 1.1234, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 1.1607, Validation Loss: 0.9686, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 1.1343, Validation Loss: 1.0572, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 1.1246, Validation Loss: 1.0551, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 1.1301, Validation Loss: 1.0349, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 1.1180, Validation Loss: 1.0007, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 1.0727, Validation Loss: 1.0051, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 1.0795, Validation Loss: 0.9805, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 1.0059, Validation Loss: 0.9561, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 1.0255, Validation Loss: 0.8715, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.9293, Validation Loss: 0.8875, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.9486, Validation Loss: 0.7915, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.8732, Validation Loss: 0.9430, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.9132, Validation Loss: 0.8916, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.8674, Validation Loss: 0.9574, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.8426, Validation Loss: 0.7542, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.8880, Validation Loss: 0.7685, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.8060, Validation Loss: 0.9769, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.8747, Validation Loss: 0.8634, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.7862, Validation Loss: 0.9056, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.7999, Validation Loss: 0.8893, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.7519, Validation Loss: 0.8592, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.7593, Validation Loss: 0.8492, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.7864, Validation Loss: 0.8867, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.7302, Validation Loss: 0.7982, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.6629, Validation Loss: 0.7991, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.7446, Validation Loss: 0.8106, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.6146, Validation Loss: 0.7728, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.6426, Validation Loss: 0.7027, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.5830, Validation Loss: 0.6915, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.6095, Validation Loss: 0.6928, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.5742, Validation Loss: 0.6962, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.5771, Validation Loss: 0.7032, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.5218, Validation Loss: 0.6681, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.5521, Validation Loss: 0.6731, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.5573, Validation Loss: 0.6785, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.5218, Validation Loss: 0.6570, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.5184, Validation Loss: 0.6701, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.5566, Validation Loss: 0.6729, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.5038, Validation Loss: 0.6770, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.5415, Validation Loss: 0.6524, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.5000, Validation Loss: 0.6606, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.5361, Validation Loss: 0.6523, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.5242, Validation Loss: 0.6898, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.5457, Validation Loss: 0.6500, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.5244, Validation Loss: 0.6615, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.4871, Validation Loss: 0.6528, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.5369, Validation Loss: 0.6593, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.4973, Validation Loss: 0.6615, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.5258, Validation Loss: 0.6365, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.4768, Validation Loss: 0.6612, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.4576, Validation Loss: 0.6550, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.5025, Validation Loss: 0.6280, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.5052, Validation Loss: 0.6383, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.5018, Validation Loss: 0.6641, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.4935, Validation Loss: 0.6473, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.4864, Validation Loss: 0.6295, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.4800, Validation Loss: 0.6182, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.4687, Validation Loss: 0.6142, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.4364, Validation Loss: 0.6373, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.4826, Validation Loss: 0.6622, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.4129, Validation Loss: 0.6697, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.4818, Validation Loss: 0.6443, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.4425, Validation Loss: 0.6254, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.4439, Validation Loss: 0.6486, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.4454, Validation Loss: 0.6288, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.4654, Validation Loss: 0.6089, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.4102, Validation Loss: 0.6382, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.4214, Validation Loss: 0.6514, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.4329, Validation Loss: 0.6269, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.4808, Validation Loss: 0.6445, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.4476, Validation Loss: 0.6585, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.4669, Validation Loss: 0.6016, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.4420, Validation Loss: 0.6202, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.4404, Validation Loss: 0.6133, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.4293, Validation Loss: 0.6583, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.4799, Validation Loss: 0.6163, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.4034, Validation Loss: 0.5750, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 90, Training Loss: 0.4229, Validation Loss: 0.5960, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 91, Training Loss: 0.4391, Validation Loss: 0.6125, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 92, Training Loss: 0.4201, Validation Loss: 0.6215, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 93, Training Loss: 0.3693, Validation Loss: 0.5891, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 94, Training Loss: 0.4014, Validation Loss: 0.6183, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 95, Training Loss: 0.3960, Validation Loss: 0.6133, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 96, Training Loss: 0.3808, Validation Loss: 0.6202, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 97, Training Loss: 0.4581, Validation Loss: 0.6061, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 98, Training Loss: 0.4704, Validation Loss: 0.6197, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 99, Training Loss: 0.3949, Validation Loss: 0.5988, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 100, Training Loss: 0.3726, Validation Loss: 0.6086, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Running rtdetr classification training with alpha = 0.5 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.9563, Validation Loss: 3.4622, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.4105, Validation Loss: 1.7149, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 1.8399, Validation Loss: 1.4776, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.6624, Validation Loss: 1.4189, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.4135, Validation Loss: 1.2343, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.4082, Validation Loss: 1.2209, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.2586, Validation Loss: 0.9682, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.1972, Validation Loss: 0.9561, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.1300, Validation Loss: 0.8599, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 1.1064, Validation Loss: 0.9086, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 1.0326, Validation Loss: 0.8634, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.9402, Validation Loss: 0.8821, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.9434, Validation Loss: 0.9289, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.9057, Validation Loss: 0.8552, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.8644, Validation Loss: 0.7164, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.8691, Validation Loss: 0.7494, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.8914, Validation Loss: 0.7155, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.8705, Validation Loss: 0.7594, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.7762, Validation Loss: 0.6575, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.8718, Validation Loss: 0.7483, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.7896, Validation Loss: 0.7751, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.8030, Validation Loss: 0.6876, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.7793, Validation Loss: 0.6508, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.7816, Validation Loss: 0.6044, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.6640, Validation Loss: 0.6466, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.7335, Validation Loss: 0.6456, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.7126, Validation Loss: 0.6413, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.7181, Validation Loss: 0.7561, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.7233, Validation Loss: 0.6099, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.6585, Validation Loss: 0.6019, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.6473, Validation Loss: 0.5839, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.6613, Validation Loss: 0.5893, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.6981, Validation Loss: 0.5923, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.7050, Validation Loss: 0.7427, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.6278, Validation Loss: 0.5641, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.6707, Validation Loss: 0.5388, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.5818, Validation Loss: 0.5946, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.6252, Validation Loss: 0.5826, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.6883, Validation Loss: 0.5882, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.6417, Validation Loss: 0.5432, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.5733, Validation Loss: 0.5612, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.5357, Validation Loss: 0.5825, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.5552, Validation Loss: 0.6088, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.5536, Validation Loss: 0.5641, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.5482, Validation Loss: 0.4812, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.5086, Validation Loss: 0.5380, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.5303, Validation Loss: 0.5523, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.5407, Validation Loss: 0.5883, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.4924, Validation Loss: 0.5485, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.5957, Validation Loss: 0.5673, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.5169, Validation Loss: 0.5276, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.5569, Validation Loss: 0.5138, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.4900, Validation Loss: 0.5588, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.5171, Validation Loss: 0.5572, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.5014, Validation Loss: 0.5717, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.5125, Validation Loss: 0.5347, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.4072, Validation Loss: 0.5232, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.3921, Validation Loss: 0.5236, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.4174, Validation Loss: 0.5164, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.3840, Validation Loss: 0.5399, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.3783, Validation Loss: 0.5235, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.3848, Validation Loss: 0.5066, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.3944, Validation Loss: 0.5060, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.3711, Validation Loss: 0.4898, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.3792, Validation Loss: 0.4931, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Early stopping triggered.
Running rtdetr classification training with alpha = 0.8 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.3380, Validation Loss: 2.8609, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 1.9381, Validation Loss: 1.5904, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.5335, Validation Loss: 1.3585, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.3940, Validation Loss: 1.1373, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.2737, Validation Loss: 0.9849, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.1434, Validation Loss: 0.8904, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.1093, Validation Loss: 0.9016, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.0062, Validation Loss: 0.8580, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.9297, Validation Loss: 0.7779, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.8403, Validation Loss: 0.7505, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.8129, Validation Loss: 0.7332, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.8268, Validation Loss: 0.6531, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.7894, Validation Loss: 0.6312, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.8116, Validation Loss: 0.6773, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.7618, Validation Loss: 0.6428, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.7382, Validation Loss: 0.7483, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.8218, Validation Loss: 0.6158, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.7679, Validation Loss: 0.6281, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.7321, Validation Loss: 0.5843, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.6734, Validation Loss: 0.7173, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.7059, Validation Loss: 0.6008, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.7082, Validation Loss: 0.6592, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.7064, Validation Loss: 0.5437, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.6634, Validation Loss: 0.5561, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.6553, Validation Loss: 0.6565, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.7085, Validation Loss: 0.7588, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.6658, Validation Loss: 0.5893, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.6336, Validation Loss: 0.5425, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.6102, Validation Loss: 0.5721, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.5994, Validation Loss: 0.5598, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.5832, Validation Loss: 0.5758, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.5966, Validation Loss: 0.5480, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.5487, Validation Loss: 0.5187, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.6580, Validation Loss: 0.5089, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.6136, Validation Loss: 0.5085, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.5775, Validation Loss: 0.4899, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.5552, Validation Loss: 0.5045, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.5688, Validation Loss: 0.4598, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.5606, Validation Loss: 0.4953, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.5358, Validation Loss: 0.4405, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.5091, Validation Loss: 0.4933, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.4806, Validation Loss: 0.4498, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.5290, Validation Loss: 0.4996, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.5232, Validation Loss: 0.4612, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.4759, Validation Loss: 0.4694, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.4980, Validation Loss: 0.5010, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.4800, Validation Loss: 0.4379, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.4908, Validation Loss: 0.4094, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.4501, Validation Loss: 0.4373, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.4621, Validation Loss: 0.4164, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.4636, Validation Loss: 0.4610, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.5217, Validation Loss: 0.4889, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.4288, Validation Loss: 0.4380, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.4352, Validation Loss: 0.4971, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.4919, Validation Loss: 0.4830, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.4759, Validation Loss: 0.4689, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.4437, Validation Loss: 0.4291, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.4334, Validation Loss: 0.4261, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.4068, Validation Loss: 0.4084, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.4203, Validation Loss: 0.4519, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.4527, Validation Loss: 0.4306, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.4467, Validation Loss: 0.4813, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.4172, Validation Loss: 0.4405, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.4225, Validation Loss: 0.4413, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.3960, Validation Loss: 0.3935, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.3932, Validation Loss: 0.4123, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.3647, Validation Loss: 0.3710, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.3777, Validation Loss: 0.3785, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.3850, Validation Loss: 0.4465, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.3768, Validation Loss: 0.4568, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.3876, Validation Loss: 0.4276, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.4025, Validation Loss: 0.4103, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.3694, Validation Loss: 0.4271, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.3480, Validation Loss: 0.4340, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.4029, Validation Loss: 0.4637, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.3713, Validation Loss: 0.4038, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.3257, Validation Loss: 0.3263, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.3624, Validation Loss: 0.4126, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.3150, Validation Loss: 0.4247, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.3485, Validation Loss: 0.3911, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.3397, Validation Loss: 0.4023, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.3980, Validation Loss: 0.5485, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.3613, Validation Loss: 0.4192, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.3528, Validation Loss: 0.4581, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.3439, Validation Loss: 0.4567, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.3073, Validation Loss: 0.4528, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.3629, Validation Loss: 0.4161, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.3171, Validation Loss: 0.4216, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.2836, Validation Loss: 0.3640, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.2651, Validation Loss: 0.3509, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.2410, Validation Loss: 0.3389, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.2531, Validation Loss: 0.3447, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.2399, Validation Loss: 0.3400, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.2550, Validation Loss: 0.3333, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.2334, Validation Loss: 0.3413, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.2370, Validation Loss: 0.3427, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.2055, Validation Loss: 0.3432, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Early stopping triggered.
Running rtdetr classification training with alpha = 1 using script scripts/rt-detr/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 2.9884, Validation Loss: 2.3853, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 1.7625, Validation Loss: 1.4167, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.4362, Validation Loss: 1.1877, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.2174, Validation Loss: 1.0977, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.0811, Validation Loss: 0.8677, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 0.9892, Validation Loss: 0.8106, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 0.9514, Validation Loss: 0.7566, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.9290, Validation Loss: 0.7160, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.8307, Validation Loss: 0.7016, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.8102, Validation Loss: 0.7024, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.7573, Validation Loss: 0.6185, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.7769, Validation Loss: 0.6859, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.7755, Validation Loss: 0.5904, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.7747, Validation Loss: 0.6017, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.6824, Validation Loss: 0.5995, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.6285, Validation Loss: 0.5661, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.6366, Validation Loss: 0.5546, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.6512, Validation Loss: 0.5305, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.5932, Validation Loss: 0.6009, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.5816, Validation Loss: 0.5751, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.5698, Validation Loss: 0.5309, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.6333, Validation Loss: 0.4916, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.5999, Validation Loss: 0.7889, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.5595, Validation Loss: 0.5107, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.5361, Validation Loss: 0.4853, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.6182, Validation Loss: 0.4754, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.5204, Validation Loss: 0.5212, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.4924, Validation Loss: 0.5224, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.5397, Validation Loss: 0.4891, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.5101, Validation Loss: 0.5009, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.5702, Validation Loss: 0.5371, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.5419, Validation Loss: 0.5099, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.4869, Validation Loss: 0.4856, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.4494, Validation Loss: 0.4152, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.4919, Validation Loss: 0.4793, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.4910, Validation Loss: 0.4737, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.5133, Validation Loss: 0.4996, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.4876, Validation Loss: 0.4436, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.4452, Validation Loss: 0.4502, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.4601, Validation Loss: 0.4123, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.4186, Validation Loss: 0.4022, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.4153, Validation Loss: 0.5137, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.4011, Validation Loss: 0.4497, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.3904, Validation Loss: 0.3792, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.4426, Validation Loss: 0.5224, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.4153, Validation Loss: 0.4128, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.4327, Validation Loss: 0.4525, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.3960, Validation Loss: 0.5453, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.3864, Validation Loss: 0.3801, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.4059, Validation Loss: 0.4060, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.3448, Validation Loss: 0.4448, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.3437, Validation Loss: 0.3835, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.4330, Validation Loss: 0.4225, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.3515, Validation Loss: 0.4211, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.3840, Validation Loss: 0.3749, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.3777, Validation Loss: 0.4023, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.3484, Validation Loss: 0.4093, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.3306, Validation Loss: 0.3891, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.3815, Validation Loss: 0.3926, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.3199, Validation Loss: 0.4055, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.3492, Validation Loss: 0.4348, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.3191, Validation Loss: 0.3594, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.2968, Validation Loss: 0.3727, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.2847, Validation Loss: 0.4084, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.3547, Validation Loss: 0.5033, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.3214, Validation Loss: 0.3566, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.3234, Validation Loss: 0.4259, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.2771, Validation Loss: 0.3900, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.3065, Validation Loss: 0.3875, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.3373, Validation Loss: 0.3628, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.2993, Validation Loss: 0.4946, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.2643, Validation Loss: 0.3338, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.2860, Validation Loss: 0.3406, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.2828, Validation Loss: 0.4385, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.3213, Validation Loss: 0.3818, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.2861, Validation Loss: 0.4814, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.3039, Validation Loss: 0.4161, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.3292, Validation Loss: 0.3693, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.3242, Validation Loss: 0.4614, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.2615, Validation Loss: 0.4026, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.3050, Validation Loss: 0.3942, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.2392, Validation Loss: 0.4316, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.2507, Validation Loss: 0.3798, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.2990, Validation Loss: 0.3292, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.2571, Validation Loss: 0.3080, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.2089, Validation Loss: 0.3111, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.2218, Validation Loss: 0.3183, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.2000, Validation Loss: 0.3333, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.2168, Validation Loss: 0.3356, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.2365, Validation Loss: 0.3151, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.1972, Validation Loss: 0.3148, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.1936, Validation Loss: 0.3216, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.1863, Validation Loss: 0.3265, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.2027, Validation Loss: 0.3154, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.1885, Validation Loss: 0.3099, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.1895, Validation Loss: 0.2991, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.1675, Validation Loss: 0.3095, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.1656, Validation Loss: 0.3374, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.1962, Validation Loss: 0.3490, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.1885, Validation Loss: 0.3342, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running yolov8 experiments:
Running yolov8 classification training with alpha = 0 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.3817, Validation Loss: 4.6160, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 4.1966, Validation Loss: 3.1005, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 3.3124, Validation Loss: 2.2493, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.7477, Validation Loss: 1.9421, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.4659, Validation Loss: 1.7163, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.3068, Validation Loss: 1.5009, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.9973, Validation Loss: 1.2261, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.7501, Validation Loss: 1.1841, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.6270, Validation Loss: 0.9779, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.6322, Validation Loss: 0.8979, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.5705, Validation Loss: 0.9975, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.4265, Validation Loss: 0.7535, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.3068, Validation Loss: 0.6841, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.2895, Validation Loss: 0.6131, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.2405, Validation Loss: 0.5692, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 1.0963, Validation Loss: 0.5560, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 1.0080, Validation Loss: 0.5636, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.9613, Validation Loss: 0.4332, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.9141, Validation Loss: 0.4514, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.8316, Validation Loss: 0.4171, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.7923, Validation Loss: 0.3572, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.8151, Validation Loss: 0.4022, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.7856, Validation Loss: 0.3423, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.9025, Validation Loss: 0.3505, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.7459, Validation Loss: 0.2776, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.7424, Validation Loss: 0.3854, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.7530, Validation Loss: 0.2522, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.7806, Validation Loss: 0.3234, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.7082, Validation Loss: 0.3355, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.6355, Validation Loss: 0.3034, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.6752, Validation Loss: 0.2918, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.6207, Validation Loss: 0.2223, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.5334, Validation Loss: 0.2549, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.5121, Validation Loss: 0.2439, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.4828, Validation Loss: 0.2403, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.5551, Validation Loss: 0.2352, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.5087, Validation Loss: 0.2472, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.4449, Validation Loss: 0.1797, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.5436, Validation Loss: 0.1955, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.4856, Validation Loss: 0.2629, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.4245, Validation Loss: 0.1929, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.5401, Validation Loss: 0.2069, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.4836, Validation Loss: 0.3897, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.5491, Validation Loss: 0.1877, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.3781, Validation Loss: 0.1837, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.4357, Validation Loss: 0.2134, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.4698, Validation Loss: 0.1960, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.4533, Validation Loss: 0.1966, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.4433, Validation Loss: 0.2078, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.3721, Validation Loss: 0.1835, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.3441, Validation Loss: 0.1611, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.2824, Validation Loss: 0.1542, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.2788, Validation Loss: 0.1500, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.3454, Validation Loss: 0.1472, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.2634, Validation Loss: 0.1509, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.2411, Validation Loss: 0.1577, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.2222, Validation Loss: 0.1499, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.2126, Validation Loss: 0.1556, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.2310, Validation Loss: 0.1456, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.2261, Validation Loss: 0.1506, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.2136, Validation Loss: 0.1541, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.2788, Validation Loss: 0.1508, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.2115, Validation Loss: 0.1406, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.2600, Validation Loss: 0.1491, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.2647, Validation Loss: 0.1516, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.1790, Validation Loss: 0.1463, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.2146, Validation Loss: 0.1493, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.1819, Validation Loss: 0.1486, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.2392, Validation Loss: 0.1448, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.2137, Validation Loss: 0.1461, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.1842, Validation Loss: 0.1483, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.1845, Validation Loss: 0.1490, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.2122, Validation Loss: 0.1402, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.2214, Validation Loss: 0.1503, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.1921, Validation Loss: 0.1421, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.2276, Validation Loss: 0.1390, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.2380, Validation Loss: 0.1430, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.1882, Validation Loss: 0.1402, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.1341, Validation Loss: 0.1434, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.1898, Validation Loss: 0.1525, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.1703, Validation Loss: 0.1422, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.1804, Validation Loss: 0.1486, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.2091, Validation Loss: 0.1416, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.1788, Validation Loss: 0.1489, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.1922, Validation Loss: 0.1459, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.1428, Validation Loss: 0.1544, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.1671, Validation Loss: 0.1484, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.1915, Validation Loss: 0.1435, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.1729, Validation Loss: 0.1508, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.1744, Validation Loss: 0.1453, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.1472, Validation Loss: 0.1471, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 92, Training Loss: 0.1527, Validation Loss: 0.1449, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 93, Training Loss: 0.1866, Validation Loss: 0.1450, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 94, Training Loss: 0.1709, Validation Loss: 0.1462, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 95, Training Loss: 0.1624, Validation Loss: 0.1488, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 96, Training Loss: 0.1585, Validation Loss: 0.1404, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Early stopping triggered.
Running yolov8 classification training with alpha = 0.2 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.2339, Validation Loss: 3.8116, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.5724, Validation Loss: 2.4307, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.7975, Validation Loss: 2.0495, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.4198, Validation Loss: 1.7183, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 2.1797, Validation Loss: 1.3661, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.8191, Validation Loss: 1.1860, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.6957, Validation Loss: 1.0167, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.5872, Validation Loss: 1.0275, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.4073, Validation Loss: 0.9353, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.3656, Validation Loss: 0.7244, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.3836, Validation Loss: 0.7811, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.1873, Validation Loss: 0.5852, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 1.1240, Validation Loss: 0.5720, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 1.0390, Validation Loss: 0.4856, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.9178, Validation Loss: 0.5626, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.9457, Validation Loss: 0.5700, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.9553, Validation Loss: 0.4772, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.8810, Validation Loss: 0.4547, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.8737, Validation Loss: 0.3976, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.8061, Validation Loss: 0.3874, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.7754, Validation Loss: 0.3050, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.6512, Validation Loss: 0.3187, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.6634, Validation Loss: 0.2734, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.6952, Validation Loss: 0.2532, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.5618, Validation Loss: 0.2166, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.5510, Validation Loss: 0.3023, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.6268, Validation Loss: 0.2760, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.5253, Validation Loss: 0.2133, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.4839, Validation Loss: 0.2119, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.4518, Validation Loss: 0.2304, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.5105, Validation Loss: 0.1765, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.4454, Validation Loss: 0.1874, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.4343, Validation Loss: 0.1662, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.3941, Validation Loss: 0.1473, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.3835, Validation Loss: 0.1642, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.4650, Validation Loss: 0.2322, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.5253, Validation Loss: 0.2131, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.3823, Validation Loss: 0.1405, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.4104, Validation Loss: 0.1935, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.5199, Validation Loss: 0.1984, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.4172, Validation Loss: 0.1520, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.3337, Validation Loss: 0.1578, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.4344, Validation Loss: 0.1655, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.3089, Validation Loss: 0.1290, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.3017, Validation Loss: 0.1646, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.3236, Validation Loss: 0.1549, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.3362, Validation Loss: 0.1735, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.2904, Validation Loss: 0.1496, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.3295, Validation Loss: 0.1515, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.3197, Validation Loss: 0.1728, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.3221, Validation Loss: 0.1350, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.2347, Validation Loss: 0.1215, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.2557, Validation Loss: 0.1396, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.2924, Validation Loss: 0.1307, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.2548, Validation Loss: 0.1301, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.2974, Validation Loss: 0.2910, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.2627, Validation Loss: 0.1334, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.3368, Validation Loss: 0.1616, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.2714, Validation Loss: 0.1341, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.3526, Validation Loss: 0.2001, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.2655, Validation Loss: 0.2193, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.2021, Validation Loss: 0.1417, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.3290, Validation Loss: 0.1944, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.2321, Validation Loss: 0.1286, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.1970, Validation Loss: 0.1142, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.1734, Validation Loss: 0.1017, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.1507, Validation Loss: 0.0981, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.1401, Validation Loss: 0.1023, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.3076, Validation Loss: 0.0974, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.1665, Validation Loss: 0.0992, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.1128, Validation Loss: 0.0945, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.1802, Validation Loss: 0.0969, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.1252, Validation Loss: 0.0950, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.1496, Validation Loss: 0.0985, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.1088, Validation Loss: 0.0968, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.1449, Validation Loss: 0.1016, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.1492, Validation Loss: 0.0938, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.1399, Validation Loss: 0.0951, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.1603, Validation Loss: 0.0920, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.1389, Validation Loss: 0.0922, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 81, Training Loss: 0.1046, Validation Loss: 0.0948, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 82, Training Loss: 0.1372, Validation Loss: 0.0997, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 83, Training Loss: 0.1054, Validation Loss: 0.1014, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 84, Training Loss: 0.1159, Validation Loss: 0.0954, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 85, Training Loss: 0.0933, Validation Loss: 0.0931, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 86, Training Loss: 0.1101, Validation Loss: 0.0889, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 87, Training Loss: 0.1247, Validation Loss: 0.0889, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 88, Training Loss: 0.1055, Validation Loss: 0.0882, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 89, Training Loss: 0.1095, Validation Loss: 0.0930, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 90, Training Loss: 0.1139, Validation Loss: 0.0967, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 91, Training Loss: 0.1125, Validation Loss: 0.0945, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 92, Training Loss: 0.1125, Validation Loss: 0.0927, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 93, Training Loss: 0.1228, Validation Loss: 0.0963, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 94, Training Loss: 0.0987, Validation Loss: 0.0903, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 95, Training Loss: 0.0959, Validation Loss: 0.0892, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 96, Training Loss: 0.0998, Validation Loss: 0.0960, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 97, Training Loss: 0.1610, Validation Loss: 0.0936, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 98, Training Loss: 0.1059, Validation Loss: 0.0926, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 99, Training Loss: 0.1345, Validation Loss: 0.0913, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 100, Training Loss: 0.1275, Validation Loss: 0.0957, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Running yolov8 classification training with alpha = 0.5 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1938, Validation Loss: 3.1153, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.8692, Validation Loss: 2.0387, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 2.2501, Validation Loss: 1.6362, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.9323, Validation Loss: 1.2849, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.5514, Validation Loss: 1.0733, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.4456, Validation Loss: 0.9039, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.4068, Validation Loss: 0.8227, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.2596, Validation Loss: 0.7536, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.1499, Validation Loss: 0.7504, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 1.1104, Validation Loss: 0.6900, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.9344, Validation Loss: 0.5238, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.9410, Validation Loss: 0.5160, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 1.0050, Validation Loss: 0.4632, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.8220, Validation Loss: 0.5742, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.8488, Validation Loss: 0.4853, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.7966, Validation Loss: 0.3877, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.8418, Validation Loss: 0.4119, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.7522, Validation Loss: 0.4179, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.7425, Validation Loss: 0.3212, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.7301, Validation Loss: 0.3677, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.7107, Validation Loss: 0.3731, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.6012, Validation Loss: 0.2695, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.5982, Validation Loss: 0.3774, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.5999, Validation Loss: 0.2551, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.5388, Validation Loss: 0.2871, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.4336, Validation Loss: 0.1851, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.4410, Validation Loss: 0.2274, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.4678, Validation Loss: 0.2403, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.4500, Validation Loss: 0.1874, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.4945, Validation Loss: 0.2050, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.4017, Validation Loss: 0.1549, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.3895, Validation Loss: 0.1722, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.3564, Validation Loss: 0.1580, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.3743, Validation Loss: 0.1827, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.3757, Validation Loss: 0.1408, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.3661, Validation Loss: 0.1694, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.3965, Validation Loss: 0.1336, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.3088, Validation Loss: 0.1313, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.3493, Validation Loss: 0.1688, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.3166, Validation Loss: 0.5150, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.3369, Validation Loss: 0.2044, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.4301, Validation Loss: 0.2291, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.3085, Validation Loss: 0.1301, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.3439, Validation Loss: 0.1382, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.3234, Validation Loss: 0.1769, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.2828, Validation Loss: 0.2171, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.3610, Validation Loss: 0.1326, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.2720, Validation Loss: 0.1134, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.3388, Validation Loss: 0.1445, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.2397, Validation Loss: 0.1039, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.2316, Validation Loss: 0.1289, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.2879, Validation Loss: 0.1075, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.2358, Validation Loss: 0.1131, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.2410, Validation Loss: 0.0997, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.2467, Validation Loss: 0.1474, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.1976, Validation Loss: 0.1107, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.2090, Validation Loss: 0.1790, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.2472, Validation Loss: 0.1213, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.2008, Validation Loss: 0.1068, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.2174, Validation Loss: 0.1344, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.2328, Validation Loss: 0.1086, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.2130, Validation Loss: 0.1104, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.2706, Validation Loss: 0.1059, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.1939, Validation Loss: 0.1053, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.1928, Validation Loss: 0.1089, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.1458, Validation Loss: 0.1093, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.1109, Validation Loss: 0.1024, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.1216, Validation Loss: 0.0931, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.1272, Validation Loss: 0.0874, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.1169, Validation Loss: 0.0911, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.1051, Validation Loss: 0.0982, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.0900, Validation Loss: 0.0904, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.1479, Validation Loss: 0.0892, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.0896, Validation Loss: 0.0903, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.0952, Validation Loss: 0.0952, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.0915, Validation Loss: 0.0944, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.1072, Validation Loss: 0.0933, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.0883, Validation Loss: 0.0855, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.0929, Validation Loss: 0.0853, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.0625, Validation Loss: 0.0874, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.0817, Validation Loss: 0.0927, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.1044, Validation Loss: 0.0924, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.0832, Validation Loss: 0.0846, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.0697, Validation Loss: 0.0832, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0825, Validation Loss: 0.0853, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.0764, Validation Loss: 0.0858, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.0985, Validation Loss: 0.0897, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0888, Validation Loss: 0.0959, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.0779, Validation Loss: 0.0970, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.0816, Validation Loss: 0.0893, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.0851, Validation Loss: 0.0923, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.0752, Validation Loss: 0.0961, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.0681, Validation Loss: 0.0990, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 94, Training Loss: 0.0836, Validation Loss: 0.0896, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 95, Training Loss: 0.0725, Validation Loss: 0.0845, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 96, Training Loss: 0.0854, Validation Loss: 0.0903, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 97, Training Loss: 0.0808, Validation Loss: 0.0884, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 98, Training Loss: 0.0824, Validation Loss: 0.0910, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 99, Training Loss: 0.0678, Validation Loss: 0.0887, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 100, Training Loss: 0.0528, Validation Loss: 0.0907, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Running yolov8 classification training with alpha = 0.8 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.4936, Validation Loss: 2.5080, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 2.3531, Validation Loss: 1.6160, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.8682, Validation Loss: 1.3338, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.6565, Validation Loss: 1.1483, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.3830, Validation Loss: 0.9714, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.2108, Validation Loss: 0.7741, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.0496, Validation Loss: 0.6558, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.0356, Validation Loss: 0.5997, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.9427, Validation Loss: 0.5561, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.9078, Validation Loss: 0.4688, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.7979, Validation Loss: 0.4477, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.7999, Validation Loss: 0.4586, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.6894, Validation Loss: 0.5524, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.6653, Validation Loss: 0.3795, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.5872, Validation Loss: 0.4164, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.6105, Validation Loss: 0.2677, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.6023, Validation Loss: 0.2634, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.6161, Validation Loss: 0.3059, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.5351, Validation Loss: 0.2238, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.5322, Validation Loss: 0.2265, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.5097, Validation Loss: 0.2008, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.4287, Validation Loss: 0.1733, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.3908, Validation Loss: 0.2293, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.4222, Validation Loss: 0.1556, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.3556, Validation Loss: 0.1681, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.3576, Validation Loss: 0.1717, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.3374, Validation Loss: 0.1710, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.3306, Validation Loss: 0.1440, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.2810, Validation Loss: 0.1127, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.3377, Validation Loss: 0.1251, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.3150, Validation Loss: 0.1193, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.2809, Validation Loss: 0.1181, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.3101, Validation Loss: 0.1090, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.2343, Validation Loss: 0.1182, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.2793, Validation Loss: 0.1099, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.3349, Validation Loss: 0.1495, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.2584, Validation Loss: 0.0987, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.2514, Validation Loss: 0.1272, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.2518, Validation Loss: 0.0797, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.2020, Validation Loss: 0.1134, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.2486, Validation Loss: 0.1419, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.2475, Validation Loss: 0.0879, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.2234, Validation Loss: 0.0868, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.2492, Validation Loss: 0.1018, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.2338, Validation Loss: 0.0967, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.1957, Validation Loss: 0.1064, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.1691, Validation Loss: 0.0709, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.1951, Validation Loss: 0.0908, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.1839, Validation Loss: 0.1173, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.2241, Validation Loss: 0.1060, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.1695, Validation Loss: 0.0904, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.1826, Validation Loss: 0.1019, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.2079, Validation Loss: 0.0782, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.1712, Validation Loss: 0.1145, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.1895, Validation Loss: 0.1185, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.1907, Validation Loss: 0.0760, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.1912, Validation Loss: 0.0803, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.2454, Validation Loss: 0.1065, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.1678, Validation Loss: 0.0678, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.1672, Validation Loss: 0.0606, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.1173, Validation Loss: 0.0618, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.1200, Validation Loss: 0.0615, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.1172, Validation Loss: 0.0612, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.1615, Validation Loss: 0.0641, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.1142, Validation Loss: 0.0620, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.0809, Validation Loss: 0.0604, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.0834, Validation Loss: 0.0630, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.1116, Validation Loss: 0.0620, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.0967, Validation Loss: 0.0595, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.0899, Validation Loss: 0.0594, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.0999, Validation Loss: 0.0595, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.0982, Validation Loss: 0.0623, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.0678, Validation Loss: 0.0588, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.1004, Validation Loss: 0.0570, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.0781, Validation Loss: 0.0579, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.0873, Validation Loss: 0.0584, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.0830, Validation Loss: 0.0669, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.1011, Validation Loss: 0.0666, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.0773, Validation Loss: 0.0621, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.0818, Validation Loss: 0.0592, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.0852, Validation Loss: 0.0619, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.0855, Validation Loss: 0.0660, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.1094, Validation Loss: 0.0632, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.0866, Validation Loss: 0.0638, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.0553, Validation Loss: 0.0611, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.0703, Validation Loss: 0.0576, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.0700, Validation Loss: 0.0587, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.0653, Validation Loss: 0.0582, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.0797, Validation Loss: 0.0577, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.0591, Validation Loss: 0.0577, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.0553, Validation Loss: 0.0562, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.0875, Validation Loss: 0.0586, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.0692, Validation Loss: 0.0581, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.0696, Validation Loss: 0.0581, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.0511, Validation Loss: 0.0591, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.0559, Validation Loss: 0.0582, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.0688, Validation Loss: 0.0578, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 98, Training Loss: 0.0592, Validation Loss: 0.0574, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 99, Training Loss: 0.0754, Validation Loss: 0.0589, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 100, Training Loss: 0.0686, Validation Loss: 0.0576, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Running yolov8 classification training with alpha = 1 using script scripts/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.2568, Validation Loss: 2.3854, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 2.3193, Validation Loss: 1.6853, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.8950, Validation Loss: 1.3639, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.6067, Validation Loss: 1.1983, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.4650, Validation Loss: 1.0788, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.2783, Validation Loss: 0.8575, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 1.1917, Validation Loss: 0.7172, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.9942, Validation Loss: 0.6742, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.9405, Validation Loss: 0.5301, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.7968, Validation Loss: 0.4971, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.7342, Validation Loss: 0.4986, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.7546, Validation Loss: 0.4058, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.7243, Validation Loss: 0.3385, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.6487, Validation Loss: 0.3287, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.6725, Validation Loss: 0.3942, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.5804, Validation Loss: 0.3604, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.5246, Validation Loss: 0.2378, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.4987, Validation Loss: 0.2415, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.5103, Validation Loss: 0.1860, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.4228, Validation Loss: 0.2598, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.4214, Validation Loss: 0.2162, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.4045, Validation Loss: 0.1685, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.3847, Validation Loss: 0.1779, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.4184, Validation Loss: 0.1443, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.3362, Validation Loss: 0.1717, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.3355, Validation Loss: 0.1373, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.3494, Validation Loss: 0.1285, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.3429, Validation Loss: 0.1495, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.3521, Validation Loss: 0.1074, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.2791, Validation Loss: 0.1532, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.3134, Validation Loss: 0.1013, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.3385, Validation Loss: 0.1021, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.3714, Validation Loss: 0.1953, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.2512, Validation Loss: 0.1106, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.2474, Validation Loss: 0.0904, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.2473, Validation Loss: 0.1000, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.2281, Validation Loss: 0.1153, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.2361, Validation Loss: 0.1049, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.2314, Validation Loss: 0.0835, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.2208, Validation Loss: 0.1435, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.2511, Validation Loss: 0.0794, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.2074, Validation Loss: 0.1123, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.2079, Validation Loss: 0.2134, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.2643, Validation Loss: 0.0970, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.2286, Validation Loss: 0.1127, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.2149, Validation Loss: 0.0704, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.2025, Validation Loss: 0.0910, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.1950, Validation Loss: 0.0754, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.2107, Validation Loss: 0.0833, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.1997, Validation Loss: 0.1535, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.1950, Validation Loss: 0.0873, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.2070, Validation Loss: 0.1102, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.1953, Validation Loss: 0.1000, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.2336, Validation Loss: 0.1130, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.1540, Validation Loss: 0.1130, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.1842, Validation Loss: 0.0844, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.1903, Validation Loss: 0.0825, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.1685, Validation Loss: 0.0602, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.1881, Validation Loss: 0.0615, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.1155, Validation Loss: 0.0625, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.1155, Validation Loss: 0.0683, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.1012, Validation Loss: 0.0616, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.1045, Validation Loss: 0.0610, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.1387, Validation Loss: 0.0692, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.0987, Validation Loss: 0.0641, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.0775, Validation Loss: 0.0635, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.0770, Validation Loss: 0.0620, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.0823, Validation Loss: 0.0618, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.1095, Validation Loss: 0.0608, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.1184, Validation Loss: 0.0622, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.1114, Validation Loss: 0.0600, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.0784, Validation Loss: 0.0620, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.1119, Validation Loss: 0.0613, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.1012, Validation Loss: 0.0591, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.0894, Validation Loss: 0.0596, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.0877, Validation Loss: 0.0602, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.0821, Validation Loss: 0.0586, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.0741, Validation Loss: 0.0627, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.0729, Validation Loss: 0.0639, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.0853, Validation Loss: 0.0632, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.0906, Validation Loss: 0.0593, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.1253, Validation Loss: 0.0587, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.0831, Validation Loss: 0.0583, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.0864, Validation Loss: 0.0585, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0874, Validation Loss: 0.0635, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.0888, Validation Loss: 0.0575, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.0836, Validation Loss: 0.0585, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.1203, Validation Loss: 0.0584, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.0783, Validation Loss: 0.0617, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.0864, Validation Loss: 0.0582, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.0772, Validation Loss: 0.0598, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.0741, Validation Loss: 0.0587, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.0909, Validation Loss: 0.0564, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.0787, Validation Loss: 0.0611, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.0648, Validation Loss: 0.0562, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.0667, Validation Loss: 0.0579, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.0918, Validation Loss: 0.0569, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.0871, Validation Loss: 0.0574, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.0870, Validation Loss: 0.0565, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.0898, Validation Loss: 0.0591, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running yolov9 experiments:
Running yolov9 classification training with alpha = 0 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 6.4928, Validation Loss: 4.9585, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 4.3814, Validation Loss: 3.2470, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 3.4659, Validation Loss: 2.4663, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 2.9240, Validation Loss: 1.9658, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 2.5218, Validation Loss: 1.6952, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 2.1060, Validation Loss: 1.3896, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.9939, Validation Loss: 1.2737, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 1.8496, Validation Loss: 1.1385, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.6405, Validation Loss: 1.1067, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 1.5628, Validation Loss: 0.8792, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 1.4790, Validation Loss: 0.9128, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 1.4075, Validation Loss: 0.7168, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 1.3078, Validation Loss: 0.7078, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 1.0847, Validation Loss: 0.6102, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 1.1619, Validation Loss: 0.6697, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 1.0956, Validation Loss: 0.6088, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 1.2251, Validation Loss: 0.5507, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.8834, Validation Loss: 0.5137, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.9585, Validation Loss: 0.5025, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.8892, Validation Loss: 0.4520, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.8252, Validation Loss: 0.4163, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.8667, Validation Loss: 0.4718, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.8136, Validation Loss: 0.3799, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.8014, Validation Loss: 0.3494, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.8189, Validation Loss: 0.3726, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.8562, Validation Loss: 0.3442, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.7086, Validation Loss: 0.4079, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.6217, Validation Loss: 0.3210, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.5793, Validation Loss: 0.2911, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.5551, Validation Loss: 0.3146, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.6856, Validation Loss: 0.4650, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.7257, Validation Loss: 0.4414, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.5028, Validation Loss: 0.2674, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.6710, Validation Loss: 0.2755, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.5402, Validation Loss: 0.2908, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.5049, Validation Loss: 0.3152, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.6074, Validation Loss: 0.2917, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.5357, Validation Loss: 0.2416, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.5661, Validation Loss: 0.2250, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.4688, Validation Loss: 0.2163, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.4667, Validation Loss: 0.2651, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.4646, Validation Loss: 0.2273, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.5628, Validation Loss: 0.2277, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.4760, Validation Loss: 0.2454, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.4810, Validation Loss: 0.2105, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.3982, Validation Loss: 0.2154, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.4225, Validation Loss: 0.2115, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.3780, Validation Loss: 0.2028, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.4524, Validation Loss: 0.2248, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.3659, Validation Loss: 0.2494, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.4305, Validation Loss: 0.2290, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.3118, Validation Loss: 0.2675, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.3445, Validation Loss: 0.2268, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.3054, Validation Loss: 0.2456, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.3801, Validation Loss: 0.2055, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.3596, Validation Loss: 0.2235, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.3515, Validation Loss: 0.2202, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.4513, Validation Loss: 0.2264, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.3468, Validation Loss: 0.2145, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.2379, Validation Loss: 0.1837, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.2342, Validation Loss: 0.1693, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.1919, Validation Loss: 0.1572, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.2582, Validation Loss: 0.1728, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.1750, Validation Loss: 0.1690, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.1918, Validation Loss: 0.1629, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.1754, Validation Loss: 0.1550, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.2329, Validation Loss: 0.1556, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.2104, Validation Loss: 0.1620, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.1826, Validation Loss: 0.1792, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.2111, Validation Loss: 0.1642, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.2026, Validation Loss: 0.1486, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.1820, Validation Loss: 0.1513, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.1505, Validation Loss: 0.1519, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.1575, Validation Loss: 0.1698, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.1795, Validation Loss: 0.1610, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.1581, Validation Loss: 0.1554, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.1877, Validation Loss: 0.1656, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.1581, Validation Loss: 0.1582, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.1523, Validation Loss: 0.1643, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.1425, Validation Loss: 0.1626, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.1193, Validation Loss: 0.1630, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.1520, Validation Loss: 0.1589, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.1721, Validation Loss: 0.1565, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.1743, Validation Loss: 0.1596, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.1107, Validation Loss: 0.1613, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.1534, Validation Loss: 0.1563, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.1552, Validation Loss: 0.1577, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.1412, Validation Loss: 0.1555, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.1294, Validation Loss: 0.1590, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.1618, Validation Loss: 0.1509, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.1728, Validation Loss: 0.1565, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Early stopping triggered.
Running yolov9 classification training with alpha = 0.2 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 5.0275, Validation Loss: 3.7503, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 3.4345, Validation Loss: 2.6122, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 2.7631, Validation Loss: 2.0217, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 2.2849, Validation Loss: 1.6575, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 2.0865, Validation Loss: 1.4179, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.7975, Validation Loss: 1.2360, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 1.6013, Validation Loss: 1.1003, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 1.4324, Validation Loss: 0.9631, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 1.5389, Validation Loss: 0.8821, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 1.3623, Validation Loss: 0.7755, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 1.1467, Validation Loss: 0.7050, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 1.0660, Validation Loss: 0.6475, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 1.0272, Validation Loss: 0.5315, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 0.9702, Validation Loss: 0.6055, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.9711, Validation Loss: 0.4832, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.8734, Validation Loss: 0.4267, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.8881, Validation Loss: 0.4782, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.8692, Validation Loss: 0.4454, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.7568, Validation Loss: 0.4162, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.7901, Validation Loss: 0.4819, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.7415, Validation Loss: 0.4569, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.6430, Validation Loss: 0.3080, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.7310, Validation Loss: 0.3095, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.6406, Validation Loss: 0.6001, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.7333, Validation Loss: 0.3452, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.5887, Validation Loss: 0.3193, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.5735, Validation Loss: 0.2729, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.4880, Validation Loss: 0.3010, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.6310, Validation Loss: 0.3652, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.5185, Validation Loss: 0.3017, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.4625, Validation Loss: 0.2492, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.4728, Validation Loss: 0.2253, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.4976, Validation Loss: 0.3749, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.4241, Validation Loss: 0.2429, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.4439, Validation Loss: 0.2863, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.3720, Validation Loss: 0.2169, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.4380, Validation Loss: 0.2871, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.4429, Validation Loss: 0.2152, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.4324, Validation Loss: 0.2625, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.3846, Validation Loss: 0.2468, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.3413, Validation Loss: 0.2511, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.3252, Validation Loss: 0.2291, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.4040, Validation Loss: 0.2069, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.3758, Validation Loss: 0.2014, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.3507, Validation Loss: 0.2748, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.4511, Validation Loss: 0.2874, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.3510, Validation Loss: 0.2359, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.3289, Validation Loss: 0.2372, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.3472, Validation Loss: 0.2589, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.4354, Validation Loss: 0.2216, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.2987, Validation Loss: 0.3221, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.3601, Validation Loss: 0.3097, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.2799, Validation Loss: 0.2039, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.3286, Validation Loss: 0.2391, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.3377, Validation Loss: 0.3225, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.2905, Validation Loss: 0.1766, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.2112, Validation Loss: 0.1627, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.3069, Validation Loss: 0.1572, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.1864, Validation Loss: 0.1510, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.1628, Validation Loss: 0.1508, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.1782, Validation Loss: 0.1516, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.2060, Validation Loss: 0.1607, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.1700, Validation Loss: 0.1643, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.1682, Validation Loss: 0.1535, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.1434, Validation Loss: 0.1564, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.1827, Validation Loss: 0.1546, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.1802, Validation Loss: 0.1542, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.1482, Validation Loss: 0.1553, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.1542, Validation Loss: 0.1636, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.1422, Validation Loss: 0.1549, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.1506, Validation Loss: 0.1526, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.1388, Validation Loss: 0.1531, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.1568, Validation Loss: 0.1546, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.1464, Validation Loss: 0.1569, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.1991, Validation Loss: 0.1592, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.1309, Validation Loss: 0.1525, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.1286, Validation Loss: 0.1551, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.1819, Validation Loss: 0.1569, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.1270, Validation Loss: 0.1554, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 80, Training Loss: 0.1702, Validation Loss: 0.1549, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Early stopping triggered.
Running yolov9 classification training with alpha = 0.5 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1370, Validation Loss: 2.9469, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 2.8264, Validation Loss: 2.0772, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 2.3271, Validation Loss: 1.6719, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.8783, Validation Loss: 1.3300, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 1.6051, Validation Loss: 1.0541, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 1.4129, Validation Loss: 0.9710, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 1.2632, Validation Loss: 0.7892, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 1.1663, Validation Loss: 0.7099, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 1.1278, Validation Loss: 0.6745, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 0.9949, Validation Loss: 0.4966, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.8641, Validation Loss: 0.5478, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.8469, Validation Loss: 0.3727, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.6986, Validation Loss: 0.3051, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.6268, Validation Loss: 0.2868, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.6578, Validation Loss: 0.3160, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.6284, Validation Loss: 0.2590, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.6275, Validation Loss: 0.2301, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.5126, Validation Loss: 0.2277, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.5450, Validation Loss: 0.1871, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.5567, Validation Loss: 0.2984, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.5028, Validation Loss: 0.1818, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.4621, Validation Loss: 0.1912, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.4479, Validation Loss: 0.1975, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.5016, Validation Loss: 0.2107, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.4015, Validation Loss: 0.2124, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.4240, Validation Loss: 0.2139, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.3940, Validation Loss: 0.1563, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.3553, Validation Loss: 0.1614, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.4153, Validation Loss: 0.1773, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.3885, Validation Loss: 0.2054, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.3375, Validation Loss: 0.1632, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.2840, Validation Loss: 0.1594, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.3022, Validation Loss: 0.1290, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.2976, Validation Loss: 0.1657, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.3131, Validation Loss: 0.2139, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.3118, Validation Loss: 0.1571, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.3064, Validation Loss: 0.1300, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.2699, Validation Loss: 0.1490, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.2182, Validation Loss: 0.1336, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.2396, Validation Loss: 0.1775, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.3296, Validation Loss: 0.1270, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.2696, Validation Loss: 0.1582, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.2931, Validation Loss: 0.1570, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.2714, Validation Loss: 0.1373, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.2870, Validation Loss: 0.1314, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.2397, Validation Loss: 0.1235, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.2360, Validation Loss: 0.2184, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.2447, Validation Loss: 0.1596, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.3517, Validation Loss: 0.1359, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.2631, Validation Loss: 0.1446, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.2394, Validation Loss: 0.1331, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.2763, Validation Loss: 0.1327, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.2275, Validation Loss: 0.1469, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.2206, Validation Loss: 0.1774, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.2321, Validation Loss: 0.1250, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.1908, Validation Loss: 0.1639, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.2047, Validation Loss: 0.1375, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.1475, Validation Loss: 0.1026, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.1356, Validation Loss: 0.1019, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.1492, Validation Loss: 0.0851, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.1150, Validation Loss: 0.0869, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.1028, Validation Loss: 0.0868, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.1252, Validation Loss: 0.0891, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.1300, Validation Loss: 0.0838, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.1093, Validation Loss: 0.0868, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.1136, Validation Loss: 0.0865, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 67, Training Loss: 0.0801, Validation Loss: 0.0868, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 68, Training Loss: 0.1189, Validation Loss: 0.0876, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 69, Training Loss: 0.1238, Validation Loss: 0.0863, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 70, Training Loss: 0.1042, Validation Loss: 0.0907, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 71, Training Loss: 0.1568, Validation Loss: 0.0892, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 72, Training Loss: 0.1227, Validation Loss: 0.0846, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 73, Training Loss: 0.0970, Validation Loss: 0.0801, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 74, Training Loss: 0.0968, Validation Loss: 0.0861, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 75, Training Loss: 0.1125, Validation Loss: 0.0849, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 76, Training Loss: 0.0964, Validation Loss: 0.0829, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 77, Training Loss: 0.0842, Validation Loss: 0.0818, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 78, Training Loss: 0.0945, Validation Loss: 0.0861, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 79, Training Loss: 0.0816, Validation Loss: 0.0816, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 80, Training Loss: 0.0857, Validation Loss: 0.0813, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 81, Training Loss: 0.1330, Validation Loss: 0.0836, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 82, Training Loss: 0.0723, Validation Loss: 0.0848, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 83, Training Loss: 0.0772, Validation Loss: 0.0856, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 84, Training Loss: 0.0716, Validation Loss: 0.0865, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 85, Training Loss: 0.0827, Validation Loss: 0.0882, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 86, Training Loss: 0.0918, Validation Loss: 0.0863, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 87, Training Loss: 0.0899, Validation Loss: 0.0863, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 88, Training Loss: 0.0677, Validation Loss: 0.0840, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 89, Training Loss: 0.0660, Validation Loss: 0.0857, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 90, Training Loss: 0.0709, Validation Loss: 0.0874, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 91, Training Loss: 0.0897, Validation Loss: 0.0844, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 92, Training Loss: 0.0856, Validation Loss: 0.0846, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 93, Training Loss: 0.0803, Validation Loss: 0.0828, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Early stopping triggered.
Running yolov9 classification training with alpha = 0.8 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.4920, Validation Loss: 2.6323, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 2.4408, Validation Loss: 1.8967, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 2.0059, Validation Loss: 1.5062, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 1.7160, Validation Loss: 1.2491, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 1.5838, Validation Loss: 1.0430, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 1.3555, Validation Loss: 1.1051, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 1.2361, Validation Loss: 0.8843, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 1.1330, Validation Loss: 0.7233, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 1.0172, Validation Loss: 0.6416, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 1.0113, Validation Loss: 0.6110, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.8750, Validation Loss: 0.4919, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.8240, Validation Loss: 0.4985, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.7938, Validation Loss: 0.4305, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.7362, Validation Loss: 0.4218, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.7426, Validation Loss: 0.3884, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.6370, Validation Loss: 0.3466, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.6980, Validation Loss: 0.3296, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.5662, Validation Loss: 0.3412, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.6939, Validation Loss: 0.3374, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.5681, Validation Loss: 0.2984, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.5327, Validation Loss: 0.2736, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.6379, Validation Loss: 0.2636, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.4879, Validation Loss: 0.2256, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.4744, Validation Loss: 0.1996, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.4616, Validation Loss: 0.2624, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.4686, Validation Loss: 0.2321, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.4442, Validation Loss: 0.2459, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.4761, Validation Loss: 0.2408, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.4758, Validation Loss: 0.1745, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.3479, Validation Loss: 0.1797, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.3567, Validation Loss: 0.1994, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.4092, Validation Loss: 0.1785, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.3337, Validation Loss: 0.1774, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.3763, Validation Loss: 0.2100, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.3838, Validation Loss: 0.1804, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.2737, Validation Loss: 0.2909, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.3044, Validation Loss: 0.1549, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.2517, Validation Loss: 0.1551, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.3056, Validation Loss: 0.1528, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.3813, Validation Loss: 0.1439, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.3239, Validation Loss: 0.1644, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.2371, Validation Loss: 0.1954, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.2965, Validation Loss: 0.1595, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.2641, Validation Loss: 0.1555, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.2785, Validation Loss: 0.1533, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.2501, Validation Loss: 0.1806, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.2203, Validation Loss: 0.1678, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.1994, Validation Loss: 0.1389, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.2021, Validation Loss: 0.1586, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.1767, Validation Loss: 0.1482, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.2647, Validation Loss: 0.1396, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.2835, Validation Loss: 0.1927, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.1981, Validation Loss: 0.2305, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.2262, Validation Loss: 0.1449, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.2202, Validation Loss: 0.1217, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.1625, Validation Loss: 0.1490, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.2084, Validation Loss: 0.1401, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.1921, Validation Loss: 0.1180, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.1631, Validation Loss: 0.1295, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.1714, Validation Loss: 0.1325, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.1694, Validation Loss: 0.1318, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.1728, Validation Loss: 0.1271, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.1965, Validation Loss: 0.1595, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.1606, Validation Loss: 0.1260, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.2014, Validation Loss: 0.1431, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.1315, Validation Loss: 0.1566, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.2486, Validation Loss: 0.1780, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.1837, Validation Loss: 0.1571, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.1682, Validation Loss: 0.1169, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.1908, Validation Loss: 0.1293, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.1346, Validation Loss: 0.1449, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.1637, Validation Loss: 0.1124, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.1579, Validation Loss: 0.1484, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 74, Training Loss: 0.1231, Validation Loss: 0.1489, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 75, Training Loss: 0.1399, Validation Loss: 0.1323, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 76, Training Loss: 0.1558, Validation Loss: 0.1038, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 77, Training Loss: 0.1333, Validation Loss: 0.1245, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 78, Training Loss: 0.1533, Validation Loss: 0.1046, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 79, Training Loss: 0.1412, Validation Loss: 0.1136, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 80, Training Loss: 0.2019, Validation Loss: 0.1374, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 81, Training Loss: 0.1070, Validation Loss: 0.1522, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 82, Training Loss: 0.1775, Validation Loss: 0.1414, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 83, Training Loss: 0.1736, Validation Loss: 0.1122, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 84, Training Loss: 0.1141, Validation Loss: 0.0945, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 85, Training Loss: 0.1199, Validation Loss: 0.1149, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 86, Training Loss: 0.1281, Validation Loss: 0.1468, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 87, Training Loss: 0.1196, Validation Loss: 0.1455, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 88, Training Loss: 0.1365, Validation Loss: 0.1315, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 89, Training Loss: 0.1338, Validation Loss: 0.1232, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 90, Training Loss: 0.1078, Validation Loss: 0.1072, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 91, Training Loss: 0.1338, Validation Loss: 0.1776, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 92, Training Loss: 0.1066, Validation Loss: 0.1244, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 93, Training Loss: 0.1294, Validation Loss: 0.1256, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 94, Training Loss: 0.0929, Validation Loss: 0.1422, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 95, Training Loss: 0.1195, Validation Loss: 0.1182, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 96, Training Loss: 0.0979, Validation Loss: 0.1162, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 97, Training Loss: 0.0701, Validation Loss: 0.1126, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 98, Training Loss: 0.0506, Validation Loss: 0.1090, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 99, Training Loss: 0.0703, Validation Loss: 0.1169, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 100, Training Loss: 0.0793, Validation Loss: 0.1156, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Running yolov9 classification training with alpha = 1 using script scripts/yolov9/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.1771, Validation Loss: 2.3520, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 2.1879, Validation Loss: 1.5708, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.7851, Validation Loss: 1.2115, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 1.4002, Validation Loss: 1.0369, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 1.2026, Validation Loss: 0.7790, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 1.1702, Validation Loss: 0.6737, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 0.9352, Validation Loss: 0.5480, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.9027, Validation Loss: 0.5187, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.7777, Validation Loss: 0.4690, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.7486, Validation Loss: 0.4375, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.6863, Validation Loss: 0.4300, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.5964, Validation Loss: 0.3189, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.5436, Validation Loss: 0.2636, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.5603, Validation Loss: 0.2345, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.5847, Validation Loss: 0.3012, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.5165, Validation Loss: 0.2613, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.4466, Validation Loss: 0.1984, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.4450, Validation Loss: 0.3131, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.4459, Validation Loss: 0.2310, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.3601, Validation Loss: 0.2213, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.3372, Validation Loss: 0.1652, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.3612, Validation Loss: 0.1610, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.3622, Validation Loss: 0.1328, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.3899, Validation Loss: 0.1396, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.3358, Validation Loss: 0.1930, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.3171, Validation Loss: 0.1399, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.3235, Validation Loss: 0.1408, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.2829, Validation Loss: 0.1503, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.2478, Validation Loss: 0.1895, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.2828, Validation Loss: 0.1411, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.2965, Validation Loss: 0.1303, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.2702, Validation Loss: 0.1503, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.2551, Validation Loss: 0.1290, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.2616, Validation Loss: 0.1149, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.2829, Validation Loss: 0.1738, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.2447, Validation Loss: 0.1653, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.2462, Validation Loss: 0.1836, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.2469, Validation Loss: 0.1306, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.2491, Validation Loss: 0.1110, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.2733, Validation Loss: 0.1355, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.1843, Validation Loss: 0.1392, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.2148, Validation Loss: 0.1054, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.2045, Validation Loss: 0.1456, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.1998, Validation Loss: 0.1135, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.1946, Validation Loss: 0.1227, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.2287, Validation Loss: 0.1134, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.2191, Validation Loss: 0.1195, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.1931, Validation Loss: 0.1366, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.1625, Validation Loss: 0.1380, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.1524, Validation Loss: 0.2205, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.2223, Validation Loss: 0.2786, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.1596, Validation Loss: 0.1395, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.2012, Validation Loss: 0.1077, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.1615, Validation Loss: 0.0915, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.1225, Validation Loss: 0.0886, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.1522, Validation Loss: 0.0852, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.1152, Validation Loss: 0.0859, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.1308, Validation Loss: 0.0940, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.1302, Validation Loss: 0.0826, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.0996, Validation Loss: 0.0826, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.0804, Validation Loss: 0.0884, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.1095, Validation Loss: 0.0881, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.0925, Validation Loss: 0.0929, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.1061, Validation Loss: 0.0917, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.1596, Validation Loss: 0.0934, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.1261, Validation Loss: 0.0923, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.0998, Validation Loss: 0.0949, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.0733, Validation Loss: 0.0874, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.0768, Validation Loss: 0.0833, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.0959, Validation Loss: 0.0867, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.0988, Validation Loss: 0.0839, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.0904, Validation Loss: 0.0841, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 73, Training Loss: 0.0925, Validation Loss: 0.0822, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 74, Training Loss: 0.1085, Validation Loss: 0.0839, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 75, Training Loss: 0.0891, Validation Loss: 0.0826, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 76, Training Loss: 0.0678, Validation Loss: 0.0824, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 77, Training Loss: 0.0713, Validation Loss: 0.0879, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 78, Training Loss: 0.0716, Validation Loss: 0.0845, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 79, Training Loss: 0.1007, Validation Loss: 0.0848, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 80, Training Loss: 0.0683, Validation Loss: 0.0860, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 81, Training Loss: 0.0747, Validation Loss: 0.0824, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 82, Training Loss: 0.0799, Validation Loss: 0.0873, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 83, Training Loss: 0.0813, Validation Loss: 0.0811, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 84, Training Loss: 0.0822, Validation Loss: 0.0834, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 85, Training Loss: 0.0771, Validation Loss: 0.0857, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 86, Training Loss: 0.0724, Validation Loss: 0.0832, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 87, Training Loss: 0.0662, Validation Loss: 0.0831, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 88, Training Loss: 0.0844, Validation Loss: 0.0817, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 89, Training Loss: 0.0753, Validation Loss: 0.0844, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 90, Training Loss: 0.0738, Validation Loss: 0.0824, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 91, Training Loss: 0.0728, Validation Loss: 0.0856, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 92, Training Loss: 0.0774, Validation Loss: 0.0899, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 93, Training Loss: 0.0690, Validation Loss: 0.0825, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 94, Training Loss: 0.0648, Validation Loss: 0.0862, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 95, Training Loss: 0.0747, Validation Loss: 0.0869, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 96, Training Loss: 0.0839, Validation Loss: 0.0907, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 97, Training Loss: 0.0736, Validation Loss: 0.0866, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 98, Training Loss: 0.0683, Validation Loss: 0.0877, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 99, Training Loss: 0.0660, Validation Loss: 0.0891, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 100, Training Loss: 0.0790, Validation Loss: 0.0829, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Running decreased_branch_complexity experiments:
Running decreased_branch_complexity classification training with alpha = 0 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.8367, Validation Loss: 4.5597, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 2, Training Loss: 2.7617, Validation Loss: 1.9132, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 3, Training Loss: 2.0288, Validation Loss: 1.4186, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 4, Training Loss: 1.6767, Validation Loss: 1.0778, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 5, Training Loss: 1.3421, Validation Loss: 0.9417, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 6, Training Loss: 1.2014, Validation Loss: 0.8676, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 7, Training Loss: 1.1038, Validation Loss: 0.9332, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 8, Training Loss: 0.9743, Validation Loss: 0.6543, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 9, Training Loss: 1.0041, Validation Loss: 0.6963, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 10, Training Loss: 0.8641, Validation Loss: 0.7046, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 11, Training Loss: 0.7974, Validation Loss: 0.4995, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 12, Training Loss: 0.7565, Validation Loss: 0.4685, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 13, Training Loss: 0.7700, Validation Loss: 0.5515, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 14, Training Loss: 0.6741, Validation Loss: 0.4219, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 15, Training Loss: 0.6116, Validation Loss: 0.4877, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 16, Training Loss: 0.6080, Validation Loss: 0.4348, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 17, Training Loss: 0.5610, Validation Loss: 0.8974, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 18, Training Loss: 0.5317, Validation Loss: 0.3811, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 19, Training Loss: 0.4696, Validation Loss: 0.3311, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 20, Training Loss: 0.4845, Validation Loss: 0.3273, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 21, Training Loss: 0.5147, Validation Loss: 0.3243, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 22, Training Loss: 0.4623, Validation Loss: 0.3041, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 23, Training Loss: 0.4626, Validation Loss: 0.3831, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 24, Training Loss: 0.4173, Validation Loss: 0.2772, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 25, Training Loss: 0.4121, Validation Loss: 0.2685, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 26, Training Loss: 0.3898, Validation Loss: 0.2894, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 27, Training Loss: 0.4132, Validation Loss: 0.2448, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 28, Training Loss: 0.3261, Validation Loss: 0.2400, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 29, Training Loss: 0.3606, Validation Loss: 0.2353, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 30, Training Loss: 0.2985, Validation Loss: 0.2437, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 31, Training Loss: 0.2865, Validation Loss: 0.2363, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 32, Training Loss: 0.2943, Validation Loss: 0.2569, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 33, Training Loss: 0.3115, Validation Loss: 0.2942, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 34, Training Loss: 0.2638, Validation Loss: 0.2399, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 35, Training Loss: 0.3401, Validation Loss: 0.2323, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 36, Training Loss: 0.2853, Validation Loss: 0.2368, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 37, Training Loss: 0.3381, Validation Loss: 0.2869, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 38, Training Loss: 0.2696, Validation Loss: 0.2358, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 39, Training Loss: 0.2505, Validation Loss: 0.3329, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 40, Training Loss: 0.2018, Validation Loss: 0.2334, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 41, Training Loss: 0.2788, Validation Loss: 0.2905, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 42, Training Loss: 0.2632, Validation Loss: 0.2406, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 43, Training Loss: 0.2602, Validation Loss: 0.2440, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 44, Training Loss: 0.2541, Validation Loss: 0.2660, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 45, Training Loss: 0.2695, Validation Loss: 0.2775, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 46, Training Loss: 0.2392, Validation Loss: 0.2116, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 47, Training Loss: 0.2199, Validation Loss: 0.2352, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 48, Training Loss: 0.1682, Validation Loss: 0.1943, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 49, Training Loss: 0.1700, Validation Loss: 0.2324, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 50, Training Loss: 0.1876, Validation Loss: 0.2287, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 51, Training Loss: 0.2069, Validation Loss: 0.2722, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 52, Training Loss: 0.2029, Validation Loss: 0.2489, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 53, Training Loss: 0.1471, Validation Loss: 0.2028, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 54, Training Loss: 0.1720, Validation Loss: 0.2883, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 55, Training Loss: 0.2142, Validation Loss: 0.2510, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 56, Training Loss: 0.2144, Validation Loss: 0.3013, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 57, Training Loss: 0.2051, Validation Loss: 0.2423, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 58, Training Loss: 0.1834, Validation Loss: 0.2482, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 59, Training Loss: 0.1758, Validation Loss: 0.2233, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 60, Training Loss: 0.1707, Validation Loss: 0.2104, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 61, Training Loss: 0.1075, Validation Loss: 0.1851, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 62, Training Loss: 0.1142, Validation Loss: 0.1732, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 63, Training Loss: 0.0835, Validation Loss: 0.1806, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 64, Training Loss: 0.0697, Validation Loss: 0.1740, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 65, Training Loss: 0.0927, Validation Loss: 0.1709, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 66, Training Loss: 0.0910, Validation Loss: 0.1676, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 67, Training Loss: 0.0932, Validation Loss: 0.1720, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 68, Training Loss: 0.0704, Validation Loss: 0.1689, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 69, Training Loss: 0.0679, Validation Loss: 0.1587, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 70, Training Loss: 0.0758, Validation Loss: 0.1612, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 71, Training Loss: 0.0659, Validation Loss: 0.1648, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 72, Training Loss: 0.0706, Validation Loss: 0.1654, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 73, Training Loss: 0.0627, Validation Loss: 0.1757, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 74, Training Loss: 0.0772, Validation Loss: 0.1754, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 75, Training Loss: 0.0561, Validation Loss: 0.1673, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 76, Training Loss: 0.0672, Validation Loss: 0.1674, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 77, Training Loss: 0.0661, Validation Loss: 0.1742, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 78, Training Loss: 0.0494, Validation Loss: 0.1707, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 79, Training Loss: 0.0606, Validation Loss: 0.1719, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 80, Training Loss: 0.0453, Validation Loss: 0.1613, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 81, Training Loss: 0.0426, Validation Loss: 0.1568, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 82, Training Loss: 0.0425, Validation Loss: 0.1604, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 83, Training Loss: 0.0589, Validation Loss: 0.1627, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 84, Training Loss: 0.0474, Validation Loss: 0.1596, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 85, Training Loss: 0.0713, Validation Loss: 0.1602, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 86, Training Loss: 0.0482, Validation Loss: 0.1621, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 87, Training Loss: 0.0559, Validation Loss: 0.1673, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 88, Training Loss: 0.0669, Validation Loss: 0.1604, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 89, Training Loss: 0.0664, Validation Loss: 0.1616, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 90, Training Loss: 0.0345, Validation Loss: 0.1614, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 91, Training Loss: 0.0519, Validation Loss: 0.1602, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 92, Training Loss: 0.0368, Validation Loss: 0.1621, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 93, Training Loss: 0.0462, Validation Loss: 0.1617, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 94, Training Loss: 0.0514, Validation Loss: 0.1644, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 95, Training Loss: 0.0395, Validation Loss: 0.1623, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 96, Training Loss: 0.0462, Validation Loss: 0.1591, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 97, Training Loss: 0.0532, Validation Loss: 0.1723, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 98, Training Loss: 0.0463, Validation Loss: 0.1725, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 99, Training Loss: 0.0474, Validation Loss: 0.1681, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Epoch: 100, Training Loss: 0.0500, Validation Loss: 0.1599, Alpha: 0.0000, Lambda Weights: [1.0, 1.0, 1.0, 1.0]
Running decreased_branch_complexity classification training with alpha = 0.2 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.1088, Validation Loss: 3.4515, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 2, Training Loss: 2.2816, Validation Loss: 1.5174, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 3, Training Loss: 1.6691, Validation Loss: 1.2348, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 4, Training Loss: 1.3183, Validation Loss: 0.9466, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 5, Training Loss: 1.1517, Validation Loss: 0.7778, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 6, Training Loss: 1.0127, Validation Loss: 0.7052, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 7, Training Loss: 0.9261, Validation Loss: 0.6257, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 8, Training Loss: 0.8488, Validation Loss: 0.5280, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 9, Training Loss: 0.7210, Validation Loss: 0.4948, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 10, Training Loss: 0.7194, Validation Loss: 0.4829, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 11, Training Loss: 0.6484, Validation Loss: 0.4251, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 12, Training Loss: 0.6747, Validation Loss: 0.4248, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 13, Training Loss: 0.6040, Validation Loss: 0.4471, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 14, Training Loss: 0.5785, Validation Loss: 0.4628, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 15, Training Loss: 0.6344, Validation Loss: 0.3615, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 16, Training Loss: 0.5426, Validation Loss: 0.3760, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 17, Training Loss: 0.4987, Validation Loss: 0.3020, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 18, Training Loss: 0.5086, Validation Loss: 0.3197, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 19, Training Loss: 0.4541, Validation Loss: 0.2967, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 20, Training Loss: 0.4500, Validation Loss: 0.2858, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 21, Training Loss: 0.4164, Validation Loss: 0.3371, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 22, Training Loss: 0.4171, Validation Loss: 0.2686, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 23, Training Loss: 0.3402, Validation Loss: 0.2690, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 24, Training Loss: 0.3138, Validation Loss: 0.2356, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 25, Training Loss: 0.3207, Validation Loss: 0.2671, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 26, Training Loss: 0.3520, Validation Loss: 0.2418, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 27, Training Loss: 0.3026, Validation Loss: 0.2603, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 28, Training Loss: 0.2872, Validation Loss: 0.2245, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 29, Training Loss: 0.3208, Validation Loss: 0.3052, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 30, Training Loss: 0.2695, Validation Loss: 0.2241, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 31, Training Loss: 0.2852, Validation Loss: 0.3625, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 32, Training Loss: 0.2772, Validation Loss: 0.2466, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 33, Training Loss: 0.2739, Validation Loss: 0.2248, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 34, Training Loss: 0.2712, Validation Loss: 0.2090, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 35, Training Loss: 0.2257, Validation Loss: 0.2088, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 36, Training Loss: 0.2223, Validation Loss: 0.2073, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 37, Training Loss: 0.1859, Validation Loss: 0.1920, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 38, Training Loss: 0.2281, Validation Loss: 0.3072, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 39, Training Loss: 0.2093, Validation Loss: 0.2129, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 40, Training Loss: 0.2356, Validation Loss: 0.3194, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 41, Training Loss: 0.2271, Validation Loss: 0.2586, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 42, Training Loss: 0.2361, Validation Loss: 0.3536, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 43, Training Loss: 0.2262, Validation Loss: 0.2956, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 44, Training Loss: 0.2175, Validation Loss: 0.2282, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 45, Training Loss: 0.2022, Validation Loss: 0.3222, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 46, Training Loss: 0.2392, Validation Loss: 0.2626, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 47, Training Loss: 0.1652, Validation Loss: 0.2173, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 48, Training Loss: 0.1842, Validation Loss: 0.2517, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 49, Training Loss: 0.1684, Validation Loss: 0.1761, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 50, Training Loss: 0.1128, Validation Loss: 0.1575, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 51, Training Loss: 0.1131, Validation Loss: 0.1640, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 52, Training Loss: 0.1271, Validation Loss: 0.1542, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 53, Training Loss: 0.0822, Validation Loss: 0.1535, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 54, Training Loss: 0.0839, Validation Loss: 0.1492, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 55, Training Loss: 0.1150, Validation Loss: 0.1474, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 56, Training Loss: 0.0778, Validation Loss: 0.1606, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 57, Training Loss: 0.0886, Validation Loss: 0.1518, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 58, Training Loss: 0.1037, Validation Loss: 0.1496, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 59, Training Loss: 0.0776, Validation Loss: 0.1447, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 60, Training Loss: 0.0931, Validation Loss: 0.1552, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 61, Training Loss: 0.0649, Validation Loss: 0.1486, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 62, Training Loss: 0.0738, Validation Loss: 0.1553, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 63, Training Loss: 0.0645, Validation Loss: 0.1483, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 64, Training Loss: 0.0578, Validation Loss: 0.1511, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 65, Training Loss: 0.0751, Validation Loss: 0.1485, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 66, Training Loss: 0.0664, Validation Loss: 0.1713, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 67, Training Loss: 0.0870, Validation Loss: 0.1590, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 68, Training Loss: 0.0708, Validation Loss: 0.1627, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 69, Training Loss: 0.0634, Validation Loss: 0.1505, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 70, Training Loss: 0.0645, Validation Loss: 0.1614, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 71, Training Loss: 0.0545, Validation Loss: 0.1568, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 72, Training Loss: 0.0555, Validation Loss: 0.1613, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 73, Training Loss: 0.0614, Validation Loss: 0.1589, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 74, Training Loss: 0.0724, Validation Loss: 0.1539, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 75, Training Loss: 0.0564, Validation Loss: 0.1564, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 76, Training Loss: 0.0483, Validation Loss: 0.1508, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 77, Training Loss: 0.0676, Validation Loss: 0.1578, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 78, Training Loss: 0.0611, Validation Loss: 0.1489, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Epoch: 79, Training Loss: 0.0536, Validation Loss: 0.1525, Alpha: 0.2000, Lambda Weights: [0.5488116145133972, 0.6703200340270996, 0.8187307715415955, 1.0]
Early stopping triggered.
Running decreased_branch_complexity classification training with alpha = 0.5 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 3.1896, Validation Loss: 2.7513, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 2, Training Loss: 1.6964, Validation Loss: 1.1807, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 3, Training Loss: 1.2536, Validation Loss: 0.8964, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 4, Training Loss: 1.0385, Validation Loss: 0.6769, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 5, Training Loss: 0.8140, Validation Loss: 0.5417, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 6, Training Loss: 0.7474, Validation Loss: 0.6012, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 7, Training Loss: 0.7385, Validation Loss: 0.4965, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 8, Training Loss: 0.6486, Validation Loss: 0.4112, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 9, Training Loss: 0.6130, Validation Loss: 0.4477, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 10, Training Loss: 0.5226, Validation Loss: 0.3647, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 11, Training Loss: 0.5404, Validation Loss: 0.3950, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 12, Training Loss: 0.4787, Validation Loss: 0.3551, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 13, Training Loss: 0.4859, Validation Loss: 0.2831, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 14, Training Loss: 0.4206, Validation Loss: 0.2896, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 15, Training Loss: 0.4578, Validation Loss: 0.3051, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 16, Training Loss: 0.3654, Validation Loss: 0.2457, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 17, Training Loss: 0.3908, Validation Loss: 0.3153, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 18, Training Loss: 0.3512, Validation Loss: 0.2249, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 19, Training Loss: 0.3578, Validation Loss: 0.2901, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 20, Training Loss: 0.3881, Validation Loss: 0.2639, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 21, Training Loss: 0.2927, Validation Loss: 0.2008, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 22, Training Loss: 0.2785, Validation Loss: 0.2292, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 23, Training Loss: 0.2601, Validation Loss: 0.2101, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 24, Training Loss: 0.2714, Validation Loss: 0.1930, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 25, Training Loss: 0.2785, Validation Loss: 0.2725, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 26, Training Loss: 0.2608, Validation Loss: 0.2202, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 27, Training Loss: 0.2302, Validation Loss: 0.2259, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 28, Training Loss: 0.2498, Validation Loss: 0.2340, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 29, Training Loss: 0.2383, Validation Loss: 0.1930, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 30, Training Loss: 0.2159, Validation Loss: 0.2523, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 31, Training Loss: 0.1987, Validation Loss: 0.2071, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 32, Training Loss: 0.2600, Validation Loss: 0.1550, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 33, Training Loss: 0.2111, Validation Loss: 0.2117, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 34, Training Loss: 0.2364, Validation Loss: 0.1754, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 35, Training Loss: 0.1807, Validation Loss: 0.1957, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 36, Training Loss: 0.2226, Validation Loss: 0.2277, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 37, Training Loss: 0.2036, Validation Loss: 0.2489, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 38, Training Loss: 0.1960, Validation Loss: 0.1661, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 39, Training Loss: 0.1922, Validation Loss: 0.1720, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 40, Training Loss: 0.1957, Validation Loss: 0.1691, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 41, Training Loss: 0.1894, Validation Loss: 0.2166, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 42, Training Loss: 0.1698, Validation Loss: 0.1652, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 43, Training Loss: 0.1359, Validation Loss: 0.1651, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 44, Training Loss: 0.1159, Validation Loss: 0.1194, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 45, Training Loss: 0.1000, Validation Loss: 0.1116, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 46, Training Loss: 0.0803, Validation Loss: 0.1066, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 47, Training Loss: 0.0807, Validation Loss: 0.1114, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 48, Training Loss: 0.0687, Validation Loss: 0.1091, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 49, Training Loss: 0.0591, Validation Loss: 0.1137, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 50, Training Loss: 0.0639, Validation Loss: 0.1090, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 51, Training Loss: 0.0725, Validation Loss: 0.1086, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 52, Training Loss: 0.0594, Validation Loss: 0.1101, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 53, Training Loss: 0.0604, Validation Loss: 0.1161, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 54, Training Loss: 0.0700, Validation Loss: 0.1101, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 55, Training Loss: 0.0510, Validation Loss: 0.1067, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 56, Training Loss: 0.0622, Validation Loss: 0.1095, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 57, Training Loss: 0.0657, Validation Loss: 0.1103, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 58, Training Loss: 0.0565, Validation Loss: 0.1126, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 59, Training Loss: 0.0494, Validation Loss: 0.1118, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 60, Training Loss: 0.0497, Validation Loss: 0.1135, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 61, Training Loss: 0.0547, Validation Loss: 0.1123, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 62, Training Loss: 0.0598, Validation Loss: 0.1121, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 63, Training Loss: 0.0578, Validation Loss: 0.1091, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 64, Training Loss: 0.0624, Validation Loss: 0.1118, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 65, Training Loss: 0.0487, Validation Loss: 0.1106, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Epoch: 66, Training Loss: 0.0562, Validation Loss: 0.1118, Alpha: 0.5000, Lambda Weights: [0.22313016653060913, 0.3678794801235199, 0.6065306663513184, 1.0]
Early stopping triggered.
Running decreased_branch_complexity classification training with alpha = 0.8 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 2.6751, Validation Loss: 2.5486, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 2, Training Loss: 1.5410, Validation Loss: 1.0354, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 3, Training Loss: 1.1388, Validation Loss: 0.8153, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 4, Training Loss: 0.8311, Validation Loss: 0.6934, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 5, Training Loss: 0.7162, Validation Loss: 0.5240, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 6, Training Loss: 0.5672, Validation Loss: 0.4664, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 7, Training Loss: 0.5404, Validation Loss: 0.4022, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 8, Training Loss: 0.4489, Validation Loss: 0.3740, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 9, Training Loss: 0.4392, Validation Loss: 0.3170, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 10, Training Loss: 0.3780, Validation Loss: 0.2806, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 11, Training Loss: 0.3995, Validation Loss: 0.3232, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 12, Training Loss: 0.4294, Validation Loss: 0.2621, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 13, Training Loss: 0.3424, Validation Loss: 0.2172, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 14, Training Loss: 0.3420, Validation Loss: 0.3610, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 15, Training Loss: 0.3215, Validation Loss: 0.3736, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 16, Training Loss: 0.2611, Validation Loss: 0.2200, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 17, Training Loss: 0.2820, Validation Loss: 0.2649, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 18, Training Loss: 0.2685, Validation Loss: 0.2572, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 19, Training Loss: 0.2759, Validation Loss: 0.2115, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 20, Training Loss: 0.2491, Validation Loss: 0.1840, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 21, Training Loss: 0.2257, Validation Loss: 0.1939, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 22, Training Loss: 0.2276, Validation Loss: 0.1959, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 23, Training Loss: 0.2143, Validation Loss: 0.1826, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 24, Training Loss: 0.2561, Validation Loss: 0.1914, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 25, Training Loss: 0.2028, Validation Loss: 0.1642, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 26, Training Loss: 0.1621, Validation Loss: 0.1701, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 27, Training Loss: 0.2062, Validation Loss: 0.1481, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 28, Training Loss: 0.1895, Validation Loss: 0.1705, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 29, Training Loss: 0.1697, Validation Loss: 0.1642, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 30, Training Loss: 0.1798, Validation Loss: 0.2558, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 31, Training Loss: 0.1741, Validation Loss: 0.1856, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 32, Training Loss: 0.1844, Validation Loss: 0.1749, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 33, Training Loss: 0.2176, Validation Loss: 0.1576, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 34, Training Loss: 0.1677, Validation Loss: 0.1108, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 35, Training Loss: 0.1438, Validation Loss: 0.1835, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 36, Training Loss: 0.1549, Validation Loss: 0.1824, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 37, Training Loss: 0.1526, Validation Loss: 0.1569, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 38, Training Loss: 0.1429, Validation Loss: 0.1641, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 39, Training Loss: 0.1415, Validation Loss: 0.1707, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 40, Training Loss: 0.1413, Validation Loss: 0.1736, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 41, Training Loss: 0.1377, Validation Loss: 0.1465, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 42, Training Loss: 0.1135, Validation Loss: 0.1317, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 43, Training Loss: 0.1128, Validation Loss: 0.1368, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 44, Training Loss: 0.1417, Validation Loss: 0.1407, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 45, Training Loss: 0.1102, Validation Loss: 0.1210, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 46, Training Loss: 0.0902, Validation Loss: 0.1011, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 47, Training Loss: 0.0671, Validation Loss: 0.0916, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 48, Training Loss: 0.0792, Validation Loss: 0.0950, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 49, Training Loss: 0.0677, Validation Loss: 0.0915, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 50, Training Loss: 0.0585, Validation Loss: 0.0919, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 51, Training Loss: 0.0653, Validation Loss: 0.0993, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 52, Training Loss: 0.0543, Validation Loss: 0.0969, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 53, Training Loss: 0.0364, Validation Loss: 0.0859, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 54, Training Loss: 0.0460, Validation Loss: 0.0917, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 55, Training Loss: 0.0435, Validation Loss: 0.0877, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 56, Training Loss: 0.0444, Validation Loss: 0.0981, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 57, Training Loss: 0.0600, Validation Loss: 0.0940, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 58, Training Loss: 0.0424, Validation Loss: 0.0906, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 59, Training Loss: 0.0492, Validation Loss: 0.0956, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 60, Training Loss: 0.0500, Validation Loss: 0.0977, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 61, Training Loss: 0.0480, Validation Loss: 0.0961, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 62, Training Loss: 0.0510, Validation Loss: 0.1011, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 63, Training Loss: 0.0427, Validation Loss: 0.1093, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 64, Training Loss: 0.0399, Validation Loss: 0.1053, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 65, Training Loss: 0.0414, Validation Loss: 0.1037, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 66, Training Loss: 0.0320, Validation Loss: 0.1029, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 67, Training Loss: 0.0453, Validation Loss: 0.1050, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 68, Training Loss: 0.0384, Validation Loss: 0.1022, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 69, Training Loss: 0.0300, Validation Loss: 0.1013, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 70, Training Loss: 0.0399, Validation Loss: 0.1013, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 71, Training Loss: 0.0298, Validation Loss: 0.0999, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 72, Training Loss: 0.0363, Validation Loss: 0.0972, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Epoch: 73, Training Loss: 0.0304, Validation Loss: 0.1001, Alpha: 0.8000, Lambda Weights: [0.09071794152259827, 0.20189650356769562, 0.4493289589881897, 1.0]
Early stopping triggered.
Running decreased_branch_complexity classification training with alpha = 1 using script scripts/decreased_branch_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 2.4192, Validation Loss: 2.2184, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 2, Training Loss: 1.3906, Validation Loss: 0.9505, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 3, Training Loss: 1.0236, Validation Loss: 0.8344, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 4, Training Loss: 0.7790, Validation Loss: 0.5364, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 5, Training Loss: 0.6371, Validation Loss: 0.4371, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 6, Training Loss: 0.5264, Validation Loss: 0.3695, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 7, Training Loss: 0.4281, Validation Loss: 0.3086, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 8, Training Loss: 0.4281, Validation Loss: 0.3120, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 9, Training Loss: 0.3769, Validation Loss: 0.2887, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 10, Training Loss: 0.3851, Validation Loss: 0.4782, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 11, Training Loss: 0.3659, Validation Loss: 0.2265, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 12, Training Loss: 0.3458, Validation Loss: 0.2728, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 13, Training Loss: 0.2965, Validation Loss: 0.2302, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 14, Training Loss: 0.2786, Validation Loss: 0.1943, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 15, Training Loss: 0.3165, Validation Loss: 0.2539, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 16, Training Loss: 0.2548, Validation Loss: 0.1777, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 17, Training Loss: 0.3171, Validation Loss: 0.1814, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 18, Training Loss: 0.2213, Validation Loss: 0.1897, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 19, Training Loss: 0.2394, Validation Loss: 0.2226, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 20, Training Loss: 0.2325, Validation Loss: 0.2101, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 21, Training Loss: 0.2494, Validation Loss: 0.1387, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 22, Training Loss: 0.2192, Validation Loss: 0.1779, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 23, Training Loss: 0.1857, Validation Loss: 0.1514, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 24, Training Loss: 0.1971, Validation Loss: 0.2056, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 25, Training Loss: 0.2136, Validation Loss: 0.1959, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 26, Training Loss: 0.1777, Validation Loss: 0.1383, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 27, Training Loss: 0.2176, Validation Loss: 0.1443, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 28, Training Loss: 0.1948, Validation Loss: 0.1305, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 29, Training Loss: 0.1953, Validation Loss: 0.1822, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 30, Training Loss: 0.1400, Validation Loss: 0.2814, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 31, Training Loss: 0.1772, Validation Loss: 0.1384, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 32, Training Loss: 0.1214, Validation Loss: 0.1503, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 33, Training Loss: 0.1513, Validation Loss: 0.2150, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 34, Training Loss: 0.1237, Validation Loss: 0.1060, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 35, Training Loss: 0.1310, Validation Loss: 0.1187, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 36, Training Loss: 0.1192, Validation Loss: 0.1379, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 37, Training Loss: 0.1436, Validation Loss: 0.1330, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 38, Training Loss: 0.1103, Validation Loss: 0.1318, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 39, Training Loss: 0.1087, Validation Loss: 0.1498, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 40, Training Loss: 0.1128, Validation Loss: 0.1476, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 41, Training Loss: 0.0994, Validation Loss: 0.1714, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 42, Training Loss: 0.1143, Validation Loss: 0.2619, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 43, Training Loss: 0.0921, Validation Loss: 0.1172, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 44, Training Loss: 0.0942, Validation Loss: 0.1619, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 45, Training Loss: 0.0783, Validation Loss: 0.1141, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 46, Training Loss: 0.0872, Validation Loss: 0.0997, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 47, Training Loss: 0.0572, Validation Loss: 0.0955, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 48, Training Loss: 0.0670, Validation Loss: 0.0895, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 49, Training Loss: 0.0499, Validation Loss: 0.0842, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 50, Training Loss: 0.0406, Validation Loss: 0.0830, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 51, Training Loss: 0.0448, Validation Loss: 0.0822, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 52, Training Loss: 0.0443, Validation Loss: 0.0802, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 53, Training Loss: 0.0368, Validation Loss: 0.0835, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 54, Training Loss: 0.0344, Validation Loss: 0.0928, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 55, Training Loss: 0.0364, Validation Loss: 0.0927, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 56, Training Loss: 0.0344, Validation Loss: 0.0914, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 57, Training Loss: 0.0345, Validation Loss: 0.0871, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 58, Training Loss: 0.0367, Validation Loss: 0.0854, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 59, Training Loss: 0.0335, Validation Loss: 0.0946, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 60, Training Loss: 0.0474, Validation Loss: 0.0932, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 61, Training Loss: 0.0343, Validation Loss: 0.0907, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 62, Training Loss: 0.0286, Validation Loss: 0.0912, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 63, Training Loss: 0.0370, Validation Loss: 0.0949, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 64, Training Loss: 0.0227, Validation Loss: 0.0946, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 65, Training Loss: 0.0283, Validation Loss: 0.0926, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 66, Training Loss: 0.0197, Validation Loss: 0.0896, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 67, Training Loss: 0.0233, Validation Loss: 0.0903, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 68, Training Loss: 0.0259, Validation Loss: 0.0930, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 69, Training Loss: 0.0412, Validation Loss: 0.0877, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 70, Training Loss: 0.0253, Validation Loss: 0.0889, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 71, Training Loss: 0.0197, Validation Loss: 0.0890, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Epoch: 72, Training Loss: 0.0240, Validation Loss: 0.0898, Alpha: 1.0000, Lambda Weights: [0.049787066876888275, 0.1353352814912796, 0.3678794801235199, 1.0]
Early stopping triggered.
Running increased_features_complexity experiments:
Running increased_features_complexity classification training with alpha = 0 using script scripts/increased_features_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.9395, Validation Loss: 4.7467, Alpha: 0.0000
Epoch: 2, Training Loss: 4.1766, Validation Loss: 3.7442, Alpha: 0.0000
Epoch: 3, Training Loss: 3.5572, Validation Loss: 4.1494, Alpha: 0.0000
Epoch: 4, Training Loss: 3.0990, Validation Loss: 2.9090, Alpha: 0.0000
Epoch: 5, Training Loss: 2.6194, Validation Loss: 2.1645, Alpha: 0.0000
Epoch: 6, Training Loss: 2.3388, Validation Loss: 1.9021, Alpha: 0.0000
Epoch: 7, Training Loss: 2.0726, Validation Loss: 1.8320, Alpha: 0.0000
Epoch: 8, Training Loss: 1.8962, Validation Loss: 1.4361, Alpha: 0.0000
Epoch: 9, Training Loss: 1.7408, Validation Loss: 1.4355, Alpha: 0.0000
Epoch: 10, Training Loss: 1.6797, Validation Loss: 1.3495, Alpha: 0.0000
Epoch: 11, Training Loss: 1.4730, Validation Loss: 1.1693, Alpha: 0.0000
Epoch: 12, Training Loss: 1.3834, Validation Loss: 1.1764, Alpha: 0.0000
Epoch: 13, Training Loss: 1.2520, Validation Loss: 0.9787, Alpha: 0.0000
Epoch: 14, Training Loss: 1.2030, Validation Loss: 0.8584, Alpha: 0.0000
Epoch: 15, Training Loss: 1.0892, Validation Loss: 0.7682, Alpha: 0.0000
Epoch: 16, Training Loss: 1.0231, Validation Loss: 0.8279, Alpha: 0.0000
Epoch: 17, Training Loss: 0.9158, Validation Loss: 0.6274, Alpha: 0.0000
Epoch: 18, Training Loss: 0.9244, Validation Loss: 0.6289, Alpha: 0.0000
Epoch: 19, Training Loss: 0.9175, Validation Loss: 0.7383, Alpha: 0.0000
Epoch: 20, Training Loss: 0.8732, Validation Loss: 0.5244, Alpha: 0.0000
Epoch: 21, Training Loss: 0.7953, Validation Loss: 0.4475, Alpha: 0.0000
Epoch: 22, Training Loss: 0.7337, Validation Loss: 0.4919, Alpha: 0.0000
Epoch: 23, Training Loss: 0.6515, Validation Loss: 0.3716, Alpha: 0.0000
Epoch: 24, Training Loss: 0.6181, Validation Loss: 0.3855, Alpha: 0.0000
Epoch: 25, Training Loss: 0.6530, Validation Loss: 0.4566, Alpha: 0.0000
Epoch: 26, Training Loss: 0.7015, Validation Loss: 0.4684, Alpha: 0.0000
Epoch: 27, Training Loss: 0.6158, Validation Loss: 0.3224, Alpha: 0.0000
Epoch: 28, Training Loss: 0.5901, Validation Loss: 0.3682, Alpha: 0.0000
Epoch: 29, Training Loss: 0.5835, Validation Loss: 0.2456, Alpha: 0.0000
Epoch: 30, Training Loss: 0.6139, Validation Loss: 0.3828, Alpha: 0.0000
Epoch: 31, Training Loss: 0.5109, Validation Loss: 0.2580, Alpha: 0.0000
Epoch: 32, Training Loss: 0.4211, Validation Loss: 0.2635, Alpha: 0.0000
Epoch: 33, Training Loss: 0.4279, Validation Loss: 0.2313, Alpha: 0.0000
Epoch: 34, Training Loss: 0.4247, Validation Loss: 0.3517, Alpha: 0.0000
Epoch: 35, Training Loss: 0.4156, Validation Loss: 0.3585, Alpha: 0.0000
Epoch: 36, Training Loss: 0.4162, Validation Loss: 0.1967, Alpha: 0.0000
Epoch: 37, Training Loss: 0.3992, Validation Loss: 0.1864, Alpha: 0.0000
Epoch: 38, Training Loss: 0.4472, Validation Loss: 0.2213, Alpha: 0.0000
Epoch: 39, Training Loss: 0.3176, Validation Loss: 0.1982, Alpha: 0.0000
Epoch: 40, Training Loss: 0.3789, Validation Loss: 0.2369, Alpha: 0.0000
Epoch: 41, Training Loss: 0.3580, Validation Loss: 0.1885, Alpha: 0.0000
Epoch: 42, Training Loss: 0.3141, Validation Loss: 0.1661, Alpha: 0.0000
Epoch: 43, Training Loss: 0.2653, Validation Loss: 0.1494, Alpha: 0.0000
Epoch: 44, Training Loss: 0.3131, Validation Loss: 0.2365, Alpha: 0.0000
Epoch: 45, Training Loss: 0.2981, Validation Loss: 0.1907, Alpha: 0.0000
Epoch: 46, Training Loss: 0.2650, Validation Loss: 0.1709, Alpha: 0.0000
Epoch: 47, Training Loss: 0.3205, Validation Loss: 0.1683, Alpha: 0.0000
Epoch: 48, Training Loss: 0.3019, Validation Loss: 0.2230, Alpha: 0.0000
Epoch: 49, Training Loss: 0.2204, Validation Loss: 0.2002, Alpha: 0.0000
Epoch: 50, Training Loss: 0.2874, Validation Loss: 0.1418, Alpha: 0.0000
Epoch: 51, Training Loss: 0.2527, Validation Loss: 0.1556, Alpha: 0.0000
Epoch: 52, Training Loss: 0.2252, Validation Loss: 0.1470, Alpha: 0.0000
Epoch: 53, Training Loss: 0.2172, Validation Loss: 0.2234, Alpha: 0.0000
Epoch: 54, Training Loss: 0.2509, Validation Loss: 0.1233, Alpha: 0.0000
Epoch: 55, Training Loss: 0.2425, Validation Loss: 0.2611, Alpha: 0.0000
Epoch: 56, Training Loss: 0.2045, Validation Loss: 0.1166, Alpha: 0.0000
Epoch: 57, Training Loss: 0.2018, Validation Loss: 0.1218, Alpha: 0.0000
Epoch: 58, Training Loss: 0.2189, Validation Loss: 0.1393, Alpha: 0.0000
Epoch: 59, Training Loss: 0.1951, Validation Loss: 0.1653, Alpha: 0.0000
Epoch: 60, Training Loss: 0.2567, Validation Loss: 0.1941, Alpha: 0.0000
Epoch: 61, Training Loss: 0.2000, Validation Loss: 0.2041, Alpha: 0.0000
Epoch: 62, Training Loss: 0.1850, Validation Loss: 0.1450, Alpha: 0.0000
Epoch: 63, Training Loss: 0.2295, Validation Loss: 0.1161, Alpha: 0.0000
Epoch: 64, Training Loss: 0.1496, Validation Loss: 0.1726, Alpha: 0.0000
Epoch: 65, Training Loss: 0.2182, Validation Loss: 0.2281, Alpha: 0.0000
Epoch: 66, Training Loss: 0.2177, Validation Loss: 0.1634, Alpha: 0.0000
Epoch: 67, Training Loss: 0.1866, Validation Loss: 0.1194, Alpha: 0.0000
Epoch: 68, Training Loss: 0.2140, Validation Loss: 0.1122, Alpha: 0.0000
Epoch: 69, Training Loss: 0.2496, Validation Loss: 0.1656, Alpha: 0.0000
Epoch: 70, Training Loss: 0.1937, Validation Loss: 0.1763, Alpha: 0.0000
Epoch: 71, Training Loss: 0.2109, Validation Loss: 0.1082, Alpha: 0.0000
Epoch: 72, Training Loss: 0.1965, Validation Loss: 0.1265, Alpha: 0.0000
Epoch: 73, Training Loss: 0.2195, Validation Loss: 0.1351, Alpha: 0.0000
Epoch: 74, Training Loss: 0.1894, Validation Loss: 0.1459, Alpha: 0.0000
Epoch: 75, Training Loss: 0.2017, Validation Loss: 0.1115, Alpha: 0.0000
Epoch: 76, Training Loss: 0.1315, Validation Loss: 0.1071, Alpha: 0.0000
Epoch: 77, Training Loss: 0.1514, Validation Loss: 0.1314, Alpha: 0.0000
Epoch: 78, Training Loss: 0.1427, Validation Loss: 0.1257, Alpha: 0.0000
Epoch: 79, Training Loss: 0.1222, Validation Loss: 0.1083, Alpha: 0.0000
Epoch: 80, Training Loss: 0.1496, Validation Loss: 0.1226, Alpha: 0.0000
Epoch: 81, Training Loss: 0.1280, Validation Loss: 0.1620, Alpha: 0.0000
Epoch: 82, Training Loss: 0.1304, Validation Loss: 0.1150, Alpha: 0.0000
Epoch: 83, Training Loss: 0.1571, Validation Loss: 0.1619, Alpha: 0.0000
Epoch: 84, Training Loss: 0.1159, Validation Loss: 0.1245, Alpha: 0.0000
Epoch: 85, Training Loss: 0.1616, Validation Loss: 0.1735, Alpha: 0.0000
Epoch: 86, Training Loss: 0.1305, Validation Loss: 0.1267, Alpha: 0.0000
Epoch: 87, Training Loss: 0.1485, Validation Loss: 0.1724, Alpha: 0.0000
Epoch: 88, Training Loss: 0.1237, Validation Loss: 0.1081, Alpha: 0.0000
Epoch: 89, Training Loss: 0.1133, Validation Loss: 0.0967, Alpha: 0.0000
Epoch: 90, Training Loss: 0.0988, Validation Loss: 0.0971, Alpha: 0.0000
Epoch: 91, Training Loss: 0.0531, Validation Loss: 0.0965, Alpha: 0.0000
Epoch: 92, Training Loss: 0.0931, Validation Loss: 0.0867, Alpha: 0.0000
Epoch: 93, Training Loss: 0.0505, Validation Loss: 0.0804, Alpha: 0.0000
Epoch: 94, Training Loss: 0.0696, Validation Loss: 0.0816, Alpha: 0.0000
Epoch: 95, Training Loss: 0.0649, Validation Loss: 0.0851, Alpha: 0.0000
Epoch: 96, Training Loss: 0.0520, Validation Loss: 0.0918, Alpha: 0.0000
Epoch: 97, Training Loss: 0.0481, Validation Loss: 0.0855, Alpha: 0.0000
Epoch: 98, Training Loss: 0.0376, Validation Loss: 0.0852, Alpha: 0.0000
Epoch: 99, Training Loss: 0.0425, Validation Loss: 0.0888, Alpha: 0.0000
Epoch: 100, Training Loss: 0.0577, Validation Loss: 0.0848, Alpha: 0.0000
Running increased_features_complexity classification training with alpha = 0.2 using script scripts/increased_features_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.9151, Validation Loss: 4.7411, Alpha: 0.2000
Epoch: 2, Training Loss: 4.1062, Validation Loss: 4.4302, Alpha: 0.2000
Epoch: 3, Training Loss: 3.5732, Validation Loss: 3.1847, Alpha: 0.2000
Epoch: 4, Training Loss: 3.2051, Validation Loss: 2.9830, Alpha: 0.2000
Epoch: 5, Training Loss: 2.9406, Validation Loss: 2.6522, Alpha: 0.2000
Epoch: 6, Training Loss: 2.6590, Validation Loss: 2.2160, Alpha: 0.2000
Epoch: 7, Training Loss: 2.3822, Validation Loss: 1.9496, Alpha: 0.2000
Epoch: 8, Training Loss: 2.1393, Validation Loss: 1.7573, Alpha: 0.2000
Epoch: 9, Training Loss: 1.9148, Validation Loss: 1.4482, Alpha: 0.2000
Epoch: 10, Training Loss: 1.7446, Validation Loss: 1.2934, Alpha: 0.2000
Epoch: 11, Training Loss: 1.5291, Validation Loss: 1.1587, Alpha: 0.2000
Epoch: 12, Training Loss: 1.3957, Validation Loss: 1.0499, Alpha: 0.2000
Epoch: 13, Training Loss: 1.3142, Validation Loss: 0.9820, Alpha: 0.2000
Epoch: 14, Training Loss: 1.2802, Validation Loss: 0.8073, Alpha: 0.2000
Epoch: 15, Training Loss: 1.1724, Validation Loss: 0.7621, Alpha: 0.2000
Epoch: 16, Training Loss: 1.0737, Validation Loss: 0.8382, Alpha: 0.2000
Epoch: 17, Training Loss: 1.0744, Validation Loss: 0.5474, Alpha: 0.2000
Epoch: 18, Training Loss: 0.9397, Validation Loss: 0.5549, Alpha: 0.2000
Epoch: 19, Training Loss: 0.8800, Validation Loss: 0.5269, Alpha: 0.2000
Epoch: 20, Training Loss: 0.7755, Validation Loss: 0.5335, Alpha: 0.2000
Epoch: 21, Training Loss: 0.8283, Validation Loss: 0.5241, Alpha: 0.2000
Epoch: 22, Training Loss: 0.7931, Validation Loss: 0.3986, Alpha: 0.2000
Epoch: 23, Training Loss: 0.7839, Validation Loss: 0.4706, Alpha: 0.2000
Epoch: 24, Training Loss: 0.7926, Validation Loss: 0.3579, Alpha: 0.2000
Epoch: 25, Training Loss: 0.6315, Validation Loss: 0.3282, Alpha: 0.2000
Epoch: 26, Training Loss: 0.6441, Validation Loss: 0.2878, Alpha: 0.2000
Epoch: 27, Training Loss: 0.5191, Validation Loss: 0.2678, Alpha: 0.2000
Epoch: 28, Training Loss: 0.4925, Validation Loss: 0.4692, Alpha: 0.2000
Epoch: 29, Training Loss: 0.5137, Validation Loss: 0.3299, Alpha: 0.2000
Epoch: 30, Training Loss: 0.4353, Validation Loss: 0.2263, Alpha: 0.2000
Epoch: 31, Training Loss: 0.4590, Validation Loss: 0.1846, Alpha: 0.2000
Epoch: 32, Training Loss: 0.4512, Validation Loss: 0.2185, Alpha: 0.2000
Epoch: 33, Training Loss: 0.4314, Validation Loss: 0.1842, Alpha: 0.2000
Epoch: 34, Training Loss: 0.4299, Validation Loss: 0.2225, Alpha: 0.2000
Epoch: 35, Training Loss: 0.3865, Validation Loss: 0.2190, Alpha: 0.2000
Epoch: 36, Training Loss: 0.4080, Validation Loss: 0.1692, Alpha: 0.2000
Epoch: 37, Training Loss: 0.3109, Validation Loss: 0.1581, Alpha: 0.2000
Epoch: 38, Training Loss: 0.3721, Validation Loss: 0.1992, Alpha: 0.2000
Epoch: 39, Training Loss: 0.3726, Validation Loss: 0.1616, Alpha: 0.2000
Epoch: 40, Training Loss: 0.2776, Validation Loss: 0.1818, Alpha: 0.2000
Epoch: 41, Training Loss: 0.2802, Validation Loss: 0.1621, Alpha: 0.2000
Epoch: 42, Training Loss: 0.2933, Validation Loss: 0.1272, Alpha: 0.2000
Epoch: 43, Training Loss: 0.3022, Validation Loss: 0.2461, Alpha: 0.2000
Epoch: 44, Training Loss: 0.3074, Validation Loss: 0.2171, Alpha: 0.2000
Epoch: 45, Training Loss: 0.3388, Validation Loss: 0.1706, Alpha: 0.2000
Epoch: 46, Training Loss: 0.2623, Validation Loss: 0.2792, Alpha: 0.2000
Epoch: 47, Training Loss: 0.2637, Validation Loss: 0.1371, Alpha: 0.2000
Epoch: 48, Training Loss: 0.2564, Validation Loss: 0.1688, Alpha: 0.2000
Epoch: 49, Training Loss: 0.2650, Validation Loss: 0.1608, Alpha: 0.2000
Epoch: 50, Training Loss: 0.2793, Validation Loss: 0.1895, Alpha: 0.2000
Epoch: 51, Training Loss: 0.2951, Validation Loss: 0.1535, Alpha: 0.2000
Epoch: 52, Training Loss: 0.2200, Validation Loss: 0.1133, Alpha: 0.2000
Epoch: 53, Training Loss: 0.2398, Validation Loss: 0.1817, Alpha: 0.2000
Epoch: 54, Training Loss: 0.2263, Validation Loss: 0.1502, Alpha: 0.2000
Epoch: 55, Training Loss: 0.2087, Validation Loss: 0.2184, Alpha: 0.2000
Epoch: 56, Training Loss: 0.2034, Validation Loss: 0.2309, Alpha: 0.2000
Epoch: 57, Training Loss: 0.1991, Validation Loss: 0.1494, Alpha: 0.2000
Epoch: 58, Training Loss: 0.1648, Validation Loss: 0.1494, Alpha: 0.2000
Epoch: 59, Training Loss: 0.2083, Validation Loss: 0.1498, Alpha: 0.2000
Epoch: 60, Training Loss: 0.1782, Validation Loss: 0.1604, Alpha: 0.2000
Epoch: 61, Training Loss: 0.1895, Validation Loss: 0.1282, Alpha: 0.2000
Epoch: 62, Training Loss: 0.1362, Validation Loss: 0.1019, Alpha: 0.2000
Epoch: 63, Training Loss: 0.1645, Validation Loss: 0.1204, Alpha: 0.2000
Epoch: 64, Training Loss: 0.1717, Validation Loss: 0.1293, Alpha: 0.2000
Epoch: 65, Training Loss: 0.1610, Validation Loss: 0.1271, Alpha: 0.2000
Epoch: 66, Training Loss: 0.1655, Validation Loss: 0.1523, Alpha: 0.2000
Epoch: 67, Training Loss: 0.1886, Validation Loss: 0.1365, Alpha: 0.2000
Epoch: 68, Training Loss: 0.1484, Validation Loss: 0.1326, Alpha: 0.2000
Epoch: 69, Training Loss: 0.1406, Validation Loss: 0.1025, Alpha: 0.2000
Epoch: 70, Training Loss: 0.1356, Validation Loss: 0.1105, Alpha: 0.2000
Epoch: 71, Training Loss: 0.1553, Validation Loss: 0.1612, Alpha: 0.2000
Epoch: 72, Training Loss: 0.1280, Validation Loss: 0.1298, Alpha: 0.2000
Epoch: 73, Training Loss: 0.1047, Validation Loss: 0.1273, Alpha: 0.2000
Epoch: 74, Training Loss: 0.1201, Validation Loss: 0.1115, Alpha: 0.2000
Epoch: 75, Training Loss: 0.0710, Validation Loss: 0.1056, Alpha: 0.2000
Epoch: 76, Training Loss: 0.0598, Validation Loss: 0.1041, Alpha: 0.2000
Epoch: 77, Training Loss: 0.0631, Validation Loss: 0.1014, Alpha: 0.2000
Epoch: 78, Training Loss: 0.0677, Validation Loss: 0.1004, Alpha: 0.2000
Epoch: 79, Training Loss: 0.0812, Validation Loss: 0.0971, Alpha: 0.2000
Epoch: 80, Training Loss: 0.0639, Validation Loss: 0.1008, Alpha: 0.2000
Epoch: 81, Training Loss: 0.0617, Validation Loss: 0.1043, Alpha: 0.2000
Epoch: 82, Training Loss: 0.0456, Validation Loss: 0.0915, Alpha: 0.2000
Epoch: 83, Training Loss: 0.0811, Validation Loss: 0.0978, Alpha: 0.2000
Epoch: 84, Training Loss: 0.0686, Validation Loss: 0.0958, Alpha: 0.2000
Epoch: 85, Training Loss: 0.0572, Validation Loss: 0.0930, Alpha: 0.2000
Epoch: 86, Training Loss: 0.0523, Validation Loss: 0.0949, Alpha: 0.2000
Epoch: 87, Training Loss: 0.0387, Validation Loss: 0.0944, Alpha: 0.2000
Epoch: 88, Training Loss: 0.0376, Validation Loss: 0.0967, Alpha: 0.2000
Epoch: 89, Training Loss: 0.0564, Validation Loss: 0.0944, Alpha: 0.2000
Epoch: 90, Training Loss: 0.0520, Validation Loss: 0.0917, Alpha: 0.2000
Epoch: 91, Training Loss: 0.0502, Validation Loss: 0.0930, Alpha: 0.2000
Epoch: 92, Training Loss: 0.0687, Validation Loss: 0.0971, Alpha: 0.2000
Epoch: 93, Training Loss: 0.0651, Validation Loss: 0.1103, Alpha: 0.2000
Epoch: 94, Training Loss: 0.0462, Validation Loss: 0.1080, Alpha: 0.2000
Epoch: 95, Training Loss: 0.0364, Validation Loss: 0.1012, Alpha: 0.2000
Epoch: 96, Training Loss: 0.0401, Validation Loss: 0.0992, Alpha: 0.2000
Epoch: 97, Training Loss: 0.0618, Validation Loss: 0.1001, Alpha: 0.2000
Epoch: 98, Training Loss: 0.0429, Validation Loss: 0.0968, Alpha: 0.2000
Epoch: 99, Training Loss: 0.0477, Validation Loss: 0.1035, Alpha: 0.2000
Epoch: 100, Training Loss: 0.0437, Validation Loss: 0.1043, Alpha: 0.2000
Running increased_features_complexity classification training with alpha = 0.5 using script scripts/increased_features_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.8609, Validation Loss: 4.7180, Alpha: 0.5000
Epoch: 2, Training Loss: 4.0180, Validation Loss: 3.4170, Alpha: 0.5000
Epoch: 3, Training Loss: 3.1535, Validation Loss: 2.7679, Alpha: 0.5000
Epoch: 4, Training Loss: 2.7196, Validation Loss: 2.3860, Alpha: 0.5000
Epoch: 5, Training Loss: 2.3713, Validation Loss: 1.9584, Alpha: 0.5000
Epoch: 6, Training Loss: 2.1366, Validation Loss: 1.8590, Alpha: 0.5000
Epoch: 7, Training Loss: 1.9328, Validation Loss: 1.7881, Alpha: 0.5000
Epoch: 8, Training Loss: 1.7917, Validation Loss: 1.4171, Alpha: 0.5000
Epoch: 9, Training Loss: 1.6373, Validation Loss: 1.2850, Alpha: 0.5000
Epoch: 10, Training Loss: 1.5097, Validation Loss: 1.2712, Alpha: 0.5000
Epoch: 11, Training Loss: 1.4221, Validation Loss: 1.0197, Alpha: 0.5000
Epoch: 12, Training Loss: 1.3960, Validation Loss: 1.3331, Alpha: 0.5000
Epoch: 13, Training Loss: 1.3588, Validation Loss: 1.0119, Alpha: 0.5000
Epoch: 14, Training Loss: 1.1520, Validation Loss: 0.9808, Alpha: 0.5000
Epoch: 15, Training Loss: 1.0662, Validation Loss: 0.7062, Alpha: 0.5000
Epoch: 16, Training Loss: 1.0068, Validation Loss: 0.6168, Alpha: 0.5000
Epoch: 17, Training Loss: 0.9759, Validation Loss: 0.6876, Alpha: 0.5000
Epoch: 18, Training Loss: 0.9415, Validation Loss: 0.6929, Alpha: 0.5000
Epoch: 19, Training Loss: 0.8347, Validation Loss: 0.6769, Alpha: 0.5000
Epoch: 20, Training Loss: 0.8482, Validation Loss: 0.8231, Alpha: 0.5000
Epoch: 21, Training Loss: 0.8007, Validation Loss: 1.3146, Alpha: 0.5000
Epoch: 22, Training Loss: 0.7236, Validation Loss: 0.3980, Alpha: 0.5000
Epoch: 23, Training Loss: 0.6634, Validation Loss: 0.3474, Alpha: 0.5000
Epoch: 24, Training Loss: 0.6564, Validation Loss: 0.5690, Alpha: 0.5000
Epoch: 25, Training Loss: 0.7478, Validation Loss: 0.7740, Alpha: 0.5000
Epoch: 26, Training Loss: 0.6413, Validation Loss: 0.3698, Alpha: 0.5000
Epoch: 27, Training Loss: 0.5890, Validation Loss: 0.3877, Alpha: 0.5000
Epoch: 28, Training Loss: 0.5940, Validation Loss: 0.3885, Alpha: 0.5000
Epoch: 29, Training Loss: 0.5191, Validation Loss: 0.3616, Alpha: 0.5000
Epoch: 30, Training Loss: 0.4908, Validation Loss: 0.2245, Alpha: 0.5000
Epoch: 31, Training Loss: 0.4385, Validation Loss: 0.2187, Alpha: 0.5000
Epoch: 32, Training Loss: 0.4525, Validation Loss: 0.3931, Alpha: 0.5000
Epoch: 33, Training Loss: 0.4142, Validation Loss: 0.4131, Alpha: 0.5000
Epoch: 34, Training Loss: 0.4325, Validation Loss: 0.2495, Alpha: 0.5000
Epoch: 35, Training Loss: 0.4331, Validation Loss: 0.2976, Alpha: 0.5000
Epoch: 36, Training Loss: 0.4042, Validation Loss: 0.1973, Alpha: 0.5000
Epoch: 37, Training Loss: 0.3723, Validation Loss: 0.1666, Alpha: 0.5000
Epoch: 38, Training Loss: 0.4587, Validation Loss: 0.1930, Alpha: 0.5000
Epoch: 39, Training Loss: 0.3234, Validation Loss: 0.2127, Alpha: 0.5000
Epoch: 40, Training Loss: 0.4259, Validation Loss: 0.1628, Alpha: 0.5000
Epoch: 41, Training Loss: 0.2836, Validation Loss: 0.2307, Alpha: 0.5000
Epoch: 42, Training Loss: 0.3532, Validation Loss: 0.3680, Alpha: 0.5000
Epoch: 43, Training Loss: 0.3157, Validation Loss: 0.1349, Alpha: 0.5000
Epoch: 44, Training Loss: 0.3447, Validation Loss: 0.1836, Alpha: 0.5000
Epoch: 45, Training Loss: 0.3105, Validation Loss: 0.1259, Alpha: 0.5000
Epoch: 46, Training Loss: 0.2751, Validation Loss: 0.2223, Alpha: 0.5000
Epoch: 47, Training Loss: 0.2938, Validation Loss: 0.1907, Alpha: 0.5000
Epoch: 48, Training Loss: 0.2994, Validation Loss: 0.2311, Alpha: 0.5000
Epoch: 49, Training Loss: 0.3243, Validation Loss: 0.1505, Alpha: 0.5000
Epoch: 50, Training Loss: 0.3077, Validation Loss: 0.1728, Alpha: 0.5000
Epoch: 51, Training Loss: 0.3050, Validation Loss: 0.1552, Alpha: 0.5000
Epoch: 52, Training Loss: 0.2555, Validation Loss: 0.5998, Alpha: 0.5000
Epoch: 53, Training Loss: 0.2543, Validation Loss: 0.2256, Alpha: 0.5000
Epoch: 54, Training Loss: 0.2627, Validation Loss: 0.1590, Alpha: 0.5000
Epoch: 55, Training Loss: 0.2009, Validation Loss: 0.1109, Alpha: 0.5000
Epoch: 56, Training Loss: 0.2181, Validation Loss: 0.1078, Alpha: 0.5000
Epoch: 57, Training Loss: 0.1743, Validation Loss: 0.1191, Alpha: 0.5000
Epoch: 58, Training Loss: 0.2152, Validation Loss: 0.1908, Alpha: 0.5000
Epoch: 59, Training Loss: 0.2066, Validation Loss: 0.1244, Alpha: 0.5000
Epoch: 60, Training Loss: 0.1960, Validation Loss: 0.1905, Alpha: 0.5000
Epoch: 61, Training Loss: 0.1937, Validation Loss: 0.2297, Alpha: 0.5000
Epoch: 62, Training Loss: 0.1582, Validation Loss: 0.1223, Alpha: 0.5000
Epoch: 63, Training Loss: 0.1566, Validation Loss: 0.2005, Alpha: 0.5000
Epoch: 64, Training Loss: 0.1818, Validation Loss: 0.1380, Alpha: 0.5000
Epoch: 65, Training Loss: 0.1571, Validation Loss: 0.1250, Alpha: 0.5000
Epoch: 66, Training Loss: 0.1383, Validation Loss: 0.2243, Alpha: 0.5000
Epoch: 67, Training Loss: 0.1923, Validation Loss: 0.1129, Alpha: 0.5000
Epoch: 68, Training Loss: 0.1167, Validation Loss: 0.1019, Alpha: 0.5000
Epoch: 69, Training Loss: 0.1020, Validation Loss: 0.1013, Alpha: 0.5000
Epoch: 70, Training Loss: 0.0770, Validation Loss: 0.0848, Alpha: 0.5000
Epoch: 71, Training Loss: 0.0569, Validation Loss: 0.0881, Alpha: 0.5000
Epoch: 72, Training Loss: 0.0632, Validation Loss: 0.0878, Alpha: 0.5000
Epoch: 73, Training Loss: 0.0689, Validation Loss: 0.0870, Alpha: 0.5000
Epoch: 74, Training Loss: 0.0600, Validation Loss: 0.0795, Alpha: 0.5000
Epoch: 75, Training Loss: 0.0638, Validation Loss: 0.0804, Alpha: 0.5000
Epoch: 76, Training Loss: 0.0685, Validation Loss: 0.0822, Alpha: 0.5000
Epoch: 77, Training Loss: 0.0679, Validation Loss: 0.0820, Alpha: 0.5000
Epoch: 78, Training Loss: 0.0729, Validation Loss: 0.0822, Alpha: 0.5000
Epoch: 79, Training Loss: 0.0587, Validation Loss: 0.1007, Alpha: 0.5000
Epoch: 80, Training Loss: 0.0460, Validation Loss: 0.0955, Alpha: 0.5000
Epoch: 81, Training Loss: 0.0631, Validation Loss: 0.0998, Alpha: 0.5000
Epoch: 82, Training Loss: 0.0574, Validation Loss: 0.0880, Alpha: 0.5000
Epoch: 83, Training Loss: 0.0446, Validation Loss: 0.0872, Alpha: 0.5000
Epoch: 84, Training Loss: 0.0674, Validation Loss: 0.0932, Alpha: 0.5000
Epoch: 85, Training Loss: 0.0414, Validation Loss: 0.0883, Alpha: 0.5000
Epoch: 86, Training Loss: 0.0496, Validation Loss: 0.0886, Alpha: 0.5000
Epoch: 87, Training Loss: 0.0394, Validation Loss: 0.0883, Alpha: 0.5000
Epoch: 88, Training Loss: 0.0532, Validation Loss: 0.0868, Alpha: 0.5000
Epoch: 89, Training Loss: 0.0477, Validation Loss: 0.0884, Alpha: 0.5000
Epoch: 90, Training Loss: 0.0415, Validation Loss: 0.0875, Alpha: 0.5000
Epoch: 91, Training Loss: 0.0353, Validation Loss: 0.0874, Alpha: 0.5000
Epoch: 92, Training Loss: 0.0574, Validation Loss: 0.0844, Alpha: 0.5000
Epoch: 93, Training Loss: 0.0456, Validation Loss: 0.0831, Alpha: 0.5000
Epoch: 94, Training Loss: 0.0551, Validation Loss: 0.0851, Alpha: 0.5000
Early stopping triggered.
Running increased_features_complexity classification training with alpha = 0.8 using script scripts/increased_features_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.7886, Validation Loss: 4.5699, Alpha: 0.8000
Epoch: 2, Training Loss: 3.8027, Validation Loss: 3.5308, Alpha: 0.8000
Epoch: 3, Training Loss: 3.0290, Validation Loss: 2.5407, Alpha: 0.8000
Epoch: 4, Training Loss: 2.5501, Validation Loss: 2.1920, Alpha: 0.8000
Epoch: 5, Training Loss: 2.2711, Validation Loss: 1.9389, Alpha: 0.8000
Epoch: 6, Training Loss: 1.9757, Validation Loss: 1.7787, Alpha: 0.8000
Epoch: 7, Training Loss: 1.7471, Validation Loss: 1.1894, Alpha: 0.8000
Epoch: 8, Training Loss: 1.5727, Validation Loss: 1.0814, Alpha: 0.8000
Epoch: 9, Training Loss: 1.4403, Validation Loss: 1.0118, Alpha: 0.8000
Epoch: 10, Training Loss: 1.2607, Validation Loss: 1.0273, Alpha: 0.8000
Epoch: 11, Training Loss: 1.1706, Validation Loss: 0.8729, Alpha: 0.8000
Epoch: 12, Training Loss: 1.2088, Validation Loss: 0.6559, Alpha: 0.8000
Epoch: 13, Training Loss: 1.0152, Validation Loss: 0.6738, Alpha: 0.8000
Epoch: 14, Training Loss: 0.9608, Validation Loss: 0.6604, Alpha: 0.8000
Epoch: 15, Training Loss: 0.8963, Validation Loss: 0.5697, Alpha: 0.8000
Epoch: 16, Training Loss: 0.8486, Validation Loss: 0.5467, Alpha: 0.8000
Epoch: 17, Training Loss: 0.7616, Validation Loss: 0.4664, Alpha: 0.8000
Epoch: 18, Training Loss: 0.7510, Validation Loss: 0.3958, Alpha: 0.8000
Epoch: 19, Training Loss: 0.7358, Validation Loss: 0.3823, Alpha: 0.8000
Epoch: 20, Training Loss: 0.6631, Validation Loss: 0.7331, Alpha: 0.8000
Epoch: 21, Training Loss: 0.6412, Validation Loss: 0.3856, Alpha: 0.8000
Epoch: 22, Training Loss: 0.6211, Validation Loss: 0.4323, Alpha: 0.8000
Epoch: 23, Training Loss: 0.6667, Validation Loss: 0.3833, Alpha: 0.8000
Epoch: 24, Training Loss: 0.6072, Validation Loss: 0.2724, Alpha: 0.8000
Epoch: 25, Training Loss: 0.5356, Validation Loss: 0.4052, Alpha: 0.8000
Epoch: 26, Training Loss: 0.4939, Validation Loss: 0.2939, Alpha: 0.8000
Epoch: 27, Training Loss: 0.5107, Validation Loss: 0.3849, Alpha: 0.8000
Epoch: 28, Training Loss: 0.5054, Validation Loss: 0.4361, Alpha: 0.8000
Epoch: 29, Training Loss: 0.5075, Validation Loss: 0.4537, Alpha: 0.8000
Epoch: 30, Training Loss: 0.4560, Validation Loss: 0.8738, Alpha: 0.8000
Epoch: 31, Training Loss: 0.5444, Validation Loss: 0.3367, Alpha: 0.8000
Epoch: 32, Training Loss: 0.5043, Validation Loss: 0.2987, Alpha: 0.8000
Epoch: 33, Training Loss: 0.4337, Validation Loss: 0.2486, Alpha: 0.8000
Epoch: 34, Training Loss: 0.4243, Validation Loss: 0.3002, Alpha: 0.8000
Epoch: 35, Training Loss: 0.4450, Validation Loss: 0.4386, Alpha: 0.8000
Epoch: 36, Training Loss: 0.4342, Validation Loss: 0.2456, Alpha: 0.8000
Epoch: 37, Training Loss: 0.3966, Validation Loss: 0.2901, Alpha: 0.8000
Epoch: 38, Training Loss: 0.3998, Validation Loss: 0.2086, Alpha: 0.8000
Epoch: 39, Training Loss: 0.3483, Validation Loss: 0.2189, Alpha: 0.8000
Epoch: 40, Training Loss: 0.3251, Validation Loss: 0.2512, Alpha: 0.8000
Epoch: 41, Training Loss: 0.3707, Validation Loss: 0.3333, Alpha: 0.8000
Epoch: 42, Training Loss: 0.3751, Validation Loss: 0.1742, Alpha: 0.8000
Epoch: 43, Training Loss: 0.3000, Validation Loss: 0.1791, Alpha: 0.8000
Epoch: 44, Training Loss: 0.3557, Validation Loss: 0.1675, Alpha: 0.8000
Epoch: 45, Training Loss: 0.2777, Validation Loss: 0.1788, Alpha: 0.8000
Epoch: 46, Training Loss: 0.2674, Validation Loss: 0.1389, Alpha: 0.8000
Epoch: 47, Training Loss: 0.2601, Validation Loss: 0.2310, Alpha: 0.8000
Epoch: 48, Training Loss: 0.2146, Validation Loss: 0.1414, Alpha: 0.8000
Epoch: 49, Training Loss: 0.2476, Validation Loss: 0.1263, Alpha: 0.8000
Epoch: 50, Training Loss: 0.2183, Validation Loss: 0.1748, Alpha: 0.8000
Epoch: 51, Training Loss: 0.2352, Validation Loss: 0.1367, Alpha: 0.8000
Epoch: 52, Training Loss: 0.3216, Validation Loss: 0.1631, Alpha: 0.8000
Epoch: 53, Training Loss: 0.2559, Validation Loss: 0.1849, Alpha: 0.8000
Epoch: 54, Training Loss: 0.2843, Validation Loss: 0.1552, Alpha: 0.8000
Epoch: 55, Training Loss: 0.2031, Validation Loss: 0.1108, Alpha: 0.8000
Epoch: 56, Training Loss: 0.2419, Validation Loss: 0.1706, Alpha: 0.8000
Epoch: 57, Training Loss: 0.2018, Validation Loss: 0.1145, Alpha: 0.8000
Epoch: 58, Training Loss: 0.2152, Validation Loss: 0.1772, Alpha: 0.8000
Epoch: 59, Training Loss: 0.2339, Validation Loss: 0.1971, Alpha: 0.8000
Epoch: 60, Training Loss: 0.2218, Validation Loss: 0.1480, Alpha: 0.8000
Epoch: 61, Training Loss: 0.2038, Validation Loss: 0.1376, Alpha: 0.8000
Epoch: 62, Training Loss: 0.1655, Validation Loss: 0.1319, Alpha: 0.8000
Epoch: 63, Training Loss: 0.1661, Validation Loss: 0.1569, Alpha: 0.8000
Epoch: 64, Training Loss: 0.2101, Validation Loss: 0.2225, Alpha: 0.8000
Epoch: 65, Training Loss: 0.1882, Validation Loss: 0.1665, Alpha: 0.8000
Epoch: 66, Training Loss: 0.1637, Validation Loss: 0.1781, Alpha: 0.8000
Epoch: 67, Training Loss: 0.1339, Validation Loss: 0.1253, Alpha: 0.8000
Epoch: 68, Training Loss: 0.1287, Validation Loss: 0.1075, Alpha: 0.8000
Epoch: 69, Training Loss: 0.1180, Validation Loss: 0.1057, Alpha: 0.8000
Epoch: 70, Training Loss: 0.0823, Validation Loss: 0.1034, Alpha: 0.8000
Epoch: 71, Training Loss: 0.1169, Validation Loss: 0.1090, Alpha: 0.8000
Epoch: 72, Training Loss: 0.0745, Validation Loss: 0.0987, Alpha: 0.8000
Epoch: 73, Training Loss: 0.1046, Validation Loss: 0.1018, Alpha: 0.8000
Epoch: 74, Training Loss: 0.0751, Validation Loss: 0.1006, Alpha: 0.8000
Epoch: 75, Training Loss: 0.0647, Validation Loss: 0.0983, Alpha: 0.8000
Epoch: 76, Training Loss: 0.0780, Validation Loss: 0.0990, Alpha: 0.8000
Epoch: 77, Training Loss: 0.0707, Validation Loss: 0.0915, Alpha: 0.8000
Epoch: 78, Training Loss: 0.0658, Validation Loss: 0.0931, Alpha: 0.8000
Epoch: 79, Training Loss: 0.0722, Validation Loss: 0.0952, Alpha: 0.8000
Epoch: 80, Training Loss: 0.0694, Validation Loss: 0.1073, Alpha: 0.8000
Epoch: 81, Training Loss: 0.0682, Validation Loss: 0.0988, Alpha: 0.8000
Epoch: 82, Training Loss: 0.0556, Validation Loss: 0.0936, Alpha: 0.8000
Epoch: 83, Training Loss: 0.0638, Validation Loss: 0.1020, Alpha: 0.8000
Epoch: 84, Training Loss: 0.0516, Validation Loss: 0.1057, Alpha: 0.8000
Epoch: 85, Training Loss: 0.0755, Validation Loss: 0.1083, Alpha: 0.8000
Epoch: 86, Training Loss: 0.0772, Validation Loss: 0.0919, Alpha: 0.8000
Epoch: 87, Training Loss: 0.0603, Validation Loss: 0.0980, Alpha: 0.8000
Epoch: 88, Training Loss: 0.0817, Validation Loss: 0.1126, Alpha: 0.8000
Epoch: 89, Training Loss: 0.0516, Validation Loss: 0.1059, Alpha: 0.8000
Epoch: 90, Training Loss: 0.0595, Validation Loss: 0.1012, Alpha: 0.8000
Epoch: 91, Training Loss: 0.0563, Validation Loss: 0.1069, Alpha: 0.8000
Epoch: 92, Training Loss: 0.0647, Validation Loss: 0.1043, Alpha: 0.8000
Epoch: 93, Training Loss: 0.0494, Validation Loss: 0.0991, Alpha: 0.8000
Epoch: 94, Training Loss: 0.0519, Validation Loss: 0.0974, Alpha: 0.8000
Epoch: 95, Training Loss: 0.0462, Validation Loss: 0.1014, Alpha: 0.8000
Epoch: 96, Training Loss: 0.0578, Validation Loss: 0.0981, Alpha: 0.8000
Epoch: 97, Training Loss: 0.0559, Validation Loss: 0.0953, Alpha: 0.8000
Early stopping triggered.
Running increased_features_complexity classification training with alpha = 1 using script scripts/increased_features_complexity/hierarchical-classification-training.py
/home/bcw/gits/FjordVision/fjordvision/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Epoch: 1, Training Loss: 4.8061, Validation Loss: 4.4701, Alpha: 1.0000
Epoch: 2, Training Loss: 3.5857, Validation Loss: 2.8658, Alpha: 1.0000
Epoch: 3, Training Loss: 2.7718, Validation Loss: 2.4709, Alpha: 1.0000
Epoch: 4, Training Loss: 2.2663, Validation Loss: 1.8649, Alpha: 1.0000
Epoch: 5, Training Loss: 1.9011, Validation Loss: 1.5637, Alpha: 1.0000
Epoch: 6, Training Loss: 1.6419, Validation Loss: 1.2459, Alpha: 1.0000
Epoch: 7, Training Loss: 1.4207, Validation Loss: 0.9952, Alpha: 1.0000
Epoch: 8, Training Loss: 1.2602, Validation Loss: 0.8731, Alpha: 1.0000
Epoch: 9, Training Loss: 1.1082, Validation Loss: 0.7661, Alpha: 1.0000
Epoch: 10, Training Loss: 0.9560, Validation Loss: 0.5965, Alpha: 1.0000
Epoch: 11, Training Loss: 0.8583, Validation Loss: 0.6293, Alpha: 1.0000
Epoch: 12, Training Loss: 0.7508, Validation Loss: 0.4625, Alpha: 1.0000
Epoch: 13, Training Loss: 0.6968, Validation Loss: 0.4241, Alpha: 1.0000
Epoch: 14, Training Loss: 0.6400, Validation Loss: 0.4531, Alpha: 1.0000
Epoch: 15, Training Loss: 0.5753, Validation Loss: 0.4313, Alpha: 1.0000
Epoch: 16, Training Loss: 0.5794, Validation Loss: 0.4334, Alpha: 1.0000
Epoch: 17, Training Loss: 0.5714, Validation Loss: 0.3250, Alpha: 1.0000
Epoch: 18, Training Loss: 0.5761, Validation Loss: 0.4397, Alpha: 1.0000
Epoch: 19, Training Loss: 0.4792, Validation Loss: 0.3055, Alpha: 1.0000
Epoch: 20, Training Loss: 0.4223, Validation Loss: 0.3080, Alpha: 1.0000
Epoch: 21, Training Loss: 0.4550, Validation Loss: 0.3757, Alpha: 1.0000
Epoch: 22, Training Loss: 0.5073, Validation Loss: 0.3029, Alpha: 1.0000
Epoch: 23, Training Loss: 0.4221, Validation Loss: 0.2857, Alpha: 1.0000
Epoch: 24, Training Loss: 0.4215, Validation Loss: 0.2837, Alpha: 1.0000
Epoch: 25, Training Loss: 0.4067, Validation Loss: 0.2571, Alpha: 1.0000
Epoch: 26, Training Loss: 0.4183, Validation Loss: 0.3195, Alpha: 1.0000
Epoch: 27, Training Loss: 0.3817, Validation Loss: 0.2276, Alpha: 1.0000
Epoch: 28, Training Loss: 0.3271, Validation Loss: 0.3533, Alpha: 1.0000
Epoch: 29, Training Loss: 0.3224, Validation Loss: 0.2825, Alpha: 1.0000
Epoch: 30, Training Loss: 0.3520, Validation Loss: 0.2866, Alpha: 1.0000
Epoch: 31, Training Loss: 0.2978, Validation Loss: 0.2067, Alpha: 1.0000
Epoch: 32, Training Loss: 0.2987, Validation Loss: 0.3825, Alpha: 1.0000
Epoch: 33, Training Loss: 0.2876, Validation Loss: 0.2036, Alpha: 1.0000
Epoch: 34, Training Loss: 0.2546, Validation Loss: 0.1917, Alpha: 1.0000
Epoch: 35, Training Loss: 0.2995, Validation Loss: 0.2260, Alpha: 1.0000
Epoch: 36, Training Loss: 0.2532, Validation Loss: 0.2603, Alpha: 1.0000
Epoch: 37, Training Loss: 0.2709, Validation Loss: 0.1898, Alpha: 1.0000
Epoch: 38, Training Loss: 0.2472, Validation Loss: 0.1592, Alpha: 1.0000
Epoch: 39, Training Loss: 0.2743, Validation Loss: 0.1703, Alpha: 1.0000
Epoch: 40, Training Loss: 0.2339, Validation Loss: 0.2061, Alpha: 1.0000
Epoch: 41, Training Loss: 0.2082, Validation Loss: 0.1795, Alpha: 1.0000
Epoch: 42, Training Loss: 0.2053, Validation Loss: 0.1992, Alpha: 1.0000
Epoch: 43, Training Loss: 0.2230, Validation Loss: 0.2468, Alpha: 1.0000
Epoch: 44, Training Loss: 0.1858, Validation Loss: 0.2609, Alpha: 1.0000
Epoch: 45, Training Loss: 0.1869, Validation Loss: 0.1965, Alpha: 1.0000
Epoch: 46, Training Loss: 0.2075, Validation Loss: 0.2338, Alpha: 1.0000
Epoch: 47, Training Loss: 0.2012, Validation Loss: 0.2300, Alpha: 1.0000
Epoch: 48, Training Loss: 0.2823, Validation Loss: 0.1913, Alpha: 1.0000
Epoch: 49, Training Loss: 0.1833, Validation Loss: 0.2178, Alpha: 1.0000
Epoch: 50, Training Loss: 0.1613, Validation Loss: 0.1489, Alpha: 1.0000
Epoch: 51, Training Loss: 0.1509, Validation Loss: 0.1337, Alpha: 1.0000
Epoch: 52, Training Loss: 0.1112, Validation Loss: 0.1317, Alpha: 1.0000
Epoch: 53, Training Loss: 0.0915, Validation Loss: 0.1264, Alpha: 1.0000
Epoch: 54, Training Loss: 0.0934, Validation Loss: 0.1228, Alpha: 1.0000
Epoch: 55, Training Loss: 0.0889, Validation Loss: 0.1245, Alpha: 1.0000
Epoch: 56, Training Loss: 0.0715, Validation Loss: 0.1281, Alpha: 1.0000
Epoch: 57, Training Loss: 0.1215, Validation Loss: 0.1366, Alpha: 1.0000
Epoch: 58, Training Loss: 0.0722, Validation Loss: 0.1190, Alpha: 1.0000
Epoch: 59, Training Loss: 0.0683, Validation Loss: 0.1203, Alpha: 1.0000
Epoch: 60, Training Loss: 0.0807, Validation Loss: 0.1264, Alpha: 1.0000
Epoch: 61, Training Loss: 0.0801, Validation Loss: 0.1275, Alpha: 1.0000
Epoch: 62, Training Loss: 0.0605, Validation Loss: 0.1254, Alpha: 1.0000
Epoch: 63, Training Loss: 0.0567, Validation Loss: 0.1264, Alpha: 1.0000
Epoch: 64, Training Loss: 0.0644, Validation Loss: 0.1227, Alpha: 1.0000
Epoch: 65, Training Loss: 0.0515, Validation Loss: 0.1224, Alpha: 1.0000
Epoch: 66, Training Loss: 0.0566, Validation Loss: 0.1194, Alpha: 1.0000
Epoch: 67, Training Loss: 0.0514, Validation Loss: 0.1174, Alpha: 1.0000
Epoch: 68, Training Loss: 0.0777, Validation Loss: 0.1287, Alpha: 1.0000
Epoch: 69, Training Loss: 0.0622, Validation Loss: 0.1340, Alpha: 1.0000
Epoch: 70, Training Loss: 0.0544, Validation Loss: 0.1294, Alpha: 1.0000
Epoch: 71, Training Loss: 0.0622, Validation Loss: 0.1198, Alpha: 1.0000
Epoch: 72, Training Loss: 0.0490, Validation Loss: 0.1208, Alpha: 1.0000
Epoch: 73, Training Loss: 0.0633, Validation Loss: 0.1150, Alpha: 1.0000
Epoch: 74, Training Loss: 0.0540, Validation Loss: 0.1217, Alpha: 1.0000
Epoch: 75, Training Loss: 0.0500, Validation Loss: 0.1164, Alpha: 1.0000
Epoch: 76, Training Loss: 0.0576, Validation Loss: 0.1266, Alpha: 1.0000
Epoch: 77, Training Loss: 0.0520, Validation Loss: 0.1290, Alpha: 1.0000
Epoch: 78, Training Loss: 0.0392, Validation Loss: 0.1310, Alpha: 1.0000
Epoch: 79, Training Loss: 0.0432, Validation Loss: 0.1232, Alpha: 1.0000
Epoch: 80, Training Loss: 0.0444, Validation Loss: 0.1220, Alpha: 1.0000
Epoch: 81, Training Loss: 0.0430, Validation Loss: 0.1221, Alpha: 1.0000
Epoch: 82, Training Loss: 0.0607, Validation Loss: 0.1310, Alpha: 1.0000
Epoch: 83, Training Loss: 0.0429, Validation Loss: 0.1214, Alpha: 1.0000
Epoch: 84, Training Loss: 0.0489, Validation Loss: 0.1374, Alpha: 1.0000
Epoch: 85, Training Loss: 0.0487, Validation Loss: 0.1304, Alpha: 1.0000
Epoch: 86, Training Loss: 0.0377, Validation Loss: 0.1327, Alpha: 1.0000
Epoch: 87, Training Loss: 0.0439, Validation Loss: 0.1319, Alpha: 1.0000
Epoch: 88, Training Loss: 0.0730, Validation Loss: 0.1302, Alpha: 1.0000
Epoch: 89, Training Loss: 0.0349, Validation Loss: 0.1343, Alpha: 1.0000
Epoch: 90, Training Loss: 0.0371, Validation Loss: 0.1288, Alpha: 1.0000
Epoch: 91, Training Loss: 0.0425, Validation Loss: 0.1309, Alpha: 1.0000
Epoch: 92, Training Loss: 0.0429, Validation Loss: 0.1270, Alpha: 1.0000
Epoch: 93, Training Loss: 0.0288, Validation Loss: 0.1321, Alpha: 1.0000
Early stopping triggered.
Experiment finished at Wed Jun 26 21:46:59 CEST 2024
