{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments on Fjord\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from anytree.importer import JsonImporter\n",
    "from utils.custom_dataset import CustomDataset\n",
    "from ultralytics import RTDETR\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "# extract test data\n",
    "df = pd.read_parquet('datasets/yolov8-segmented-objects-dataset.parquet')\n",
    "\n",
    "# Assuming df is your DataFrame with all data\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Local version of get labels\n",
    "def get_hierarchical_labels(species_index, species_names, genus_names, class_names, binary_names, root):\n",
    "    if species_index == -1:\n",
    "        return -1, -1, -1  # Handle cases where species_index is invalid\n",
    "\n",
    "    species_name = species_names[species_index]\n",
    "    node = next((n for n in root.descendants if n.name == species_name), None)\n",
    "\n",
    "    if node is None:\n",
    "        return -1, -1, -1  # Species not found in the tree\n",
    "\n",
    "    genus_index, class_index, binary_index = -1, -1, -1\n",
    "    current_node = node\n",
    "    while current_node.parent is not None:\n",
    "        current_node = current_node.parent\n",
    "        if current_node.rank == 'genus':\n",
    "            genus_index = genus_names.index(current_node.name) if current_node.name in genus_names else -1\n",
    "        elif current_node.rank == 'class':\n",
    "            class_index = class_names.index(current_node.name) if current_node.name in class_names else -1\n",
    "        elif current_node.rank == 'binary':\n",
    "            binary_index = binary_names.index(current_node.name) if current_node.name in binary_names else -1\n",
    "\n",
    "    return genus_index, class_index, binary_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.0.weight', 'conv1.0.bias', 'conv1.1.weight', 'conv1.1.bias', 'conv1.1.running_mean', 'conv1.1.running_var', 'conv1.1.num_batches_tracked', 'conv1.3.weight', 'conv1.3.bias', 'conv1.4.weight', 'conv1.4.bias', 'conv1.4.running_mean', 'conv1.4.running_var', 'conv1.4.num_batches_tracked', 'conv1.7.fc.0.weight', 'conv1.7.fc.2.weight', 'conv1.8.conv1.weight', 'conv2.0.weight', 'conv2.0.bias', 'conv2.1.weight', 'conv2.1.bias', 'conv2.1.running_mean', 'conv2.1.running_var', 'conv2.1.num_batches_tracked', 'conv2.3.weight', 'conv2.3.bias', 'conv2.4.weight', 'conv2.4.bias', 'conv2.4.running_mean', 'conv2.4.running_var', 'conv2.4.num_batches_tracked', 'conv2.7.fc.0.weight', 'conv2.7.fc.2.weight', 'conv2.8.conv1.weight', 'conv3.0.weight', 'conv3.0.bias', 'conv3.1.weight', 'conv3.1.bias', 'conv3.1.running_mean', 'conv3.1.running_var', 'conv3.1.num_batches_tracked', 'conv3.3.weight', 'conv3.3.bias', 'conv3.4.weight', 'conv3.4.bias', 'conv3.4.running_mean', 'conv3.4.running_var', 'conv3.4.num_batches_tracked', 'conv3.7.fc.0.weight', 'conv3.7.fc.2.weight', 'conv3.8.conv1.weight', 'conv4.0.weight', 'conv4.0.bias', 'conv4.1.weight', 'conv4.1.bias', 'conv4.1.running_mean', 'conv4.1.running_var', 'conv4.1.num_batches_tracked', 'conv4.3.weight', 'conv4.3.bias', 'conv4.4.weight', 'conv4.4.bias', 'conv4.4.running_mean', 'conv4.4.running_var', 'conv4.4.num_batches_tracked', 'conv4.7.fc.0.weight', 'conv4.7.fc.2.weight', 'conv4.8.conv1.weight', 'branches.0.fc_layers.0.weight', 'branches.0.fc_layers.0.bias', 'branches.0.fc_layers.1.weight', 'branches.0.fc_layers.1.bias', 'branches.0.fc_layers.1.running_mean', 'branches.0.fc_layers.1.running_var', 'branches.0.fc_layers.1.num_batches_tracked', 'branches.0.fc_layers.4.weight', 'branches.0.fc_layers.4.bias', 'branches.0.fc_layers.5.weight', 'branches.0.fc_layers.5.bias', 'branches.0.fc_layers.5.running_mean', 'branches.0.fc_layers.5.running_var', 'branches.0.fc_layers.5.num_batches_tracked', 'branches.0.fc_layers.8.weight', 'branches.0.fc_layers.8.bias', 'branches.0.fc_layers.9.weight', 'branches.0.fc_layers.9.bias', 'branches.0.fc_layers.9.running_mean', 'branches.0.fc_layers.9.running_var', 'branches.0.fc_layers.9.num_batches_tracked', 'branches.0.fc_layers.12.weight', 'branches.0.fc_layers.12.bias', 'branches.1.fc_layers.0.weight', 'branches.1.fc_layers.0.bias', 'branches.1.fc_layers.1.weight', 'branches.1.fc_layers.1.bias', 'branches.1.fc_layers.1.running_mean', 'branches.1.fc_layers.1.running_var', 'branches.1.fc_layers.1.num_batches_tracked', 'branches.1.fc_layers.4.weight', 'branches.1.fc_layers.4.bias', 'branches.1.fc_layers.5.weight', 'branches.1.fc_layers.5.bias', 'branches.1.fc_layers.5.running_mean', 'branches.1.fc_layers.5.running_var', 'branches.1.fc_layers.5.num_batches_tracked', 'branches.1.fc_layers.8.weight', 'branches.1.fc_layers.8.bias', 'branches.1.fc_layers.9.weight', 'branches.1.fc_layers.9.bias', 'branches.1.fc_layers.9.running_mean', 'branches.1.fc_layers.9.running_var', 'branches.1.fc_layers.9.num_batches_tracked', 'branches.1.fc_layers.12.weight', 'branches.1.fc_layers.12.bias', 'branches.2.fc_layers.0.weight', 'branches.2.fc_layers.0.bias', 'branches.2.fc_layers.1.weight', 'branches.2.fc_layers.1.bias', 'branches.2.fc_layers.1.running_mean', 'branches.2.fc_layers.1.running_var', 'branches.2.fc_layers.1.num_batches_tracked', 'branches.2.fc_layers.4.weight', 'branches.2.fc_layers.4.bias', 'branches.2.fc_layers.5.weight', 'branches.2.fc_layers.5.bias', 'branches.2.fc_layers.5.running_mean', 'branches.2.fc_layers.5.running_var', 'branches.2.fc_layers.5.num_batches_tracked', 'branches.2.fc_layers.8.weight', 'branches.2.fc_layers.8.bias', 'branches.2.fc_layers.9.weight', 'branches.2.fc_layers.9.bias', 'branches.2.fc_layers.9.running_mean', 'branches.2.fc_layers.9.running_var', 'branches.2.fc_layers.9.num_batches_tracked', 'branches.2.fc_layers.12.weight', 'branches.2.fc_layers.12.bias', 'branches.3.fc_layers.0.weight', 'branches.3.fc_layers.0.bias', 'branches.3.fc_layers.1.weight', 'branches.3.fc_layers.1.bias', 'branches.3.fc_layers.1.running_mean', 'branches.3.fc_layers.1.running_var', 'branches.3.fc_layers.1.num_batches_tracked', 'branches.3.fc_layers.4.weight', 'branches.3.fc_layers.4.bias', 'branches.3.fc_layers.5.weight', 'branches.3.fc_layers.5.bias', 'branches.3.fc_layers.5.running_mean', 'branches.3.fc_layers.5.running_var', 'branches.3.fc_layers.5.num_batches_tracked', 'branches.3.fc_layers.8.weight', 'branches.3.fc_layers.8.bias', 'branches.3.fc_layers.9.weight', 'branches.3.fc_layers.9.bias', 'branches.3.fc_layers.9.running_mean', 'branches.3.fc_layers.9.running_var', 'branches.3.fc_layers.9.num_batches_tracked', 'branches.3.fc_layers.12.weight', 'branches.3.fc_layers.12.bias'])\n"
     ]
    }
   ],
   "source": [
    "model_path = \"datasets/hierarchical-model-weights/weights/best_model_alpha_0.50.pth\"\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Print the keys of the state dictionary\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ablation</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>binary</th>\n",
       "      <th>class</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yolov8-no-reclassification</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.9131</td>\n",
       "      <td>0.9185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yolov8-Reclassified</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.9003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ablation  Alpha  binary   class   genus  species\n",
       "0  yolov8-no-reclassification    0.5  0.6612  0.8792  0.9131   0.9185\n",
       "1         yolov8-Reclassified    0.5  0.6522  0.8600  0.8930   0.9003"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_experiment(data_path, classes_file, model_path, ablation, root, reclassify=True):\n",
    "    df = pd.read_parquet(data_path)\n",
    "    _, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "    object_names = [line.strip() for line in open(classes_file, 'r')]\n",
    "    subcategory_names, category_names, binary_names = [], [], []\n",
    "    for node in root.descendants:\n",
    "        if node.rank == 'genus':\n",
    "            subcategory_names.append(node.name)\n",
    "        elif node.rank == 'class':\n",
    "            category_names.append(node.name)\n",
    "        elif node.rank == 'binary':\n",
    "            binary_names.append(node.name)\n",
    "\n",
    "    rank_counts = defaultdict(int)\n",
    "    for node in root.descendants:\n",
    "        rank_counts[node.rank] += 1\n",
    "    num_classes_hierarchy = [rank_counts['binary'], rank_counts['class'], rank_counts['genus'], rank_counts['species']]\n",
    "\n",
    "    from models.hierarchical_cnn import HierarchicalCNN\n",
    "    num_additional_features = 2  # e.g., conf, pred_species\n",
    "    if ablation in ['yolov8', 'baseline', 'yolov9', 'baseline', 'RT-DETR']:\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'remove_features':\n",
    "        from models.ablations.remove_features.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy)\n",
    "    elif ablation == 'attention_removed':\n",
    "        from models.ablations.attention_removed.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'decreased_branch_complexity':\n",
    "        from models.ablations.decreased_branch_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'increased_features_complexity':\n",
    "        from models.ablations.increased_features_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ablation study: {ablation}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = CustomDataset(test_df, object_names, subcategory_names, category_names, binary_names, root)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    true_labels = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "    predictions = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, conf, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "            images, conf, pred_species = [x.to(device) for x in [images, conf, pred_species]]\n",
    "\n",
    "            if not reclassify:\n",
    "                for pred in pred_species:\n",
    "                    genus_idx, class_idx, binary_idx = get_hierarchical_labels(pred.item(), object_names, subcategory_names, category_names, binary_names, root)\n",
    "                    predictions['species'].append(pred.item())\n",
    "                    predictions['genus'].append(genus_idx)\n",
    "                    predictions['class'].append(class_idx)\n",
    "                    predictions['binary'].append(binary_idx)\n",
    "            else:\n",
    "                outputs = model(images, conf, pred_species)\n",
    "                for i, output in enumerate(outputs):\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    level = ['binary', 'class', 'genus', 'species'][i]\n",
    "                    predictions[level].extend(predicted.cpu().numpy())\n",
    "\n",
    "            true_labels['binary'].extend(binary_index.cpu().numpy())\n",
    "            true_labels['class'].extend(class_index.cpu().numpy())\n",
    "            true_labels['genus'].extend(genus_index.cpu().numpy())\n",
    "            true_labels['species'].extend(species_index.cpu().numpy())\n",
    "\n",
    "    # Remove cases where no predictions were made\n",
    "    for level in ['binary', 'class', 'genus', 'species']:\n",
    "        true_labels[level] = [label for label, pred in zip(true_labels[level], predictions[level]) if pred != -1]\n",
    "        predictions[level] = [pred for pred in predictions[level] if pred != -1]\n",
    "\n",
    "    f1_scores = {level: f1_score(true_labels[level], predictions[level], average='macro') for level in ['binary', 'class', 'genus', 'species']}\n",
    "    return f1_scores\n",
    "\n",
    "# Populate Taxonomy\n",
    "importer = JsonImporter()\n",
    "with open('datasets/ontology.json', 'r') as f:\n",
    "    root = importer.read(f)\n",
    "\n",
    "# Paths and setup\n",
    "classes_file = 'datasets/EMVSD/EMVSD/classes.txt'\n",
    "ablations = ['yolov8']\n",
    "alpha_values = [0.5]\n",
    "\n",
    "# Run experiments and collect results\n",
    "results = []\n",
    "for ablation in ablations:\n",
    "    for alpha in alpha_values:\n",
    "        if ablation in ['yolov8', 'baseline']:\n",
    "            data_path = 'datasets/yolov8-segmented-objects-dataset.parquet'\n",
    "            model_path = f'datasets/hierarchical-model-weights/weights/best_model_alpha_{alpha:.2f}.pth'\n",
    "        elif ablation == 'RT-DETR':\n",
    "            data_path = 'datasets/rtdetr-segmented-objects-dataset.parquet'\n",
    "            model_path = f'datasets/hierarchical-model-weights/weights/best_model_alpha_rtdetr_{alpha:.2f}.pth'\n",
    "        elif ablation == 'yolov9':\n",
    "            data_path = 'datasets/yolov9-segmented-objects-dataset.parquet'\n",
    "            model_path = f'datasets/hierarchical-model-weights/weights/best_model_alpha_yolov9_{alpha:.2f}.pth'\n",
    "        else:\n",
    "            model_path = f'datasets/hierarchical-model-weights/ablations/{ablation}/weights/best_model_alpha_{alpha:.2f}.pth'\n",
    "        \n",
    "        # Run experiment without reclassification\n",
    "        f1_scores_no_reclassification = run_experiment(data_path, classes_file, model_path, ablation, root, reclassify=False)\n",
    "        results.append({'Ablation': ablation + '-no-reclassification', 'Alpha': alpha, **f1_scores_no_reclassification})\n",
    "\n",
    "        # Run experiment with reclassification for hierarchical CNN models\n",
    "        if ablation in ['yolov8', 'RT-DETR', 'yolov9']:\n",
    "            f1_scores_reclassified = run_experiment(data_path, classes_file, model_path, ablation, root, reclassify=True)\n",
    "            results.append({'Ablation': ablation + '-Reclassified', 'Alpha': alpha, **f1_scores_reclassified})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjordvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
