{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments on Fjord\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# extract test data\n",
    "df = pd.read_parquet('datasets/segmented-objects-dataset.parquet')\n",
    "\n",
    "# Assuming df is your DataFrame with all data\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Local version of get labels\n",
    "def get_hierarchical_labels(species_index, species_names, genus_names, class_names, binary_names, root):\n",
    "    if species_index == -1:\n",
    "        return -1, -1, -1  # Handle cases where species_index is invalid\n",
    "\n",
    "    species_name = species_names[species_index]\n",
    "    node = next((n for n in root.descendants if n.name == species_name), None)\n",
    "\n",
    "    if node is None:\n",
    "        return -1, -1, -1  # Species not found in the tree\n",
    "\n",
    "    genus_index, class_index, binary_index = -1, -1, -1\n",
    "    current_node = node\n",
    "    while current_node.parent is not None:\n",
    "        current_node = current_node.parent\n",
    "        if current_node.rank == 'genus':\n",
    "            genus_index = genus_names.index(current_node.name) if current_node.name in genus_names else -1\n",
    "        elif current_node.rank == 'class':\n",
    "            class_index = class_names.index(current_node.name) if current_node.name in class_names else -1\n",
    "        elif current_node.rank == 'binary':\n",
    "            binary_index = binary_names.index(current_node.name) if current_node.name in binary_names else -1\n",
    "\n",
    "    return genus_index, class_index, binary_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ablation</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>binary</th>\n",
       "      <th>class</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yolov8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yolov8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yolov8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yolov8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yolov8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.9210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>baseline</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.9214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6620</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.9218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.9221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.9223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.9119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.9128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.9152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.9227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Ablation  Alpha  binary   class   genus  species\n",
       "0                          Yolov8    0.0  0.6608  0.8810  0.9151   0.9205\n",
       "1                          Yolov8    0.2  0.6608  0.8810  0.9151   0.9205\n",
       "2                          Yolov8    0.5  0.6608  0.8810  0.9151   0.9205\n",
       "3                          Yolov8    0.8  0.6608  0.8810  0.9151   0.9205\n",
       "4                          Yolov8    1.0  0.6608  0.8810  0.9151   0.9205\n",
       "5                        baseline    0.0  0.6610  0.8814  0.9162   0.9224\n",
       "6                        baseline    0.2  0.6613  0.8822  0.9159   0.9218\n",
       "7                        baseline    0.5  0.6621  0.8826  0.9167   0.9220\n",
       "8                        baseline    0.8  0.6615  0.8810  0.9165   0.9210\n",
       "9                        baseline    1.0  0.6610  0.8822  0.9164   0.9214\n",
       "10  increased_features_complexity    0.0  0.6620  0.8822  0.9160   0.9220\n",
       "11  increased_features_complexity    0.2  0.6622  0.8821  0.9161   0.9223\n",
       "12  increased_features_complexity    0.5  0.6611  0.8824  0.9166   0.9218\n",
       "13  increased_features_complexity    0.8  0.6621  0.8822  0.9163   0.9221\n",
       "14  increased_features_complexity    1.0  0.6610  0.8819  0.9168   0.9223\n",
       "15                remove_features    0.0  0.6571  0.8739  0.9055   0.9119\n",
       "16                remove_features    0.2  0.6576  0.8754  0.9085   0.9136\n",
       "17                remove_features    0.5  0.6572  0.8743  0.9069   0.9128\n",
       "18                remove_features    0.8  0.6582  0.8753  0.9081   0.9142\n",
       "19                remove_features    1.0  0.6588  0.8769  0.9097   0.9152\n",
       "20              attention_removed    0.0  0.6607  0.8812  0.9163   0.9206\n",
       "21              attention_removed    0.2  0.6610  0.8815  0.9149   0.9207\n",
       "22              attention_removed    0.5  0.6610  0.8794  0.9154   0.9204\n",
       "23              attention_removed    0.8  0.6607  0.8816  0.9152   0.9213\n",
       "24              attention_removed    1.0  0.6606  0.8808  0.9158   0.9216\n",
       "25    decreased_branch_complexity    0.0  0.6610  0.8818  0.9159   0.9212\n",
       "26    decreased_branch_complexity    0.2  0.6611  0.8818  0.9161   0.9210\n",
       "27    decreased_branch_complexity    0.5  0.6605  0.8814  0.9163   0.9216\n",
       "28    decreased_branch_complexity    0.8  0.6619  0.8819  0.9161   0.9215\n",
       "29    decreased_branch_complexity    1.0  0.6622  0.8823  0.9165   0.9227"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from anytree.importer import JsonImporter\n",
    "from utils.custom_dataset import CustomDataset\n",
    "\n",
    "def run_experiment(data_path, classes_file, model_path, ablation, root):\n",
    "    df = pd.read_parquet(data_path)\n",
    "    _, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "    object_names = [line.strip() for line in open(classes_file, 'r')]\n",
    "    subcategory_names, category_names, binary_names = [], [], []\n",
    "    for node in root.descendants:\n",
    "        if node.rank == 'genus':\n",
    "            subcategory_names.append(node.name)\n",
    "        elif node.rank == 'class':\n",
    "            category_names.append(node.name)\n",
    "        elif node.rank == 'binary':\n",
    "            binary_names.append(node.name)\n",
    "\n",
    "    rank_counts = defaultdict(int)\n",
    "    for node in root.descendants:\n",
    "        rank_counts[node.rank] += 1\n",
    "    num_classes_hierarchy = [rank_counts['binary'], rank_counts['class'], rank_counts['genus'], rank_counts['species']]\n",
    "\n",
    "  # Adjust model import and initialization based on ablation type\n",
    "    if ablation == 'baseline':\n",
    "        from models.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'Yolov8':\n",
    "        from models.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'remove_features':\n",
    "        from models.ablations.remove_features.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy)\n",
    "    elif ablation == 'attention_removed':\n",
    "        from models.ablations.attention_removed.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'decreased_branch_complexity':\n",
    "        from models.ablations.decreased_branch_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'increased_features_complexity':\n",
    "        from models.ablations.increased_features_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ablation study: {ablation}\")\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = CustomDataset(test_df, object_names, subcategory_names, category_names, binary_names, root)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    true_labels = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "    predictions = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "            images, conf, iou, pred_species = [x.to(device) for x in [images, conf, iou, pred_species]]\n",
    "\n",
    "            if ablation == 'Yolov8':\n",
    "                for idx in pred_species:\n",
    "                    genus_idx, class_idx, binary_idx = get_hierarchical_labels(idx.item(), object_names, subcategory_names, category_names, binary_names, root)\n",
    "                    # Storing the hierarchical labels\n",
    "                    predictions['binary'].append(binary_idx)\n",
    "                    predictions['class'].append(class_idx)\n",
    "                    predictions['genus'].append(genus_idx)\n",
    "                    predictions['species'].append(idx.item())\n",
    "            else:\n",
    "                outputs = model(images, conf, iou, pred_species) if ablation != 'remove_features' else model(images)\n",
    "                for i, output in enumerate(outputs):\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    level = ['binary', 'class', 'genus', 'species'][i]\n",
    "                    predictions[level].extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store true labels directly from the DataLoader\n",
    "            true_labels['binary'].extend(binary_index.cpu().numpy())\n",
    "            true_labels['class'].extend(class_index.cpu().numpy())\n",
    "            true_labels['genus'].extend(genus_index.cpu().numpy())\n",
    "            true_labels['species'].extend(species_index.cpu().numpy())\n",
    "\n",
    "    f1_scores = {level: f1_score(true_labels[level], predictions[level], average='macro') for level in ['binary', 'class', 'genus', 'species']}\n",
    "    return f1_scores\n",
    "\n",
    "# Populate Taxonomy\n",
    "importer = JsonImporter()\n",
    "with open('datasets/ontology.json', 'r') as f:\n",
    "    root = importer.read(f)\n",
    "\n",
    "# Paths and setup\n",
    "data_path = 'datasets/segmented-objects-dataset.parquet'\n",
    "classes_file = 'datasets/The Fjord Dataset/fjord/classes.txt'\n",
    "ablations = ['Yolov8', 'baseline', 'increased_features_complexity', 'remove_features', 'attention_removed', 'decreased_branch_complexity']\n",
    "alpha_values = [0, 0.2, 0.5, 0.8, 1]\n",
    "\n",
    "# Run experiments and collect results\n",
    "results = []\n",
    "for ablation in ablations:\n",
    "    for alpha in alpha_values:\n",
    "        if ablation == 'Yolov8' or ablation == 'baseline':\n",
    "            model_path = f'datasets/hierarchical-model-weights/weights/best_model_alpha_{alpha:.2f}.pth'\n",
    "        else:\n",
    "            model_path = f'datasets/hierarchical-model-weights/ablations/{ablation}/weights/best_model_alpha_{alpha:.2f}.pth'\n",
    "        f1_scores = run_experiment(data_path, classes_file, model_path, ablation, root)\n",
    "        results.append({'Ablation': ablation, 'Alpha': alpha, **f1_scores})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjordvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
