{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Ablations on Fjord\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# extract test data\n",
    "df = pd.read_parquet('data/segmented-objects-dataset.parquet')\n",
    "\n",
    "# Assuming df is your DataFrame with all data\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Local version of get labels\n",
    "def get_hierarchical_labels(species_index, species_names, genus_names, class_names, binary_names, root):\n",
    "    if species_index == -1:\n",
    "        return -1, -1, -1  # Handle cases where species_index is invalid\n",
    "\n",
    "    species_name = species_names[species_index]\n",
    "    node = next((n for n in root.descendants if n.name == species_name), None)\n",
    "\n",
    "    if node is None:\n",
    "        return -1, -1, -1  # Species not found in the tree\n",
    "\n",
    "    genus_index, class_index, binary_index = -1, -1, -1\n",
    "    current_node = node\n",
    "    while current_node.parent is not None:\n",
    "        current_node = current_node.parent\n",
    "        if current_node.rank == 'genus':\n",
    "            genus_index = genus_names.index(current_node.name) if current_node.name in genus_names else -1\n",
    "        elif current_node.rank == 'class':\n",
    "            class_index = class_names.index(current_node.name) if current_node.name in class_names else -1\n",
    "        elif current_node.rank == 'binary':\n",
    "            binary_index = binary_names.index(current_node.name) if current_node.name in binary_names else -1\n",
    "\n",
    "    return genus_index, class_index, binary_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the training log file\n",
    "training_log = pd.read_csv('models/ablations/attention_removed/logs/model_alpha_0.00.csv')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(training_log['Epoch'], training_log['Training Loss'], label='Training Loss')\n",
    "plt.plot(training_log['Epoch'], training_log['Validation Loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from anytree.importer import JsonImporter\n",
    "from utils.custom_dataset import CustomDataset\n",
    "\n",
    "def run_experiment(data_path, classes_file, model_path, ablation, root):\n",
    "    df = pd.read_parquet(data_path)\n",
    "    _, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "    object_names = [line.strip() for line in open(classes_file, 'r')]\n",
    "    subcategory_names, category_names, binary_names = [], [], []\n",
    "    for node in root.descendants:\n",
    "        if node.rank == 'genus':\n",
    "            subcategory_names.append(node.name)\n",
    "        elif node.rank == 'class':\n",
    "            category_names.append(node.name)\n",
    "        elif node.rank == 'binary':\n",
    "            binary_names.append(node.name)\n",
    "\n",
    "    rank_counts = defaultdict(int)\n",
    "    for node in root.descendants:\n",
    "        rank_counts[node.rank] += 1\n",
    "    num_classes_hierarchy = [rank_counts['binary'], rank_counts['class'], rank_counts['genus'], rank_counts['species']]\n",
    "\n",
    "  # Adjust model import and initialization based on ablation type\n",
    "    if ablation == 'remove_features':\n",
    "        from models.ablations.remove_features.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy)\n",
    "    elif ablation == 'attention_removed':\n",
    "        from models.ablations.attention_removed.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'decreased_branch_complexity':\n",
    "        from models.ablations.decreased_branch_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'increased_features_complexity':\n",
    "        from models.ablations.increased_features_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ablation study: {ablation}\")\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = CustomDataset(test_df, object_names, subcategory_names, category_names, binary_names, root)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    true_labels = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "    predictions = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "            images, conf, iou, pred_species = [x.to(device) for x in [images, conf, iou, pred_species]]\n",
    "\n",
    "            outputs = model(images, conf, iou, pred_species) if ablation != 'remove_features' else model(images)\n",
    "\n",
    "            for i, output in enumerate(outputs):\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                level = ['binary', 'class', 'genus', 'species'][i]\n",
    "                predictions[level].extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store true labels directly from the DataLoader\n",
    "            true_labels['binary'].extend(binary_index.cpu().numpy())\n",
    "            true_labels['class'].extend(class_index.cpu().numpy())\n",
    "            true_labels['genus'].extend(genus_index.cpu().numpy())\n",
    "            true_labels['species'].extend(species_index.cpu().numpy())\n",
    "\n",
    "    f1_scores = {level: f1_score(true_labels[level], predictions[level], average='macro') for level in ['binary', 'class', 'genus', 'species']}\n",
    "    return f1_scores\n",
    "\n",
    "# Populate Taxonomy\n",
    "importer = JsonImporter()\n",
    "with open('/mnt/RAID/projects/FjordVision/data/ontology.json', 'r') as f:\n",
    "    root = importer.read(f)\n",
    "\n",
    "# Paths and setup\n",
    "data_path = 'data/segmented-objects-dataset.parquet'\n",
    "classes_file = '/mnt/RAID/datasets/The Fjord Dataset/fjord/classes.txt'\n",
    "ablations = ['increased_features_complexity', 'remove_features', 'attention_removed', 'decreased_branch_complexity']\n",
    "alpha_values = [0, 0.2, 0.5, 0.8, 1]\n",
    "\n",
    "# Run experiments and collect results\n",
    "results = []\n",
    "for ablation in ablations:\n",
    "    for alpha in alpha_values:\n",
    "        model_path = f'models/ablations/{ablation}/weights/best_model_alpha_{alpha:.2f}.pth'\n",
    "        f1_scores = run_experiment(data_path, classes_file, model_path, ablation, root)\n",
    "        results.append({'Ablation': ablation, 'Alpha': alpha, **f1_scores})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ablation</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>binary</th>\n",
       "      <th>class</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6620</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.9218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.9221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.9223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.9119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.9128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.9152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.9227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Ablation  Alpha  binary   class   genus  species\n",
       "0   increased_features_complexity    0.0  0.6620  0.8822  0.9160   0.9220\n",
       "1   increased_features_complexity    0.2  0.6622  0.8821  0.9161   0.9223\n",
       "2   increased_features_complexity    0.5  0.6611  0.8824  0.9166   0.9218\n",
       "3   increased_features_complexity    0.8  0.6621  0.8822  0.9163   0.9221\n",
       "4   increased_features_complexity    1.0  0.6610  0.8819  0.9168   0.9223\n",
       "5                 remove_features    0.0  0.6571  0.8739  0.9055   0.9119\n",
       "6                 remove_features    0.2  0.6576  0.8754  0.9085   0.9136\n",
       "7                 remove_features    0.5  0.6572  0.8743  0.9069   0.9128\n",
       "8                 remove_features    0.8  0.6582  0.8753  0.9081   0.9142\n",
       "9                 remove_features    1.0  0.6588  0.8769  0.9097   0.9152\n",
       "10              attention_removed    0.0  0.6607  0.8812  0.9163   0.9206\n",
       "11              attention_removed    0.2  0.6610  0.8815  0.9149   0.9207\n",
       "12              attention_removed    0.5  0.6610  0.8794  0.9154   0.9204\n",
       "13              attention_removed    0.8  0.6607  0.8816  0.9152   0.9213\n",
       "14              attention_removed    1.0  0.6606  0.8808  0.9158   0.9216\n",
       "15    decreased_branch_complexity    0.0  0.6610  0.8818  0.9159   0.9212\n",
       "16    decreased_branch_complexity    0.2  0.6611  0.8818  0.9161   0.9210\n",
       "17    decreased_branch_complexity    0.5  0.6605  0.8814  0.9163   0.9216\n",
       "18    decreased_branch_complexity    0.8  0.6619  0.8819  0.9161   0.9215\n",
       "19    decreased_branch_complexity    1.0  0.6622  0.8823  0.9165   0.9227"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Ablations on COCO\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from anytree.importer import JsonImporter\n",
    "from collections import defaultdict\n",
    "from utils.custom_dataset import CustomDatasetCoco\n",
    "\n",
    "def run_coco_experiment(data_path, classes_file, model_path, ablation, root_coco):\n",
    "    df = pd.read_parquet(data_path)\n",
    "    _, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "    object_names = [line.strip() for line in open(classes_file, 'r')]\n",
    "    subcategory_names, category_names, binary_names = [], [], []\n",
    "    for node in root_coco.descendants:\n",
    "        if node.rank == 'subcategory':\n",
    "            subcategory_names.append(node.name)\n",
    "        elif node.rank == 'category':\n",
    "            category_names.append(node.name)\n",
    "        elif node.rank == 'binary':\n",
    "            binary_names.append(node.name)\n",
    "\n",
    "    rank_counts = defaultdict(int)\n",
    "    for node in root_coco.descendants:\n",
    "        rank_counts[node.rank] += 1\n",
    "    num_classes_hierarchy = [rank_counts['binary'], rank_counts['category'], rank_counts['subcategory'], rank_counts['object']]\n",
    "\n",
    "  # Adjust model import and initialization based on ablation type\n",
    "    if ablation == 'remove_features':\n",
    "        from models.ablations.remove_features.hierarchical_cnn import HierarchicalCNN\n",
    "        model = HierarchicalCNN(num_classes_hierarchy)\n",
    "    elif ablation == 'attention_removed':\n",
    "        from models.ablations.attention_removed.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'decreased_branch_complexity':\n",
    "        from models.ablations.decreased_branch_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    elif ablation == 'increased_features_complexity':\n",
    "        from models.ablations.increased_features_complexity.hierarchical_cnn import HierarchicalCNN\n",
    "        num_additional_features = 3  # e.g., conf, iou, pred_species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ablation study: {ablation}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = CustomDatasetCoco(test_df, object_names, subcategory_names, category_names, binary_names, root_coco)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    true_labels = {level: [] for level in ['binary', 'category', 'subcategory', 'object']}\n",
    "    predictions = {level: [] for level in ['binary', 'category', 'subcategory', 'object']}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "            images, conf, iou, pred_species = [x.to(device) for x in [images, conf, iou, pred_species]]\n",
    "\n",
    "            outputs = model(images, conf, iou, pred_species) if ablation != 'remove_features' else model(images)\n",
    "\n",
    "            for i, output in enumerate(outputs):\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                level = ['binary', 'category', 'subcategory', 'object'][i]\n",
    "                predictions[level].extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store true labels directly from the DataLoader\n",
    "            true_labels['binary'].extend(binary_index.cpu().numpy())\n",
    "            true_labels['category'].extend(class_index.cpu().numpy())\n",
    "            true_labels['subcategory'].extend(genus_index.cpu().numpy())\n",
    "            true_labels['object'].extend(species_index.cpu().numpy())\n",
    "\n",
    "    f1_scores = {level: f1_score(true_labels[level], predictions[level], average='macro') for level in ['binary', 'category', 'subcategory', 'object']}\n",
    "    return f1_scores\n",
    "\n",
    "# Populate Taxonomy for COCO\n",
    "importer = JsonImporter()\n",
    "root_coco = importer.read(open('data/coco.json', 'r'))\n",
    "\n",
    "# Paths and setup for COCO\n",
    "data_path = 'data/coco-segmented-objects-dataset.parquet'\n",
    "classes_file = '/mnt/RAID/datasets/coco/classes.txt'\n",
    "ablations = ['increased_features_complexity', 'remove_features', 'attention_removed', 'decreased_branch_complexity']\n",
    "alpha_values = [0, 0.2, 0.5, 0.8, 1]\n",
    "\n",
    "# Run experiments and collect results for COCO\n",
    "coco_results = []\n",
    "for ablation in ablations:\n",
    "    for alpha in alpha_values:\n",
    "        model_path = f'models/ablations/{ablation}/weights-coco/best_model_alpha_{alpha:.2f}.pth'\n",
    "        f1_scores = run_coco_experiment(data_path, classes_file, model_path, ablation, root_coco)\n",
    "        coco_results.append({'Ablation': ablation, 'Alpha': alpha, **f1_scores})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "coco_results_df = pd.DataFrame(coco_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ablation</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>binary</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6269</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.5368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.5783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>increased_features_complexity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.2943</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>remove_features</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3607</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.5536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.5581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.5539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.5807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>attention_removed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.5705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.5263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6246</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.5909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.5815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.5843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decreased_branch_complexity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.5032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Ablation  Alpha  binary  category  subcategory  \\\n",
       "0   increased_features_complexity    0.0  0.6158    0.0502       0.0273   \n",
       "1   increased_features_complexity    0.2  0.6269    0.0909       0.0050   \n",
       "2   increased_features_complexity    0.5  0.6273    0.0644       0.0978   \n",
       "3   increased_features_complexity    0.8  0.6272    0.0986       0.0483   \n",
       "4   increased_features_complexity    1.0  0.6260    0.0886       0.0512   \n",
       "5                 remove_features    0.0  0.3508    0.2425       0.1225   \n",
       "6                 remove_features    0.2  0.3486    0.2943       0.1185   \n",
       "7                 remove_features    0.5  0.3103    0.2539       0.1177   \n",
       "8                 remove_features    0.8  0.3830    0.2742       0.1215   \n",
       "9                 remove_features    1.0  0.3607    0.2978       0.1170   \n",
       "10              attention_removed    0.0  0.6268    0.1103       0.0521   \n",
       "11              attention_removed    0.2  0.6240    0.1625       0.1068   \n",
       "12              attention_removed    0.5  0.6241    0.2045       0.0642   \n",
       "13              attention_removed    0.8  0.6247    0.1587       0.0945   \n",
       "14              attention_removed    1.0  0.6251    0.1013       0.0668   \n",
       "15    decreased_branch_complexity    0.0  0.6205    0.0822       0.0033   \n",
       "16    decreased_branch_complexity    0.2  0.6246    0.1173       0.0529   \n",
       "17    decreased_branch_complexity    0.5  0.6226    0.0754       0.0266   \n",
       "18    decreased_branch_complexity    0.8  0.6240    0.1096       0.0155   \n",
       "19    decreased_branch_complexity    1.0  0.6225    0.1027       0.0306   \n",
       "\n",
       "    object  \n",
       "0   0.0778  \n",
       "1   0.5368  \n",
       "2   0.5821  \n",
       "3   0.5783  \n",
       "4   0.5115  \n",
       "5   0.0094  \n",
       "6   0.0094  \n",
       "7   0.0094  \n",
       "8   0.0093  \n",
       "9   0.0093  \n",
       "10  0.5536  \n",
       "11  0.5581  \n",
       "12  0.5539  \n",
       "13  0.5807  \n",
       "14  0.5705  \n",
       "15  0.5263  \n",
       "16  0.5909  \n",
       "17  0.5815  \n",
       "18  0.5843  \n",
       "19  0.5032  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_results_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjordvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
