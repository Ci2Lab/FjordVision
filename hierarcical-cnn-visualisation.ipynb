{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Trained Pytorch model and results\n",
    "\n",
    "## Import libraries and plot training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from anytree import Node\n",
    "from anytree.importer import JsonImporter\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from models.hierarchical_cnn import HierarchicalCNN\n",
    "from utils.custom_dataset import CustomDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df = pd.read_parquet('datasets/segmented-objects-dataset.parquet')\n",
    "\n",
    "# Assuming df is your DataFrame with all data\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Model and Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate Taxonomy\n",
    "importer = JsonImporter()\n",
    "with open('datasets/ontology.json', 'r') as f:\n",
    "    root = importer.read(f)\n",
    "\n",
    "classes_file = 'datasets/The Fjord Dataset/fjord/classes.txt'\n",
    "\n",
    "object_names = []\n",
    "with open(classes_file, 'r') as file:\n",
    "    object_names = [line.strip() for line in file]\n",
    "\n",
    "subcategory_names, category_names, binary_names = [], [], []\n",
    "for node in root.descendants:\n",
    "    if node.rank == 'genus':\n",
    "        subcategory_names.append(node.name)\n",
    "    elif node.rank == 'class':\n",
    "        category_names.append(node.name)\n",
    "    elif node.rank == 'binary':\n",
    "        binary_names.append(node.name)\n",
    "\n",
    "class_name_lists = [binary_names, category_names, subcategory_names, object_names]\n",
    "                    \n",
    "# Create a defaultdict to store the counts for each rank\n",
    "rank_counts = defaultdict(int)\n",
    "\n",
    "# Iterate over the nodes of the tree\n",
    "for node in root.descendants:\n",
    "    rank = node.rank\n",
    "    rank_counts[rank] += 1\n",
    "\n",
    "# Example instantiation of the model\n",
    "num_classes_hierarchy = list(rank_counts.values())  # Example: [num_species, num_genus, num_class, num_binary]\n",
    "num_additional_features = 3  # Assuming 3 additional features: conf, iou, pred_species\n",
    "\n",
    "model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "model.load_state_dict(torch.load('datasets/hierarchical-model-weights/weights/best_model_alpha_0.50.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local version of get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarchical_labels(species_index, species_names, genus_names, class_names, binary_names, root):\n",
    "    if species_index == -1:\n",
    "        return -1, -1, -1  # Handle cases where species_index is invalid\n",
    "\n",
    "    species_name = species_names[species_index]\n",
    "    node = next((n for n in root.descendants if n.name == species_name), None)\n",
    "\n",
    "    if node is None:\n",
    "        return -1, -1, -1  # Species not found in the tree\n",
    "\n",
    "    genus_index, class_index, binary_index = -1, -1, -1\n",
    "    current_node = node\n",
    "    while current_node.parent is not None:\n",
    "        current_node = current_node.parent\n",
    "        if current_node.rank == 'genus':\n",
    "            genus_index = genus_names.index(current_node.name) if current_node.name in genus_names else -1\n",
    "        elif current_node.rank == 'class':\n",
    "            class_index = class_names.index(current_node.name) if current_node.name in class_names else -1\n",
    "        elif current_node.rank == 'binary':\n",
    "            binary_index = binary_names.index(current_node.name) if current_node.name in binary_names else -1\n",
    "\n",
    "    return genus_index, class_index, binary_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df, object_names, subcategory_names, category_names, binary_names, root)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835887403543093"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df['predicted_species'] == test_df['species']).sum() / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Initialize lists to store true labels, predictions, and hierarchical labels for each level\n",
    "true_labels = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "predictions = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "yolo_labels = {level: [] for level in ['binary', 'class', 'genus', 'species']}\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "        images, conf, iou, pred_species = images.to(device), conf.to(device), iou.to(device), pred_species.to(device)\n",
    "        \n",
    "        outputs = model(images, conf, iou, pred_species)\n",
    "        \n",
    "        # Convert model outputs to predictions\n",
    "        for i, output in enumerate(outputs):  # For each hierarchical level\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            level = ['binary', 'class', 'genus', 'species'][i]\n",
    "            predictions[level].extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Extract hierarchical labels for each prediction in pred_species\n",
    "        for idx in pred_species:\n",
    "            genus_idx, class_idx, binary_idx = get_hierarchical_labels(idx.item(), object_names, subcategory_names, category_names, binary_names, root)\n",
    "            # Storing the hierarchical labels\n",
    "            yolo_labels['binary'].append(binary_idx)\n",
    "            yolo_labels['class'].append(class_idx)\n",
    "            yolo_labels['genus'].append(genus_idx)\n",
    "            yolo_labels['species'].append(idx.item())\n",
    "        \n",
    "        # Store true labels\n",
    "        true_labels['binary'].extend(binary_index.cpu().numpy())\n",
    "        true_labels['class'].extend(class_index.cpu().numpy())\n",
    "        true_labels['genus'].extend(genus_index.cpu().numpy())\n",
    "        true_labels['species'].extend(species_index.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "# Assume necessary imports and model definition are done here\n",
    "\n",
    "def transform_activations(activations):\n",
    "    \"\"\"\n",
    "    Transforms activations from (C x B x H x W) to (B x C x H x W).\n",
    "    Specifically handles the case where C should be treated as B for visualization.\n",
    "    \"\"\"\n",
    "    B, C, H, W = activations.shape[1], 1, activations.shape[2], activations.shape[3]\n",
    "    return activations.permute(1, 0, 2, 3).view(B, C, H, W)\n",
    "\n",
    "def resample_activations_to_grid(activations, nrow=4):\n",
    "    \"\"\"\n",
    "    Ensures there are nrow*nrow activation maps by either repeating or subsetting.\n",
    "    Adjusted for a 4x4 grid.\n",
    "    \"\"\"\n",
    "    total_needed = nrow * nrow  # Adjusted for a 4x4 grid\n",
    "    current_count = activations.shape[0]\n",
    "\n",
    "    if current_count < total_needed:\n",
    "        repeats = total_needed // current_count + 1\n",
    "        activations = activations.repeat(repeats, 1, 1, 1)[:total_needed]\n",
    "    elif current_count > total_needed:\n",
    "        indices = torch.linspace(0, current_count - 1, total_needed).long()\n",
    "        activations = activations[indices]\n",
    "\n",
    "    return activations\n",
    "\n",
    "def visualize_hierarchical_predictions_and_activations(image, activations, true_labels, predictions, class_name_lists, file_name):\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 4))  # Adjusted subplot size for better visualization\n",
    "    levels = ['original', 'binary', 'class', 'genus', 'species']\n",
    "\n",
    "    # Original image visualization\n",
    "    img_np = np.transpose(image.cpu().numpy(), (1, 2, 0))\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    axs[0].imshow(img_np)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Visualize activations for each level\n",
    "    for i, level in enumerate(levels):\n",
    "        if i == 0: continue\n",
    "        current_activation = activations[i - 1]\n",
    "        current_activation = transform_activations(current_activation)\n",
    "        current_activation = resample_activations_to_grid(current_activation, nrow=4)  # Ensure 4x4 grid\n",
    "        activation_grid = make_grid(current_activation, nrow=4, normalize=True, padding=2)\n",
    "\n",
    "        # Directly convert the grid tensor to a NumPy array and apply cmap\n",
    "        grid_np = np.transpose(activation_grid.cpu().numpy(), (1, 2, 0))\n",
    "        axs[i].imshow(grid_np[:, :, 0], cmap='viridis')  # Ensures viridis is applied for single-channel images\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name)  # Save the figure\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n",
    "# Define alpha values\n",
    "alpha_values = [0.5]\n",
    "\n",
    "# Create the main directory for activations if it doesn't exist\n",
    "os.makedirs('activations', exist_ok=True)\n",
    "\n",
    "# Loop through each alpha value\n",
    "for alpha in alpha_values:\n",
    "    # Adjust the alpha value for file naming convention\n",
    "    alpha_str = f\"{alpha:.2f}\"  # This ensures that alpha is formatted with two decimal places\n",
    "    alpha_dir = f'activations/alpha_{alpha_str}'\n",
    "    os.makedirs(alpha_dir, exist_ok=True)\n",
    "    \n",
    "    # Loop through each species\n",
    "    for idx, species in enumerate(object_names):\n",
    "        # Modify the model loading path to include the current alpha value\n",
    "        model_path = f'datasets/hierarchical-model-weights/weights/best_model_alpha_{alpha_str}.pth'\n",
    "        \n",
    "        # Load and prepare the model for each species\n",
    "        model = HierarchicalCNN(num_classes_hierarchy, num_additional_features)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        model.register_hooks()\n",
    "\n",
    "        # Get one random sample from the DataLoader\n",
    "        for images, conf, iou, pred_species, species_index, genus_index, class_index, binary_index in test_loader:\n",
    "            if species_index[0].item() == idx:\n",
    "                selected_image = images[0].unsqueeze(0).to(device)\n",
    "                selected_conf = conf[0].unsqueeze(0).to(device)\n",
    "                selected_iou = iou[0].unsqueeze(0).to(device)\n",
    "                selected_pred_species = pred_species[0].unsqueeze(0).to(device)\n",
    "                _ = model(selected_image, selected_conf, selected_iou, selected_pred_species)\n",
    "                break\n",
    "\n",
    "        # Create a directory for the species within the alpha directory if it doesn't exist\n",
    "        species_dir = os.path.join(alpha_dir, species.replace(\" \", \"_\"))\n",
    "        os.makedirs(species_dir, exist_ok=True)\n",
    "\n",
    "        # Generate and save the activation visualizations in the species directory\n",
    "        file_name = os.path.join(species_dir, f'{species.replace(\" \", \"_\")}.png')\n",
    "        visualize_hierarchical_predictions_and_activations(\n",
    "            selected_image.squeeze(0), \n",
    "            model.activations, \n",
    "            {'binary': binary_index[0].item(), 'category': class_index[0].item(), 'subcategory': genus_index[0].item(), 'object': species_index[0].item()}, \n",
    "            predictions, \n",
    "            class_name_lists,\n",
    "            file_name  # Pass the file name where the image should be saved\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Segmentation of Selected Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise most likely classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the parameters for the image optimization process\n",
    "upscaling_steps = 13\n",
    "upscaling_factor = 1.2\n",
    "lr = 0.01\n",
    "\n",
    "# Load the model\n",
    "alphas = ['0.50']\n",
    "levels = ['binary', 'category', 'subcategory', 'object']\n",
    "class_levels = [binary_names, category_names, subcategory_names, object_names]\n",
    "\n",
    "# Create the main directory for class activations\n",
    "os.makedirs('class-activations', exist_ok=True)\n",
    "\n",
    "for alpha in alphas:\n",
    "    model_path = f'datasets/hierarchical-model-weights/weights/best_model_alpha_{alpha}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for level_index, level in enumerate(levels):\n",
    "        level_path = os.path.join('class-activations', level)\n",
    "        os.makedirs(level_path, exist_ok=True)\n",
    "\n",
    "        for class_name in class_levels[level_index]:\n",
    "            class_path = os.path.join(level_path, class_name.replace(\" \", \"_\"))\n",
    "            os.makedirs(class_path, exist_ok=True)\n",
    "\n",
    "            # Initialize the image tensor once before the loop\n",
    "            image = torch.randn(1, 3, 50, 50, device=device, requires_grad=True)\n",
    "\n",
    "            for step in range(upscaling_steps):\n",
    "                optimizer = optim.Adam([image], lr=lr)\n",
    "\n",
    "                for iteration in range(30):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(image, torch.tensor([0.0], device=device), torch.tensor([0.0], device=device), torch.tensor([0.0], device=device))\n",
    "                    target_class_index = class_levels[level_index].index(class_name)\n",
    "                    target_output = outputs[level_index]\n",
    "\n",
    "                    loss = -target_output[0, target_class_index]\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Delete intermediate tensors\n",
    "                    del outputs, target_output, loss\n",
    "\n",
    "                # Upscale the image tensor\n",
    "                if step < upscaling_steps - 1:\n",
    "                    size = int(50 * (upscaling_factor ** (step + 1)))\n",
    "                    image = image.detach().cpu().numpy()\n",
    "                    image = np.transpose(image, (0, 2, 3, 1))\n",
    "                    image = cv2.resize(image[0], (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "                    image = np.transpose(image, (2, 0, 1))\n",
    "                    image = torch.from_numpy(image).unsqueeze(0).to(device)\n",
    "                    image.requires_grad_(True)\n",
    "\n",
    "            # Process and save the final image\n",
    "            image_np = image.detach().cpu().squeeze().numpy()\n",
    "            image_np = np.transpose(image_np, (1, 2, 0))\n",
    "            image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n",
    "            image_filename = os.path.join(class_path, f'{class_name.replace(\" \", \"_\")}_alpha_{alpha}.png')\n",
    "            plt.imsave(image_filename, image_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjordvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
